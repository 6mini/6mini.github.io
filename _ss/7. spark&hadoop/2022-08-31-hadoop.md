---
title: "[빅데이터 처리 입문] 하둡과 에코시스템(Hadoop ecosystem)"
description: 
categories:
 - Spark & Hadoop
tags: []
mathjax: enable
---

# 하둡(Hadoop)
- 높은 확장성과 신뢰성을 보유한 분산 스토리지와 분산 처리 기능을 제공하기 위한 다수의 소프트웨어 집합체이다.
- 간단한 프로그래밍 모델을 사용하여 컴퓨터의 클러스터에서 대규모 데이터 세트를 분산 저장 및 처리할 수 있는 오픈소스 프레임워크이다.

## 구성 요소
- 분산 파일 시스템: HDFS(Hadoop Distributed File System)
- 리소스 관리자: YARN(Yet Another Resource Negotiation)
- 분산 데이터 처리: MapReduce

## 역사

![image](https://user-images.githubusercontent.com/79494088/187341400-27f52e0e-32e0-44bb-aced-2192d9d50aef.png)

# 하둡 에코시스템(Hadoop ecosystem)이란?
- 하둡의 코어 프로젝트는 HDFS와 MapReduce지만 그 외에도 다양한 서브 프로젝트들이 많이 있다. 
- 하둡 에코시스템은 바로 그 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 모임이라고 볼 수 있다.

![image](https://user-images.githubusercontent.com/79494088/187341460-a0f2e4a6-4ce6-4845-8072-fbe110822ee4.png)

- 굉장히 다양한 프레임워크가 존재하는 것을 볼 수 있다.

## 빅데이터 플랫폼과의 관계

![image](https://user-images.githubusercontent.com/79494088/187342013-dd23bbc6-7688-4d66-aa85-26675953f43e.png)

# 하둡 클러스터(cluster) 구축 고려사항

## 클러스터란?
- 여러 대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는 컴퓨터들의 집합이다.
- 주로 마스터(Master)와 워커(Worker)로 구성된다.

<img width="535" alt="image" src="https://user-images.githubusercontent.com/79494088/188770173-b38232a4-11db-4271-b9fa-46f6bc9459a7.png">

<img width="447" alt="image" src="https://user-images.githubusercontent.com/79494088/188770246-d1132f2c-25b0-4039-bde0-36a59327cbd6.png">

- 워커 3에 장애가 발생하더라도, 워커 1, 2에서 파티션(Partition) A, B에 대한 정보를 갖고 있기 때문에 대응할 수 있다. 

## 클러스터 규모 결정

### 데이터 스토리지 용량으로 결정
- 데이터가 얼마나 존재하고 얼마나 빠르게 생산되는 지 확인해야한다.
- 스토리지 용량으로 결정하며, 저장 될 데이터 크기를 예측한다.
- 사본을 얼마나 복제할 지 전략을 결정해야한다.(복제계수)
- 저장 기간을 고려하여 필요한 노드 수를 결정할 수 있다.
- 그 외에도 데이터 포맷, 압축 여부, 증가율의 변화 등을 고려해야한다.

#### 예시
- 하루에 저장되는 데이터의 크기는 1TB이다.
- 복제 계수는 3이다.
- 저장 기간은 3년이다.
- 필요한 노드 수는 서버 한 대의 저장 용량 5TB * 12 = 약 70대로 결정한다.

### 데이터 수집 속도로 결정
- 데이터 수집 및 처리의 속도로 예측하여 결정한다.

#### 예시
- 1TB의 데이터를 분석할 때 5분 이내로 결과를 저장해야한다.
- 쓰기 속도는 디스크당 초당 50MB이다.
- 디스크 70개를 병렬로 써야하며 서버당 디스크가 24개씩 있는 경우, 약 3대의 서버가 필요하다.

## 클러스터 하드웨어 결정
- 워크로드에 따라 하드웨어 선정을 다르게 진행해야한다.
    - CPU, Memory, I/O

# HDFS(Hadoop Distributed FileSystem)

## 분산 파일 시스템

<img width="737" alt="image" src="https://user-images.githubusercontent.com/79494088/188779266-10de67aa-192e-4a69-bf2c-b28fe155c336.png">

- 네트워크로 연결된 머신의 스토리지를 관리하는 파일 시스템이다.

## 특징
- 범용 하드웨어를 사용하여 분산 파일 시스템으로 구성되어 있다.
- 파일을 블록 단위로 저장한다.
- 마스터와 워커의 구조이다.
- 내고장성(Fault-tolerance)을 제공한다.
- 확장성을 제공한다.

### HDFS Block
- 하나의 파일을 여러 블록으로 저장한다.(기본 블록 사이즈가 128MB이다.)
- 실제 파일 크기가 블록 사이즈보다 적은 경우 파일 크기만큼만 디스크를 사용한다.
- 일반적인 디스크 블록에 비해 크다.
- 탐색 비용을 최소화하기 위함이며, 블록의 시작점을 탐색하는데 시간이 적게 걸린다.
- 메타 데이터 크기가 감소되는 이점이 있다.

#### 블록 단위 처리의 이점
- 파일 하나의 크기가 실제 하나의 물리 디스크 사이즈보다 커질 수 있다.
- 스토리지의 관리가 단순화된다.
- 내고장성과 가용성을 지원하는 복제 기능에 적합하다.

## 구조

<img width="677" alt="image" src="https://user-images.githubusercontent.com/79494088/188779944-60b7b446-7ecd-44eb-b76a-b2ba7fb2b841.png">

### NameNode
- 메타데이터를 관리한다.
    - FsImage(파일 시스템 이미지) 네임 스페이스를 포함한 데이터의 모든 정보이다.
    - EditLog: 데이터 노드에서 발생한 데이터의 변환 내역이다.
- 데이터 노드를 관리한다.

### Secondary NameNode

<img width="432" alt="image" src="https://user-images.githubusercontent.com/79494088/188780321-bffd8c26-ecb3-49d8-91e2-201164b96fd1.png">


- Namenode의 Standby 역할이 아니며, 체크 포인트 역할을 한다.
    - FsImage와 EditLog를 주기적으로 병합한다.
- 주기적으로 NameNode의 FsImage를 백업한다.

### DataNode
- 실제 파일을 로컬 파일 시스템에 HDFS 데이터로 저장한다.
- 하트비트를 통한 데이터 노드 동작 여부를 전달한다.
- 저장하고 있는 블록의 목록을 주기적으로 네임노드에 보고한다.

### NameNode와 DataNode

<img width="594" alt="image" src="https://user-images.githubusercontent.com/79494088/188780500-b5470d66-0a08-483a-afe8-2e8ea16c30b4.png">

- 하나에서 장애가 발생하더라도 문제 없이 읽을 수 있다.

## 읽기 연산

<img width="620" alt="image" src="https://user-images.githubusercontent.com/79494088/188780624-a4594e51-da23-443b-bcc9-9bcb032154d3.png">

## 쓰기 연산

<img width="784" alt="image" src="https://user-images.githubusercontent.com/79494088/188780674-35cb897d-73e3-4d42-b1b1-fe26dc3da546.png">

## 추가적인 특징
- 블록 캐싱 기능을 제공한다.
- HDFS Federation을 지원한다.
- 고가용성(HA)을 지원한다.

# 하둡 설치 및 실습

- Homebrew 설치
- Java 설치

```s
$ java -version
'''
java version "1.8.0_25"
Java(TM) SE Runtime Environment (build 1.8.0_25-b17)
Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode)
'''
```

- 환경 변수를 설정한다.

```s
$ vim ~/.zshrc

export JAVA_HOME=$(/usr/libexec/java_home)

$ source ~/.zshrc

$ echo $JAVA_HOME
'''
/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home
'''
```

- 자바 설치는 완료되었다.
- 하둡을 실행할 때 `ssh` 명령어를 이용하여 로컬호스트에 접속할 수 있는 환경을 구성해야한다.

## ssh 로그인 설정

```s
$ ssh localhost 
'''
ssh: connect to host localhost port 22: Connection refused
'''
```

- 현재는 원격 로그인이 설정되어 있지 않아 위와 같은 에러 메세지가 전시된다.

![image](https://user-images.githubusercontent.com/79494088/190044355-4ececeb5-4f74-4f0b-aa02-c0c45c190f1e.png)

- 시스템 환경설정 -> 공유 -> 원격 로그인을 체크한다.

```s
$ ssh localhost
'''
(6mini@localhost) Password:
'''
```

- 에러 메세지는 사라지고 패스워드를 입력하는 메세지가 전시된다.
- 패스워드를 입력하지 않고 바로 접속할 수 있는 환경을 구성한다.

```s
$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
"""
Generating public/private rsa key pair.
Your identification has been saved in /Users/6mini/.ssh/id_rsa
Your public key has been saved in /Users/6mini/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:+2MzbkwRRf5gGRRVzAqdAdbxLAtnfkVjR0nao+ckkeM 6mini@6miniui-MacBookPro.local
The key's randomart image is:
+---[RSA 3072]----+
|           +O*=%*|
|          .o.oO==|
|           .**+++|
|          ...B=oo|
|        S  . E+o.|
|         ..   =. |
|        .o     . |
|         .B      |
|         +o+     |
+----[SHA256]-----+
"""

$ cd ~/.ssh

.ssh$ ls
'''
id_rsa          id_rsa.pub      known_hosts     known_hosts.old
'''

.ssh$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys 

.ssh$ ssh localhost
'''
Last login: Wed Sep 14 11:28:55 2022
'''
```

- 위 과정을 통해 패스워드 없이 pub key로 로컬호스트에 접속할 수 있는 상태를 만들었다.
- 다음으로는 하둡 패키지를 다운로드한다.

## 하둡 다운로드

```s
$ wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz

$ tar zxvf hadoop-3.3.2.tar.gz
```

- 환경 변수를 설정한다.

```s
$ vim ~/.zshrc

export HADOOP_HOME=/Users/6mini/hadoop/hadoop-3.3.2

export PATH=$PATH:$HADOOP_HOME/bin 

$ source ~/.zshrc

$ hadoop
'''
Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]
 or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]
  where CLASSNAME is a user-provided Java class

  OPTIONS is none or any of:

--config dir                     Hadoop config directory
--debug                          turn on shell script debug mode
--help                           usage information
buildpaths                       attempt to add class files from build tree
hostnames list[,of,host,names]   hosts to use in slave mode
hosts filename                   list of hosts to use in slave mode
loglevel level                   set the log4j level for this command
workers                          turn on worker mode

  SUBCOMMAND is one of:


    Admin Commands:

daemonlog     get/set the log level for each daemon

    Client Commands:

archive       create a Hadoop archive
checknative   check native Hadoop and compression libraries availability
classpath     prints the class path needed to get the Hadoop jar and the
              required libraries
conftest      validate configuration XML files
credential    interact with credential providers
distch        distributed metadata changer
distcp        copy file or directories recursively
dtutil        operations related to delegation tokens
envvars       display computed Hadoop environment variables
fs            run a generic filesystem user client
gridmix       submit a mix of synthetic job, modeling a profiled from
              production load
jar <jar>     run a jar file. NOTE: please use "yarn jar" to launch YARN
              applications, not this command.
jnipath       prints the java.library.path
kdiag         Diagnose Kerberos Problems
kerbname      show auth_to_local principal conversion
key           manage keys via the KeyProvider
rumenfolder   scale a rumen input trace
rumentrace    convert logs into a rumen trace
s3guard       manage metadata on S3
trace         view and modify Hadoop tracing settings
version       print the version

    Daemon Commands:

kms           run KMS, the Key Management Server
registrydns   run the registry DNS server

SUBCOMMAND may print help when invoked w/o parameters or with -h.
'''
```

- 하둡 명령어를 사용할 수 있는 상태가 되었다.
- 하둡을 실행하기 전 환경설정 파일들을 설정해야한다.

## 설정 파일 수정
```s
$ cd etc/hadoop

$ ls
'''
capacity-scheduler.xml           kms-log4j.properties
configuration.xsl                kms-site.xml
container-executor.cfg           log4j.properties
core-site.xml                    mapred-env.cmd
hadoop-env.cmd                   mapred-env.sh
hadoop-env.sh                    mapred-queues.xml.template
hadoop-metrics2.properties       mapred-site.xml
hadoop-policy.xml                shellprofile.d
hadoop-user-functions.sh.example ssl-client.xml.example
hdfs-rbf-site.xml                ssl-server.xml.example
hdfs-site.xml                    user_ec_policies.xml.template
httpfs-env.sh                    workers
httpfs-log4j.properties          yarn-env.cmd
httpfs-site.xml                  yarn-env.sh
kms-acls.xml                     yarn-site.xml
kms-env.sh                       yarnservice-log4j.properties
'''
```

### `core-site.xml`

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

### `hdfs-site.xml`

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/Users/6mini/hadoop/hadoop-3.3.2/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/Users/6mini/hadoop/hadoop-3.3.2/dfs/data</value>
    </property>
</configuration>
```

- 노드 위치를 설정해주었는데 디렉토리가 없기 때문에 생성해준다.

```s
hadoop-3.3.2$ mkdir -p dfs/name
hadoop-3.3.2$ mkdir -p dfs/data
```

### `mapred-site.xml`

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>
```

### `yarn-site.xml`

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>
```

## HDFS 실행

- 네임 노드를 포맷시킨다.

```s
$ hdfs namenode -format
```

- hdfs를 시작한다.

```s
$ sbin/start-dfs.sh
```
