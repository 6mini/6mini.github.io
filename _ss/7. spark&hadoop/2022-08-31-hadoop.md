---
title: "[빅데이터 처리 입문] 하둡과 에코시스템(Hadoop ecosystem)"
description: 하둡 및 하둡 에코시스템의 정의와 구성요소, 하둡 클러스터 구축 시의 고려사항, HDFS의 정의와 구조
categories:
 - Spark & Hadoop
tags: [하둡, 하둡 에코시스템, HDFS]
mathjax: enable
---

# 하둡(Hadoop)
- 높은 확장성과 신뢰성을 보유한 분산 스토리지와 분산 처리 기능을 제공하기 위한 다수의 소프트웨어 집합체이다.
- 간단한 프로그래밍 모델을 사용하여 컴퓨터의 클러스터에서 대규모 데이터 세트를 분산 저장 및 처리할 수 있는 오픈소스 프레임워크이다.

## 구성 요소
- 분산 파일 시스템: HDFS(Hadoop Distributed File System)
- 리소스 관리자: YARN(Yet Another Resource Negotiation)
- 분산 데이터 처리: MapReduce

## 역사

![image](https://user-images.githubusercontent.com/79494088/187341400-27f52e0e-32e0-44bb-aced-2192d9d50aef.png)

# 하둡 에코시스템(Hadoop ecosystem)이란?
- 하둡의 코어 프로젝트는 HDFS와 MapReduce지만 그 외에도 다양한 서브 프로젝트들이 많이 있다. 
- 하둡 에코시스템은 바로 그 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 모임이라고 볼 수 있다.

![image](https://user-images.githubusercontent.com/79494088/187341460-a0f2e4a6-4ce6-4845-8072-fbe110822ee4.png)

- 굉장히 다양한 프레임워크가 존재하는 것을 볼 수 있다.

## 빅데이터 플랫폼과의 관계

![image](https://user-images.githubusercontent.com/79494088/187342013-dd23bbc6-7688-4d66-aa85-26675953f43e.png)

# 하둡 클러스터(cluster) 구축 고려사항

## 클러스터란?
- 여러 대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는 컴퓨터들의 집합이다.
- 주로 마스터(Master)와 워커(Worker)로 구성된다.

<img width="535" alt="image" src="https://user-images.githubusercontent.com/79494088/188770173-b38232a4-11db-4271-b9fa-46f6bc9459a7.png">

<img width="447" alt="image" src="https://user-images.githubusercontent.com/79494088/188770246-d1132f2c-25b0-4039-bde0-36a59327cbd6.png">

- 워커 3에 장애가 발생하더라도, 워커 1, 2에서 파티션(Partition) A, B에 대한 정보를 갖고 있기 때문에 대응할 수 있다. 

## 클러스터 규모 결정

### 데이터 스토리지 용량으로 결정
- 데이터가 얼마나 존재하고 얼마나 빠르게 생산되는 지 확인해야한다.
- 스토리지 용량으로 결정하며, 저장 될 데이터 크기를 예측한다.
- 사본을 얼마나 복제할 지 전략을 결정해야한다.(복제계수)
- 저장 기간을 고려하여 필요한 노드 수를 결정할 수 있다.
- 그 외에도 데이터 포맷, 압축 여부, 증가율의 변화 등을 고려해야한다.

#### 예시
- 하루에 저장되는 데이터의 크기는 1TB이다.
- 복제 계수는 3이다.
- 저장 기간은 3년이다.
- 필요한 노드 수는 서버 한 대의 저장 용량 5TB * 12 = 약 70대로 결정한다.

### 데이터 수집 속도로 결정
- 데이터 수집 및 처리의 속도로 예측하여 결정한다.

#### 예시
- 1TB의 데이터를 분석할 때 5분 이내로 결과를 저장해야한다.
- 쓰기 속도는 디스크당 초당 50MB이다.
- 디스크 70개를 병렬로 써야하며 서버당 디스크가 24개씩 있는 경우, 약 3대의 서버가 필요하다.

## 클러스터 하드웨어 결정
- 워크로드에 따라 하드웨어 선정을 다르게 진행해야한다.
    - CPU, Memory, I/O

# HDFS(Hadoop Distributed FileSystem)

## 분산 파일 시스템

<img width="737" alt="image" src="https://user-images.githubusercontent.com/79494088/188779266-10de67aa-192e-4a69-bf2c-b28fe155c336.png">

- 네트워크로 연결된 머신의 스토리지를 관리하는 파일 시스템이다.

## 특징
- 범용 하드웨어를 사용하여 분산 파일 시스템으로 구성되어 있다.
- 파일을 블록 단위로 저장한다.
- 마스터와 워커의 구조이다.
- 내고장성(Fault-tolerance)을 제공한다.
- 확장성을 제공한다.

### HDFS Block
- 하나의 파일을 여러 블록으로 저장한다.(기본 블록 사이즈가 128MB이다.)
- 실제 파일 크기가 블록 사이즈보다 적은 경우 파일 크기만큼만 디스크를 사용한다.
- 일반적인 디스크 블록에 비해 크다.
- 탐색 비용을 최소화하기 위함이며, 블록의 시작점을 탐색하는데 시간이 적게 걸린다.
- 메타 데이터 크기가 감소되는 이점이 있다.

#### 블록 단위 처리의 이점
- 파일 하나의 크기가 실제 하나의 물리 디스크 사이즈보다 커질 수 있다.
- 스토리지의 관리가 단순화된다.
- 내고장성과 가용성을 지원하는 복제 기능에 적합하다.

## 구조

<img width="677" alt="image" src="https://user-images.githubusercontent.com/79494088/188779944-60b7b446-7ecd-44eb-b76a-b2ba7fb2b841.png">

### NameNode
- 메타데이터를 관리한다.
    - FsImage(파일 시스템 이미지) 네임 스페이스를 포함한 데이터의 모든 정보이다.
    - EditLog: 데이터 노드에서 발생한 데이터의 변환 내역이다.
- 데이터 노드를 관리한다.

### Secondary NameNode

<img width="432" alt="image" src="https://user-images.githubusercontent.com/79494088/188780321-bffd8c26-ecb3-49d8-91e2-201164b96fd1.png">


- Namenode의 Standby 역할이 아니며, 체크 포인트 역할을 한다.
    - FsImage와 EditLog를 주기적으로 병합한다.
- 주기적으로 NameNode의 FsImage를 백업한다.

### DataNode
- 실제 파일을 로컬 파일 시스템에 HDFS 데이터로 저장한다.
- 하트비트를 통한 데이터 노드 동작 여부를 전달한다.
- 저장하고 있는 블록의 목록을 주기적으로 네임노드에 보고한다.

### NameNode와 DataNode

<img width="594" alt="image" src="https://user-images.githubusercontent.com/79494088/188780500-b5470d66-0a08-483a-afe8-2e8ea16c30b4.png">

- 하나에서 장애가 발생하더라도 문제 없이 읽을 수 있다.

## 읽기 연산

<img width="620" alt="image" src="https://user-images.githubusercontent.com/79494088/188780624-a4594e51-da23-443b-bcc9-9bcb032154d3.png">

## 쓰기 연산

<img width="784" alt="image" src="https://user-images.githubusercontent.com/79494088/188780674-35cb897d-73e3-4d42-b1b1-fe26dc3da546.png">

## 추가적인 특징
- 블록 캐싱 기능을 제공한다.
- HDFS Federation을 지원한다.
- 고가용성(HA)을 지원한다.
