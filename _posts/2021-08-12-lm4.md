---
title: '[Linear Models] ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)'
description: í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸(train/validate/test) ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ëŠ” ì´ìœ ë¥¼ ëª…í™•íˆ ì´í•´, ë¶„ë¥˜(Classification) ë¬¸ì œì™€ íšŒê·€ë¬¸ì œì˜ ì°¨ì´ì ì„ íŒŒì•…í•˜ê³  ë¬¸ì œì— ë§ëŠ” ëª¨ë¸ ì‚¬ìš©, ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic regression)ì„ ì´í•´
categories:
 - Machine Learning
tags: [Machine Learning, Linear Models, Logistic Regression, ë¡œì§€ìŠ¤í‹±íšŒê·€]
mathjax: enable
# 0ï¸âƒ£1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£7ï¸âƒ£8ï¸âƒ£9ï¸âƒ£ğŸ”Ÿ
---

# 1ï¸âƒ£ í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸(train/validate/test)
- ìºê¸€ì€ ë³´í†µ ë°ì´í„°ì…‹ì„ í›ˆë ¨/í…ŒìŠ¤íŠ¸ë¡œ ë‚˜ëˆ„ì–´ ì œê³µí•œë‹¤.
- í…ŒìŠ¤íŠ¸ë°ì´í„°ëŠ” íŠ¹ì„±ì˜ ê°œìˆ˜ê°€ í•˜ë‚˜ ì ë‹¤.

```py
import pandas as pd
train = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/titanic/train.csv')
test = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/titanic/test.csv')

print("train features: ", train.shape[1])
print("test features: ", test.shape[1])

'''
train features:  12
test features:  11
'''

# ì—†ëŠ” íƒ€ê²Ÿ í™•ì¸
print("target col: ", train.columns.difference(test.columns)[0])

# target col:  Survived
```

- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œëŠ” íƒ€ê²Ÿ ì •ë³´ë¥¼ ì œì™¸í•´ ë†“ì•˜ë‹¤.
- ì´ìœ 
  - ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì˜¬ë°”ë¥´ê²Œ ì¸¡ì •í•˜ê¸° ìœ„í•´ì„œ
- ê²€ì¦ì…‹ì´ í•„ìš”í•œ ì´ìœ 
  - í›ˆë ¨ì„¸íŠ¸ë¡œ ëª¨ë¸ì„ í•œ ë²ˆì— ì™„ì „í•˜ê²Œ í•™ìŠµì‹œí‚¤ê¸° ì–´ë µê¸° ë•Œë¬¸ì´ë‹¤.
  - í›ˆë ¨ì„¸íŠ¸ë¡œ ë‹¤ë¥´ê²Œ íŠœë‹ëœ ì—¬ëŸ¬ ëª¨ë¸ì„ í•™ìŠµ í›„ ì–´ë–¤ ëª¨ë¸ì´ í•™ìŠµì´ ì˜ ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•˜ê³  ì„ íƒí•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.
- í›ˆë ¨/ê²€ì¦ì„¸íŠ¸ë¡œ ì¢‹ì€ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë‚¸ í›„ ìµœì¢…ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ì„¸íŠ¸ì—ì„œ ë‹¨ í•œë²ˆì˜ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•œë‹¤.
- ìµœì¢…í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ë§ˆìŒì— ë“¤ì§€ ì•ŠëŠ”ë‹¤ê³  ëª¨ë¸ì„ ë˜ ìˆ˜ì •í•œë‹¤ë©´ ê·¸ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ì„¸íŠ¸ì— ê³¼ì í•©í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤.

## 3ê°œì˜ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì€ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ë§¤ìš° ì¤‘ìš”
- í›ˆë ¨ë°ì´í„° : ëª¨ë¸ì„ Fit í•˜ëŠ”ë° ì‚¬ìš©
- ê²€ì¦ë°ì´í„° : ì˜ˆì¸¡ ëª¨ë¸ì„ ì„ íƒí•˜ê¸° ìœ„í•´ ì˜ˆì¸¡ì˜ ì˜¤ë¥˜ë¥¼ ì¸¡ì •í•  ë•Œ ì‚¬ìš©
- í…ŒìŠ¤íŠ¸ë°ì´í„° : ì¼ë°˜í™” ì˜¤ë¥˜ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ì„ íƒëœ ëª¨ë¸ì— í•œí•˜ì—¬ ë§ˆì§€ë§‰ì— í•œ ë²ˆë§Œ ì‚¬ìš©
  - í›ˆë ¨ì´ë‚˜ ê²€ì¦ê³¼ì •ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜ 
  - í…ŒìŠ¤íŠ¸ë°ì´í„°ê°€ ìœ ì¶œ(leak) ë˜ì–´ í›ˆë ¨/ê²€ì¦ê³¼ì •ì— ì‚¬ì˜ë˜ë©´ ëª¨ë¸ì„ ì˜ëª» í‰ê°€í•˜ê²Œ ëœë‹¤.

### ëª¨ë¸ê²€ì¦

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-12 14 02 22](https://user-images.githubusercontent.com/79494088/129140750-8bd1c4fc-f41c-4f43-987b-ebbbb095878f.png)

- í•™ìŠµ ëª¨ë¸ ê°œë°œ ì‹œ, ëª¨ë¸ ì„ íƒ(Model Selection) ìˆ˜í–‰í•´ì•¼ í•œë‹¤.
- ì´ ë•Œ í•˜ì´í¼íŒŒë¼ë¯¸í„°(HyperParameter) íŠœë‹ì„ í•˜ê²Œ ë˜ëŠ”ë° íŠœë‹ì˜ íš¨ê³¼ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ê²€ì¦ì„¸íŠ¸ê°€ í•„ìš”í•˜ë‹¤.
  - [í•˜ì´í¼íŒŒë¼ë¯¸í„°](https://gooopy.tistory.com/75) : ì—°êµ¬ìê°€ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ê°’(í•™ìŠµë¥ , Optimizer, í™œì„±í™” í•¨ìˆ˜, ì†ì‹¤ í•¨ìˆ˜ ë“± ë‹¤ì–‘í•œ ì¸ì)
- í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì ˆëŒ€ë¡œ í•˜ë©´ ì•ˆëœë‹¤.
- ë°ì´í„°ê°€ ë§ì€ ê²½ìš°, ì„¸ê°€ì§€ë¡œ ë‚˜ëˆ„ë©´ ë˜ì§€ë§Œ, ë°ì´í„°ìˆ˜ê°€ ì ì€ ê²½ìš° K-fold êµì°¨ê²€ì¦ì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤. (ì´ ë•Œë„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ëŠ” ë¯¸ë¦¬ ë–¼ ë†“ì•„ì•¼ í•¨)

### ìºê¸€ì˜ ë°ì´í„°ì…‹ ë‚˜ëˆ„ê¸°
- í›ˆë ¨ë°ì´í„°ë¥¼ í›ˆë ¨/ê²€ì¦ì…‹ìœ¼ë¡œ ë‚˜ëˆˆë‹¤.
- Sklearnì˜ train_test_split ì‚¬ìš©

```py
from sklearn.model_selection import train_test_split
train, val = train_test_split(train, random_state=2)
print("train shape: ", train.shape)
print("val shape: ", val.shape)

'''
train shape:  (668, 12)
val shape:  (223, 12)
'''
```

# 2ï¸âƒ£ ë¶„ë¥˜(Classification)ë¬¸ì œ
- ë¶„ë¥˜ë¬¸ì œëŠ” íšŒê·€ë¬¸ì œì™€ ë‹¤ë¥¸ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì¤€ëª¨ë¸ì„ ì„¤ì •
- ë‹¤ìˆ˜ í´ë˜ìŠ¤ë¥¼ ê¸°ì¤€ëª¨ë¸ë¡œ ì •í•˜ëŠ” ë°©ë²•
  - íšŒê·€ë¬¸ì œ : íƒ€ê²Ÿ ë³€ìˆ˜ì˜ í‰ê· ê°’
  - ë¶„ë¥˜ë¬¸ì œ : íƒ€ê²Ÿ ë³€ìˆ˜ì—ì„œ ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ë²”ì£¼
  - ì‹œê³„ì—´ : ì–´ë–¤ ì‹œì ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ì „ ì‹œê°„ì˜ ë°ì´í„°
- ë¶„ë¥˜ë¬¸ì œì—ì„œëŠ” íƒ€ê²Ÿ ë³€ìˆ˜ê°€ í¸ì¤‘ëœ ë²”ì£¼ë¹„ìœ¨ì„ ê°€ì§€ëŠ” ê²½ìš°ê°€ ë§ë‹¤.
  - í¸ì¤‘ ëœ ë‹¤ìˆ˜ ëª¨ë¸ì„ ì“°ì§€ ì•Šê³  ì ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì°©ê°ì´ ì¼ì–´ë‚  ìˆ˜ ìˆë‹¤.
  - ë§Œì•½ ë‹¤ìˆ˜ ëª¨ë¸ì˜ ë¹„ìœ¨ì´ 90%ì¼ ê²½ìš° ì •í™•ë„ë„ 90%ê°€ ë  ìˆ˜ ìˆëŠ”ë°, ê·¸ê²ƒë³´ë‹¤ ì¢‹ì€ ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ ë…¸ë ¥í•´ì•¼ í•œë‹¤.

## íƒ€ê²Ÿ ë²”ì£¼ ë¹„ìœ¨ í™•ì¸

```py
# íƒ€ê²Ÿì„ ì •í•©ë‹ˆë‹¤
# survived => 0 = No, 1 = Yes
target = 'Survived'

# íƒ€ê²Ÿ ë°ì´í„° ë²”ì£¼ì˜ ë¹„ìœ¨ì„ í™•ì¸
y_train = train[target]
y_train.value_counts(normalize=True) # ë²”ì£¼ ë¹„ìœ¨ í™•ì¸

'''
0    0.625749
1    0.374251
Name: Survived, dtype: float64
'''

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
sns.countplot(x=y_train); # ì‹œê°í™”ë¡œë„ í™•ì¸
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-12 14 13 05](https://user-images.githubusercontent.com/79494088/129141629-7eb9e01c-4515-498f-8506-1412dbe8e830.png)

## ë²”ì£¼ 0(majority class)ìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰

```py
# mode(): ê°€ì¥ ë†’ì€ ë²¨ë¥˜ ê°’ ë°˜í™˜
major = y_train.mode()[0]

# íƒ€ê²Ÿ ìƒ˜í”Œ ìˆ˜ ë§Œí¼ 0ì´ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤. ê¸°ì¤€ëª¨ë¸ë¡œ ì˜ˆì¸¡
y_pred = [major] * len(y_train)
```

## ë¶„ë¥˜ì˜ í‰ê°€ì§€í‘œ(evaluation metrics)
- íšŒê·€ í‰ê°€ì§€í‘œë¥¼ ë¶„ë¥˜ì— ì‚¬ìš©í•˜ë©´ ì•ˆëœë‹¤. ë°˜ëŒ€ë„ ë§ˆì°¬ê°€ì§€
- ë¶„ë¥˜ë¬¸ì œì—ì„œëŠ” ì •í™•ë„ë¥¼ í‰ê°€ì§€í‘œë¡œ ì‚¬ìš©í•œë‹¤.
  - Accuracy = $\frac{ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•œ ìˆ˜} {ì „ì²´ ì˜ˆì¸¡ ìˆ˜}$ = $\frac{TP + TN} {P + N}$

```py
from sklearn.metrics import accuracy_score
print("training accuracy: ", accuracy_score(y_train, y_pred)) # ê¸°ì¤€ ëª¨ë¸ì˜ ì •í™•ë„ ì‚°ì¶œ

# training accuracy:  0.625748502994012
# ìµœë‹¤ í´ë˜ìŠ¤ì˜ ë¹ˆë„ê°€ ì •í™•ë„ê°€ ëœë‹¤.

y_val = val[target] 
y_pred = [major] * len(y_val)
print("validation accuracy: ", accuracy_score(y_val, y_pred)) # ê²€ì¦ì„¸íŠ¸ì—ì„œì˜ ì •í™•ë„ í™•ì¸

# validation accuracy:  0.5874439461883408
```

# 3ï¸âƒ£ ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)

## ë¨¼ì € ì„ í˜•íšŒê·€ëª¨ë¸ ì‚¬ìš©

```py
from sklearn.linear_model import LinearRegression

linear_model = LinearRegression()

# ìˆ«ìí˜• íŠ¹ì„±
features = ['Pclass', 'Age', 'Fare']
X_train = train[features]
X_val = val[features]

# Age, Cabinì˜ ê²°ì¸¡ì¹˜ë¥¼ í‰ê·  ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
from sklearn.impute import SimpleImputer # ì‹¬í”Œí•˜ê²Œ ê²°ì¸¡ì¹˜ë“¤ì„ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›Œì¤Œ

## default, imputing 'mean' value
imputer = SimpleImputer() 
X_train_imputed = imputer.fit_transform(X_train)
X_val_imputed = imputer.transform(X_val)

# í•™ìŠµ
linear_model.fit(X_train_imputed, y_train)

# ì˜ˆì¸¡
pred = linear_model.predict(X_val_imputed)

# íšŒê·€ê³„ìˆ˜ ìˆ˜ì¹˜ í™•ì¸
pd.Series(linear_model.coef_, features)

'''
Pclass   -0.203810
Age      -0.007513
Fare      0.000819
dtype: float64
'''
# Pclassì˜ ê²½ìš° ë†’ì„ ìˆ˜ë¡(2, 3ë“±ì„) ìƒì¡´ë¥ ì´ ë–¨ì–´ì§
# Ageì˜ ê²½ìš° ë§ì„ ìˆ˜ë¡ ìƒì¡´ë¥ ì´ ë–¨ì–´ì§
# Fareì˜ ê²½ìš°ëŠ” ìˆ˜ì¹˜ê°€ ì‘ì§€ë§Œ ë†’ì„ ìˆ˜ë¡ ìƒì¡´ë¥ ì´ ì˜¬ë¼ê°
```

### ê°€ìƒì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

```py
test_case = [[1, 5, 600]] # 1ë“±ê¸‰ì˜ 5ì‚´ ë‚˜ì´ì— ë¹„ì‹¼ìš”ê¸ˆ : ë¬´ì¡°ê±´ ìƒì¡´í•  ê²ƒ ê°™ë‹¤
linear_model.predict(test_case) 

# array([1.28916042]) : 1ì´ ë„˜ì—ˆë‹¤.
```

- íšŒê·€ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— íƒ€ê²Ÿë³€ìˆ˜ê°’ì´ ìŒìˆ˜ì—ì„œ ì–‘ìˆ˜ê¹Œì§€ ë‚˜íƒ€ë‚˜ëŠ”ë° ìƒì¡´ì¸ì§€ ì•„ë‹Œì§€ ë¶„ëª…í•˜ê²Œ ê²°ê³¼ë¥¼ ì•Œ ìˆ˜ ì—†ë‹¤.
- ê²Œë‹¤ê°€ íšŒê·€ì´ê¸° ë•Œë¬¸ì— ë¶„ë¥˜ëª¨ë¸ì— ì‚¬ìš©í•˜ëŠ” í‰ê°€ì§€í‘œë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤.

## ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨ë¸
- ë¡œì§€ìŠ¤í‹±íšŒê·€ë¥¼ ì‚¬ìš©í•˜ë©´ íƒ€ê²Ÿë³€ìˆ˜ì˜ ë²”ì£¼ë¡œ 0ê³¼ 1ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©° ê° ë²”ì£¼ì˜ ì˜ˆì¸¡ í™•ë¥ ê°’ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.
- ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨ë¸ì˜ ì‹

{% raw %} $$\large P(X)={\frac {1}{1+e^{-(\beta _{0}+\beta _{1}X_{1}+\cdots +\beta _{p}X_{p})}}}$$
$$ 0 \leq P(X) \leq 1$$ {% endraw %}

- ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë¡œì§€ìŠ¤í‹± í•¨ìˆ˜, ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ í˜•íƒœë¡œ í‘œí˜„

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-12 14 27 15](https://user-images.githubusercontent.com/79494088/129142837-26e4ce15-9827-4713-a4e4-95d57f6b2f19.png)

- ê¸°ì¤€ê°’ì€ 0.5
- ê²°ê³¼ì ìœ¼ë¡œ ê´€ì¸¡ì¹˜ê°€ íŠ¹ì • ê¸€ë˜ìŠ¤ì— ì†í•  í™•ë¥ ê°’ìœ¼ë¡œ ê³„ì‚°ëœë‹¤.
- ë¶„ë¥˜ë¬¸ì œì—ì„œëŠ” í™•ë¥ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜í•˜ëŠ”ë°, í™•ë¥ ê°’ì´ ì •í•´ì§„ ê¸°ì¤€ê°’ ë³´ë‹¤ í¬ë©´ 1 ì•„ë‹ˆë©´ 0ì´ë¼ê³  ì˜ˆì¸¡í•œë‹¤.

### Logit transformation
- ë¡œì§€ìŠ¤í‹±íšŒê·€ì˜ ê³„ìˆ˜ëŠ” ë¹„ì„ í˜• í•¨ìˆ˜ ë‚´ì— ìˆì–´ì„œ ì§ê´€ì ìœ¼ë¡œ í•´ì„í•˜ê¸° ì–´ë ¤ìš´ë°, ì˜¤ì¦ˆ(Odds)ë¥¼ ì‚¬ìš©í•˜ë©´ ì„ í˜•ê²°í•© í˜•íƒœë¡œ ë³€í™˜ ê°€ëŠ¥í•´ ë³´ë‹¤ ì‰½ê²Œ í•´ì„ì´ ê°€ëŠ¥í•˜ë‹¤. 
- ì˜¤ì¦ˆëŠ” ì‹¤íŒ¨í™•ë¥ ì— ëŒ€í•œ ì„±ê³µí™•ë¥ ì˜ ë¹„ì¸ë° ì˜ˆë¥¼ë“¤ì–´ ì˜¤ì¦ˆê°’ì´ 4ë©´, ì„±ê³µí™•ë¥ ì´ ì‹¤íŒ¨í™•ë¥ ì˜ 4ë°°ë¼ëŠ” ëœ»ì´ë‹¤.
- ë¶„ë¥˜ë¬¸ì œì—ì„œëŠ” í´ë˜ìŠ¤ 1 í™•ë¥ ì— ëŒ€í•œ í´ë˜ìŠ¤ 0 í™•ë¥ ì˜ ë¹„ë¼ê³  í•´ì„í•˜ë©´ ëœë‹¤. 
  - $Odds = \large \frac{p}{1-p}$, 
  - p = ì„±ê³µí™•ë¥ , 1-p = ì‹¤íŒ¨í™•ë¥ 
  - p = 1 ì¼ë•Œ odds = $\infty$
  - p = 0 ì¼ë•Œ odds = 0

  {% raw %} $$\large ln(Odds) = ln(\frac{p}{1-p}) = ln(\frac{\frac {1}{1+e^{-(\beta _{0}+\beta _{1}X_{1}+\cdots +\beta _{p}X_{p})}}}{1 - \frac {1}{1+e^{-(\beta _{0}+\beta _{1}X_{1}+\cdots +\beta _{p}X_{p})}}}) = \normalsize \beta _{0}+\beta _{1}X_{1}+\cdots +\beta _{p}X_{p}$$ {% endraw %}

- ë¡œì§“ë³€í™˜(Logit transformation) : ì˜¤ì¦ˆì— ë¡œê·¸ë¥¼ ì·¨í•´ ë³€í™˜í•˜ëŠ” ê²ƒ
- ë¡œì§“ë³€í™˜ì„ í†µí•´ ë¹„ì„ í˜•í˜•íƒœì¸ ë¡œì§€ìŠ¤í‹±í•¨ìˆ˜í˜•íƒœë¥¼ ì„ í˜•í˜•íƒœë¡œ ë§Œë“¤ì–´ íšŒê·€ê³„ìˆ˜ì˜ ì˜ë¯¸ë¥¼ í•´ì„í•˜ê¸° ì‰½ê²Œ í•˜ëŠ”ë°, íŠ¹ì„± Xì˜ ì¦ê°€ì— ë”°ë¼ ë¡œì§“(ln(oddx))ê°€ ì–¼ë§ˆë‚˜ ì¦ê°€oê°ì†Œ í–ˆë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤.<br>(odds í™•ë¥ ë¡œ í•´ì„ì„ í•˜ë ¤ë©´ exp(ê³„ìˆ˜) = p ë¥¼ ê³„ì‚°í•´ì„œ íŠ¹ì„± 1ë‹¨ìœ„ ì¦ê°€ë‹¹ í™•ë¥ ì´ pë°° ì¦ê°€í•œë‹¤ê³  í•´ì„ì„ í•  ìˆ˜ ìˆë‹¤.)
- ê¸°ì¡´ ë¡œì§€ìŠ¤í‹±í˜•íƒœì˜ y ê°’ì€ 0~1ì˜ ë²”ìœ„ë¥¼ ê°€ì¡Œë‹¤ë©´ ë¡œì§“ì€ - âˆ  ~  âˆ  ë²”ìœ„ë¥¼ ê°€ì§„ë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-12 14 37 35](https://user-images.githubusercontent.com/79494088/129143684-d9045577-bc51-404b-9c38-a2ef8346e027.png)

# 4ï¸âƒ£ ë¡œì§€ìŠ¤í‹±íšŒê·€ vs ì„ í˜•íšŒê·€

```py
from sklearn.linear_model import LogisticRegression

logistic = LogisticRegression()
logistic.fit(X_train_imputed, y_train)

print('ê²€ì¦ì„¸íŠ¸ ì •í™•ë„', logistic.score(X_val_imputed, y_val)) # ë¶„ë¥˜ ì •í™•ë„ ë¦¬í„´

# ê²€ì¦ì„¸íŠ¸ ì •í™•ë„ 0.7130044843049327
# ê¸°ì¤€ëª¨ë¸ë³´ë‹¤ ì •í™•ë„ê°€ ë†’ê²Œ ë‚˜ì™”ë‹¤.

pred = logistic.predict(X_val_imputed) # ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
pred

'''
array([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,
       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
       0, 1, 0])
'''

logistic.predict(test_case) # ìœ„ì—ì„œ ë§Œë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‚¬ìš©

logistic.predict_proba(test_case) # í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ ê°’ í™•ì¸

# array([[0.01749669, 0.98250331]])

print(features)
print(logistic.coef_) # ë¡œì§€ìŠ¤í‹±íšŒê·€ì˜ ê³„ìˆ˜ í™•ì¸

'''
['Pclass', 'Age', 'Fare']
[[-0.90248227 -0.03581619  0.00447486]]
'''

# ì„ í˜•íšŒê·€ë¶„ì„ê³¼ ë¹„êµí–ˆì„ ë•Œ íšŒê·€ê³„ìˆ˜ ìˆ˜ì¹˜ëŠ” ë³€í–ˆì§€ë§Œ ë°©í–¥ì€ ê°™ìŒì„ ë³¼ ìˆ˜ ìˆë‹¤.

```

## íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì‚¬ìš© ëª¨ë¸
- ëª¨ë¸ì— ì í•©í•˜ê¸° ì „ ë°ì´í„° ë³€í™˜ ìˆ˜í–‰
  - OneHotEncoder
  - SimpleImputer
  - StandardScaler

```py
train.columns

'''
Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],
      dtype='object')
'''

train['Ticket'].value_counts() # ì‚¬ìš©ê°€ëŠ¥í•œ ë²”ì£¼ í™•ì¸

'''
347088              6
S.O.C. 14879        5
CA. 2343            5
382652              5
3101295             5
                   ..
STON/O2. 3101271    1
2693                1
345572              1
SCO/W 1585          1
315086              1
Name: Ticket, Length: 539, dtype: int64
'''
```

- ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë³€ìˆ˜ë¥¼ ì„ íƒ : `['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']`
- `PassengerId`, `Name`, `Cabin`, `Ticket`ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì´ìœ 
  - ì•„ì´ë””ë‚˜ ì´ë¦„ ê°™ì€ íŠ¹ì„±ì„ ê°€ì§„ ê²ƒë“¤ì€ ìƒ˜í”Œë³„ë¡œ ëª¨ë‘ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ì¼ë°˜í™”ë¥¼ í•˜ê¸°ìœ„í•œ ê²ƒì— ë„ì›€ì´ ë˜ì§€ ì•ŠìŒ
  - ìºë¹ˆì€ ë²”ì£¼ì˜ ì¢…ë¥˜ ë„ˆë¬´ ë§ê³  ê²°ì¸¡ì¹˜ê°€ ë§ë‹¤.
  - í‹°ì¼“ë„ ë²”ì£¼ ì¢…ë¥˜ê°€ ë„ˆë¬´ ë§ë‹¤.
- ì‚¬ìš©í•˜ê³ ìí•˜ëŠ” íŠ¹ì„±ì— ëŒ€í•´ vaue_countsë¡œ ë²”ì£¼ë¥¼ í™•ì¸í•´ì•¼ í•œë‹¤.

```py
from category_encoders import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
target = 'Survived'

X_train = train[features]
y_train = train[target]

X_val = val[features]
y_val = val[target]


# ì›í•«ì¸ì½”ë”©
encoder = OneHotEncoder(use_cat_names=True)
X_train_encoded = encoder.fit_transform(X_train) 
X_val_encoded = encoder.transform(X_val) # fit ì•ˆí•˜ëŠ” ì´ìœ  : ê²€ì¦ì…‹ì—ì„œ ì–´ë– í•œ ë²”ì£¼ê°€ ë¶€ì¡±í•˜ë©´ ë¬¸ì œê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤.


# ê²°ì¸¡ì¹˜ í‰ê· ìœ¼ë¡œ ë³€í™˜
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train_encoded)
X_val_imputed = imputer.transform(X_val_encoded)


# íŠ¹ì„±ê°’ë“¤ì„ í‘œì¤€í™”
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_imputed)
X_val_scaled = scaler.transform(X_val_imputed)


X_train_scaled.T[0].mean(), X_train_scaled.T[0].std()
# í‰ê· ì€ 0, í‘œì¤€í¸ì°¨ëŠ” 1ë¡œ í‘œì¤€í™”


model = LogisticRegression(random_state=1)
model.fit(X_train_scaled, y_train) # LogisticRegression(random_state=1)


# ì •í™•ë„ í™•ì¸
y_pred = model.predict(X_val_scaled)
accuracy_score(y_val, y_pred) # 0.7892376681614349


# ê³„ìˆ˜ í™•ì¸
coefficients = pd.Series(model.coef_[0], X_train_encoded.columns)
coefficients
'''
Pclass         -0.915833
Sex_female      0.662095
Sex_male       -0.662095
Age            -0.559957
SibSp          -0.406466
Parch          -0.015897
Fare            0.078016
Embarked_S     -0.094939
Embarked_Q      0.007684
Embarked_C      0.077224
Embarked_nan    0.188837
dtype: float64
'''

# ì‹œê°í™”
coefficients.sort_values().plot.barh();
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-12 14 51 50](https://user-images.githubusercontent.com/79494088/129144978-e0ffe0e3-e956-4542-b98b-932711ca2475.png)

```py
model.intercept_ # array([-0.71320882])

# ì ˆí¸(intercept)ì€ ë§ˆì´ë„ˆìŠ¤ë¡œ ëª¨ë“  íŠ¹ì„±ì´ 0ì¸ ê²½ìš° ìƒì¡´í•˜ì§€ ëª»í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  ì•Œë ¤ì£¼ê¸´ í•˜ì§€ë§Œ 
# ì‚¬ì‹¤ ê´€ì¸¡í•  ìˆ˜ ì—†ëŠ” ì˜ˆì‹œë¡œ í•´ì„ì´ í¬ê²Œ ìœ ìš©í•˜ì§€ ì•Šë‹¤.
```

### ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ì„¸íŠ¸ì— ì ìš© í›„ ìºê¸€ì— ì œì¶œ

```py
X_test = test[features]
X_test_encoded = encoder.transform(X_test)
X_test_imputed = imputer.transform(X_test_encoded)
X_test_scaled = scaler.transform(X_test_imputed)

y_pred_test = model.predict(X_test_scaled)


submission = test[['PassengerId']].copy()
submission['Survived'] = y_pred_test
submission
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-12 14 54 37](https://user-images.githubusercontent.com/79494088/129145231-53659c4b-b08e-4d13-b846-77128d4e7a3d.png)

```py
submission.to_csv('submission_titanic.csv', index=False)
```