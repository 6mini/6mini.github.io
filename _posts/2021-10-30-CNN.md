---
title: '[Deep Learning]CNN'
description: 작성 중
categories:
 - Deep Learning
tags: [Deep Learning]
mathjax: enable
---

# 합성곱 연산과 이미지 필터

## 아날로그 신호 처리

![image](https://user-images.githubusercontent.com/79494088/139516870-59ba3190-3ef1-404f-a0ec-8092a8a4478f.png)


- 선형 시불변 시스템(Linear Time Invariant System; LTI System): LTI 시스템은 선형적이고 시간에 영향을 받지 않는 신호처리 시스템이다.
- 아날로그 시스템은 비인간적인 시스템이다.

## Dirac 델타 함수

![image](https://user-images.githubusercontent.com/79494088/139516961-5c8b3b09-0e70-4a2c-ba39-4237c711ce4a.png)

- $t$ = 0을 제외한 모든 위치에서 출력이 0이다.
- 모든 구간에서 적분한 값이 1 이다.

## 임펄스 응답

![image](https://user-images.githubusercontent.com/79494088/139517005-8e8c526e-2ac7-4a98-8f21-5ffb53a60d96.png)

- LTI 시스템에 임펄스(Dirac 델타 함수)를 입력했을 때의 출력을 임펄스 응답이라고 한다.
- 임펄스 응답을 필터(Filter)라고도 하며, LTI 시스템의 동작을 완전하게 표현한다.

## Convolution(합성곱 연산)

![image](https://user-images.githubusercontent.com/79494088/139517082-bfd96c29-7ed2-4c54-84ff-ed3aa7bf133b.png)

- 두 함수를 합성하는 합성곱 연산은 한 함수를 뒤집고 이동하면서, 두 함수의 곱을 적분하여 계산한다.

## Convolution과 LTI 시스템

![image](https://user-images.githubusercontent.com/79494088/139517187-f984806d-bd97-4d1c-9a78-817a8f48cf3b.png)

- LTI 시스템은 입력 신호에 임펄스 응답을 합성곱(Convolution)한 결과와 같다.

## 2차원 신호와 흑백 이미지

![image](https://user-images.githubusercontent.com/79494088/139517211-642e2bdb-93e5-4b6f-b33d-bf3d1f484b79.png)

- 흑백 영상은 각 픽셀 0~1 사이의 실수로 된 2-D Signal로 표현할 수 있다.

## 2차원 신호와 컬러 이미지

![image](https://user-images.githubusercontent.com/79494088/139517265-1a53ed0e-6c19-4f91-bc0c-b1d972fd914f.png)

- 컬러 영상은 RGB의 3채널로 구성된 2-D Siganl로 표현할 수 있다.


## 영상의 합성곱 계산

![image](https://user-images.githubusercontent.com/79494088/139517351-14cf51d2-43e0-46ed-958e-a30f1b56b07b.png)

- 2D 디지털 신호의 합성곱은 필터를 한 칸씩 옮기면서 영상과 겹치는 부분을 모두 곱해 합치면 된다.

### 잡음 제거 필터

![image](https://user-images.githubusercontent.com/79494088/139517396-09b87990-461a-48b1-84f5-bfe84ccec019.png)

- 2D Gaussian Filter를 적용하면 흐려진 영상을 얻을 수 있다.
- 영상이 흐려지는 대신, 잡음을 제거하는 특성이 있다.

### 미분 필터

![image](https://user-images.githubusercontent.com/79494088/139517421-fa1e759a-cd63-48f6-b32e-9d728b63bac6.png)

- Sobel Filter를 적용하면 특정 방향으로 미분한 영상을 얻을 수 있다.
- 해당 방향의 Edge 성분을 추출하는 특성이 있다.

# 합성곱 계층

## 뉴런

![image](https://user-images.githubusercontent.com/79494088/139517446-dda3fc92-64bd-4233-a85b-b11cd6266658.png)

## 곱에서 합성곱으로

- 입력 뉴런 대신 입력 영상을, 가중치 대신 필터를, 곱 대신 합성 곱을 사용하면 된다.
- 편향은 그대로 동일하게 유지된다.
 
## 전결합 계층(Fully Connected Layer)

![image](https://user-images.githubusercontent.com/79494088/139520924-7265a7ca-86e2-4826-b420-95b2ae2b6a6e.png)

## 합성곱 계층(Convorutional Layer)

![image](https://user-images.githubusercontent.com/79494088/139520943-8de1798c-6b35-421a-9329-5ba2d304c0e6.png)

- 합성곱으로 이루어진 뉴런을 전결합 형태로 연결한 것을 합성곱 계층이라고 한다.
- 합성곱 계층은 주로 우측에 있는 방식으로 쉽게 표현된다.

### 합성곱 계층의 의미

![image](https://user-images.githubusercontent.com/79494088/139521060-7abade86-08cb-4a48-8a27-90acbc42914b.png)

# 기본적인 합성곱 신경망

## 합성곱 신경망의 기본 구조

![image](https://user-images.githubusercontent.com/79494088/139521086-71fefca5-af46-43ba-8d24-73ecb1d6d1ff.png)

- 특정 모양을 포착하는 것이 합성곱 계층의 의미이다.

### 합성곱 계층
- 합성곱 계층에서 영상의 크기는 그대로이며, 영상의 채널 수가 달라진다.
- 합성곱 계층에 의해서 추출된 결과는 공간적 특징이 있으며 특징 맵(Feature Map)이라고 한다.

### 풀링 계층(Pooling Layer)

![image](https://user-images.githubusercontent.com/79494088/139521210-0c43685a-da8b-4e79-b3be-a945c62dbebe.png)

- 풀링 계층은 여러 화소를 종합하여 하나의 화소로 변환하는 계층이다.
- 풀링 계층을 통과하면 영상의 크기가 줄어들고, 정보가 종합된다.

![image](https://user-images.githubusercontent.com/79494088/139521282-5702a89c-5a9e-42c2-9eb5-a6a3e79d0c82.png)

- 풀링 방법은 다양하지만, 가장 많이 쓰이는 방법은 최댓값과 평균값이다.
- 합성곱 신경망의 애플리케이션에 맞는 풀링 계층을 사용한다.

### 평탄화(Flatten)

![image](https://user-images.githubusercontent.com/79494088/139521374-b9709bbd-5e19-4a5e-8272-78b90a38e5f1.png)

- 입력된 특징 맵의 모든 화소를 나열하여 하나의 벡터로 만드는 것을 평탄화라고 한다.
- 아무 연산도 일어나지 않으며, 합성곱 게층과 전결합 계층을 연결하는 역할을 한다.

### 전결합 계층(Fully Connected Layer)

![image](https://user-images.githubusercontent.com/79494088/139521603-301f9307-2ffd-45b9-bfaa-d57c6821801b.png)

- 2개의 전결합 계층을 사용하여 최종 출력을 내어 준다.
- 이 과정은 합성곱 신경망으로 추출한 특징을 입력으로 얕은 신경망을 사용하는 것과 같다.

### Softmax

![image](https://user-images.githubusercontent.com/79494088/139521708-56860457-5f63-4bb0-bdcd-e7ec494c75e1.png)

- 다중 클래스 분류 문제를 해결하기 위해 마지막 계층에는 Softmax 활성 함수를 사용한다.

### 이런 구조를 쓰는 이유
- 합성곱 계층을 통해 같은 크기의 필터가 영상에서 더 넓은 영역을 커버한다.
- 풀링 계층을 통해 N번 반복하면서 특징 맵의 크기가 줄어든다.

#### Receptive Field

![image](https://user-images.githubusercontent.com/79494088/139521769-3c8e460d-3daf-4269-ad8a-36e4f457e518.png)

- 같은 크기의 필터여도, 풀링에 의해 작아진 특징 맵에 적용되면 원본 영상에서 차지하는 범위가 넓은데 이 범위를 Receptive Field라고 한다.

## Exemple

### LeNet-5

![image](https://user-images.githubusercontent.com/79494088/139521839-e84de290-8576-4c9a-befa-61d01b96b8f8.png)

- 98년도 상당히 이른 시기에 CNN의 기본 구조를 잘 정립했다.

### VGG-16

![image](https://user-images.githubusercontent.com/79494088/139521850-faecf708-0fd9-41bf-99fd-56de6b0bae74.png)

- 2014년도 ILSVRC에서 TOP-5 정확도 92.7%를 기록했다.

# 합성곱 신경망의 심화 이해 

## 합성곱 계층의 필요성

![image](https://user-images.githubusercontent.com/79494088/139522073-73c22b7f-e9de-4cc0-b3d8-9d5891287a75.png)

- 전결합 계층을 바로 해도 될 것 같은데 합성곱 계층을 하는 이유는 연산이 어마어마해지기 때문이다.

## 전결합 계층의 수학적 표현

![image](https://user-images.githubusercontent.com/79494088/139524605-99d135da-f394-4344-a8cf-ff6ee2850589.png)


## 합성곱 계층의 수학적 표현

![image](https://user-images.githubusercontent.com/79494088/139525091-5207bda8-68ef-41c1-a417-1e7e025f548e.png)

- 합성곱계층은 $C_{in} * C_{out}$번의 합성곱 연산으로 이루어져 있다.
- 편향은 전결합 계층과 동일하게 하나의 벡터로 이루어진다.

