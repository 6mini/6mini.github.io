---
title: '[Tree Based Model] ëœë¤í¬ë ˆìŠ¤íŠ¸(Random Forests)'
description: ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ ì´í•´í•˜ê³  ë¬¸ì œì— ì ìš©í•˜ë©° ìˆœì„œí˜•ì¸ì½”ë”©(Ordinal encoding)ê³¼ ì›í•« ì¸ì½”ë”©ì„ êµ¬ë¶„í•œë‹¤. ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ì¸ì½”ë”© ë°©ë²•ì´ íŠ¸ë¦¬ëª¨ë¸ê³¼ ì„ í˜•íšŒê·€ ëª¨ë¸ì— ì£¼ëŠ” ì˜í–¥ì„ ì´í•´í•œë‹¤.
categories:
 - Machine Learning
tags: [Machine Learning, Tree Based Model, Random Forests, Ordinal encoding, ëœë¤í¬ë ˆìŠ¤íŠ¸, ìˆœì„œí˜•ì¸ì½”ë”©]
mathjax: enable
# 0ï¸âƒ£1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£7ï¸âƒ£8ï¸âƒ£9ï¸âƒ£ğŸ”Ÿ
---

# EDA

## Decision Tree Data ì‚¬ìš©
- [Decision Tree ì´ìš© ëª¨ë¸ë§ ë°”ë¡œê°€ê¸°](https://6mini.github.io/machine%20learning/2021/08/17/didunk-decision-tree/)

```py
# Data import
target = 'vacc_h1n1_f'
train = pd.merge(pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train.csv'), 
                 pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train_labels.csv')[target], left_index=True, right_index=True)
test = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/test.csv')
sample_submission = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/submission.csv')

# í›ˆë ¨/ê²€ì¦ ë¶„ë¦¬
from sklearn.model_selection import train_test_split
train, val = train_test_split(train, train_size=0.80, test_size=0.20, 
                              stratify=train[target], random_state=2)


train.shape, val.shape, test.shape
'''
((33723, 39), (8431, 39), (28104, 38))
'''

# ì• ì „ í•¨ìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
def engineer(df):
    """íŠ¹ì„±ì„ ì—”ì§€ë‹ˆì–´ë§ í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    
#     ë†’ì€ ì¹´ë””ë„ë¦¬í‹°ë¥¼ ê°€ì§€ëŠ” íŠ¹ì„±ì„ ì œê±°í•©ë‹ˆë‹¤.
#     selected_cols = df.select_dtypes(include=['number', 'object'])
#     colnames = selected_cols.columns.tolist()
#     labels = selected_cols.nunique()
    
#     selected_features = labels[labels <= 30].index.tolist()
#     df = df[selected_features]
    
    # ìƒˆë¡œìš´ íŠ¹ì„±ì„ ìƒì„±í•©ë‹ˆë‹¤.
    behaviorals = [col for col in df.columns if 'behavioral' in col] 
    df['behaviorals'] = df[behaviorals].sum(axis=1)
    
    
    dels = [col for col in df.columns if ('employment' in col or 'seas' in col)]
    df.drop(columns=dels, inplace=True)
        
    return df


train = engineer(train)
val = engineer(val)
test = engineer(test)

# íŠ¹ì„±/íƒ€ê²Ÿ ë¶„ë¦¬
features = train.drop(columns=[target]).columns

X_train = train[features]
y_train = train[target]
X_val = val[features]
y_val = val[target]
X_test = test[features]
```

# Random Forests

```py
%%time
from category_encoders import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer 
from sklearn.pipeline import make_pipeline

pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True), 
    SimpleImputer(), 
    RandomForestClassifier(n_jobs=-1, random_state=10, oob_score=True)
)
# n_jobs=-1 : ì‹¤í–‰ë˜ê³  ìˆëŠ” ì»´í“¨í„° í™˜ê²½ì—ì„œ ê°€ìš©í•œ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ì˜µì…˜
#  ì˜¤ë¹„ ìŠ¤ì½”ì–´ : ì•„ë˜ì—ì„œ ë‹¤ì‹œ ì •ë¦¬

pipe.fit(X_train, y_train)
print('ê²€ì¦ ì •í™•ë„: ', pipe.score(X_val, y_val))
'''
ê²€ì¦ ì •í™•ë„:  0.8265923378009726
CPU times: user 10 s, sys: 494 ms, total: 10.5 s
Wall time: 2.96 s
'''
```

## ëœë¤í¬ë ˆìŠ¤íŠ¸ëŠ” ì•™ìƒë¸”(Ensemble) ë°©ë²•

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-18 10 24 53](https://user-images.githubusercontent.com/79494088/129821710-9bf9c6d8-1bc9-4482-97d0-b7068fb63370.png)

- ì•™ìƒë¸” : í•œ ì¢…ë¥˜ì˜ ë°ì´í„°ë¡œ ì—¬ëŸ¬ ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµëª¨ë¸(Week base learner, ì‘ì€ ì—¬ëŸ¬ê°œì˜ ëª¨ë¸, ê¸°ë³¸ëª¨ë¸)ì„ ë§Œë“¤ì–´ ê·¸ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ê²°ê³¼ë¥¼ **ë‹¤ìˆ˜ê²°ì´ë‚˜ í‰ê· **ì„ ë‚´ì–´ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•(ì´ë¡ ì ìœ¼ë¡œ ê¸°ë³¸ëª¨ë¸ ëª‡ê°€ì§€ ì¡°ê±´ì„ ì¶©ì¡±í•˜ëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.)
- ëœë¤í¬ë ˆìŠ¤íŠ¸ëŠ” ê²°ì •íŠ¸ë¦¬ë¥¼ ê¸°ë³¸ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ëŠ” **ì•™ìƒë¸” ë°©ë²•**ì´ë‹¤.
- ê²°ì •íŠ¸ë¦¬ë“¤ì€ **ë…ë¦½ì **ìœ¼ë¡œ ë§Œë“¤ì–´ì§€ë©° ê°ê° ëœë¤ìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ì„±ëŠ¥ë³´ë‹¤ ì¢‹ì„ ê²½ìš° ëœë¤í¬ë ˆìŠ¤íŠ¸ëŠ” ê²°ì •íŠ¸ë¦¬ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ë‹¤.

## How make ëœí¬'s ê¸°ë³¸ëª¨ë¸

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-18 10 32 43](https://user-images.githubusercontent.com/79494088/129822315-f8a0f663-183b-4a6b-ab8f-745b9db5d892.png)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-18 10 33 15](https://user-images.githubusercontent.com/79494088/129822355-143ffc06-1f7c-40b1-a8b3-c07db6d5b081.png)

- ê°ê°ì˜ ë¶€íŠ¸ìŠ¤íŠ¸ë©ì´ë¼ëŠ” ìƒ˜í”Œì„ í†µí•´ í•™ìŠµì´ ë˜ëŠ”ë° ì´ë ‡ê²Œ ëª¨ë¸ë§ì„ í•˜ê³  í•©ì¹˜ëŠ” ê³¼ì •ì„ ë°°ê¹…(Bagging, Bootstrap Aggregating)ì´ë¼ê³  í•œë‹¤.

## Bootstrap Sampling

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-18 10 36 14](https://user-images.githubusercontent.com/79494088/129822591-e2bbcad3-2c70-4075-b613-c1ec059a38a2.png)

- ì•™ìƒë¸”ì— ì‚¬ìš©í•˜ëŠ” ì‘ì€ ëª¨ë¸ë“¤ì€ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘(Bootstraping)ì´ë¼ëŠ” ìƒ˜í”Œë§ ê³¼ì •ìœ¼ë¡œ ì–»ì€ ë¶€íŠ¸ìŠ¤íŠ¸ë©ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•´ í•™ìŠµí•œë‹¤.
- ì›ë³¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œë§ì„ í•  ë•Œ ë³µì›ì¶”ì¶œì„ í•œë‹¤ëŠ” ê²ƒì¸ë°, ë³µì›ì¶”ì¶œì€ ìƒ˜í”Œì„ ë½‘ì•„ ê°’ì„ ê¸°ë¡í•˜ê³   ì œìë¦¬ì— ëŒë ¤ë†“ëŠ” ê²ƒì„ ë§í•œë‹¤.
- ìƒ˜í”Œë§ì„ íŠ¹ì •í•œ ìˆ˜ë§Œí¼ ë°˜ë³µí•˜ë©´ í•˜ë‚˜ì˜ ë¶€íŠ¸ìŠ¤íŠ¸ë ™ ì„¸íŠ¸ê°€ ì™„ì„±ëœë‹¤.
- ë³µì›ì¶”ì¶œì´ê¸° ë•Œë¬¸ì— ë¶€íŠ¸ìŠ¤íŠ¸ë©ì„¸íŠ¸ì—ëŠ” ê°™ì€ ìƒ˜í”Œì´ ë°˜ë³µë  ìˆ˜ ìˆë‹¤.
- Training Setì—ì„œ ë½‘íˆì§€ ì•Šì€ ìƒ˜í”Œë“¤ì´ Test Setì— ìˆëŠ”ë° ì´ Test Setì„ ê¸°ë³¸ëª¨ë¸ì„ ê²€ì¦í•  ë•Œ ì‚¬ìš©í•˜ê³  ì´ ì„¸íŠ¸ë¥¼ **OB Set**ì´ë¼ í•œë‹¤.
- ë¶€íŠ¸ìŠ¤íŠ¸ë©ì„¸íŠ¸ì˜ í¬ê¸°ê°€ nì´ë¼ í•  ë•Œ í•œ ë²ˆì˜ ì¶”ì¶œê³¼ì •ì—ì„œ ì–´ë–¤ í•œ ìƒ˜í”Œì´ ì¶”ì¶œ ë˜ì§€ ì•Šì„ í™•ë¥ 

$$\displaystyle \frac {n-1}{n}$$

- níšŒ ë³µì›ì¶”ì¶œì„ ì§„í–‰í–ˆì„ ë•Œ ê·¸ ìƒ˜í”Œì´ ì¶”ì¶œë˜ì§€ ì•Šì•˜ì„ í™•ë¥ 

$$\displaystyle \left({\frac {n-1}{n}}\right)^{n}$$

- nì„ ë¬´í•œíˆ í¬ê²Œ í–ˆì„ ë•Œ ì´ ì‹

$$\displaystyle \lim _{{n\to \infty }}\left({1 - \frac {1}{n}}\right)^{n} = e^{-1} = 0.368$$

- ì°¸ê³ 

$$\displaystyle e =  \lim _{{n\to \infty }}\left(1+{\frac  {1}{n}}\right)^{n}$$

- ì¦‰ ë°ì´í„°ê°€ ì¶©ë¶„íˆ í¬ë‹¤ê³  ê°€ì •í–ˆì„ ë•Œ í•œ ë¶€íŠ¸ìŠ¤íŠ¸ë©ì„¸íŠ¸ëŠ” **í‘œë³¸ì˜ 63.2%** ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ê°€ì§„ë‹¤.
- ì—¬ê¸°ì„œ ì¶”ì¶œë˜ì§€ ì•Šì€ 36.8%ì˜ ìƒ˜í”Œì´ Out Of Bag ìƒ˜í”Œì´ë©° ì´ê²ƒì„ ì‚¬ìš©í•´ ëª¨ë¸ì„ ê²€ì¦í•  ìˆ˜ ìˆë‹¤.

```py
pipe.named_steps['randomforestclassifier'].oob_score_
'''
0.8188180173768644
'''
```

## Aggregation
- **Aggregation** : ë¶€íŠ¸ìŠ¤íŠ¸ë©ì„¸íŠ¸ë¡œ ë§Œë“¤ì–´ì§„ ê¸°ë³¸ëª¨ë¸(Weak learner, ì‘ì€ ëª¨ë¸ë“¤)ë“¤ì„ í•©ì¹˜ëŠ” ê³¼ì •
  - íšŒê·€ë¬¸ì œ : ê¸°ë³¸ëª¨ë¸ ê²°ê³¼ë“¤ì˜ **í‰ê· **
  - ë¶„ë¥˜ë¬¸ì œ : ë‹¤ìˆ˜ê²°ë¡œ ê°€ì¥ ë§ì€ ëª¨ë¸ë“¤ì´ ì„ íƒí•œ **ë²”ì£¼**

## Random Select
- ëœë¤í¬ë ˆìŠ¤íŠ¸ëŠ” ê¸°ë³¸ëª¨ë¸ë“¤ì˜ íŠ¸ë¦¬ë¥¼ ë§Œë“¤ ë•Œ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•œ íŠ¹ì„±ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•œë‹¤.
- ê¸°ë³¸ëª¨ë¸ íŠ¸ë¦¬ë¥¼ ë§Œë“¤ ë•Œ ì¼ë°˜ ê²°ì •íŠ¸ë¦¬ ì•Œê³ ë¦¬ì¦˜ê³¼ ë‹¤ë¥¸ì 
  - íšŒê·€ë¬¸ì œì¼ ê²½ìš° ê¸°ë³¸ëª¨ë¸ ê²°ê³¼ë“¤ì˜ **í‰ê· **ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë‚¸ë‹¤.
  - ë¶„ë¥˜ë¬¸ì œì¼ ê²½ìš° **ë‹¤ìˆ˜ê²°**ë¡œ ê°€ì¥ ë§ì€ ëª¨ë¸ë“¤ì´ ì„ íƒí•œ ë²”ì£¼ë¡œ ì˜ˆì¸¡í•œë‹¤.

# ìˆœì„œí˜•(Ordinal) ì¸ì½”ë”©
- ìˆœì„œí˜• ì¸ì½”ë”©ì€ ë²”ì£¼ì— ìˆ«ìë¥¼ mappingí•œë‹¤.
  - [a, b, c] ì„¸ ë²”ì£¼ê°€ ìˆë‹¤ë©´ ì´ê²ƒì„ [1, 2, 3] ì´ë ‡ê²Œ ìˆ«ìë¡œ ì¸ì½”ë”©í•œë‹¤.
- íŠ¸ë¦¬êµ¬ì¡° í•™ìŠµì—ì„œ ì›í•«ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ë©´ ë¬¸ì œê°€ ìˆë‹¤.
  - íŠ¸ë¦¬êµ¬ì¡°ì—ì„œëŠ” ì¤‘ìš”í•œ íŠ¹ì„±ì´ ìƒìœ„ ë…¸ë“œì—ì„œ ë¨¼ì € ë¶„í• ì´ ì¼ì–´ë‚œë‹¤.
  - ë²”ì£¼ ì¢…ë¥˜ê°€ ë§ì€(high cardinality) íŠ¹ì„±ì€ ì›í•«ì¸ì½”ë”©ìœ¼ë¡œ ì¸í•´ ìƒìœ„ë…¸ë“œì—ì„œ ì„ íƒë  ê¸°íšŒê°€ ì ì–´ì§„ë‹¤.
  - ì›í•«ì¸ì½”ë”© ì˜í–¥ì„ ì•ˆ ë°›ëŠ” ìˆ˜ì¹˜í˜• íŠ¹ì„±ì´ ìƒìœ„ë…¸ë“œë¥¼ ì°¨ì§€í•  ê¸°íšŒê°€ ë†’ì•„ì§€ê³  ì „ì²´ì ì¸ ì„±ëŠ¥ ì €í•˜ê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤.
  - íŠ¸ë¦¬ëª¨ë¸ì—ì„œëŠ” ìˆœì„œì •ë³´ê°€ ìƒê´€ì—†ì–´ì„œ ìˆœì„œí˜•ì„ ì‚¬ìš©í•´ë„ ê´œì°®ë‹¤.
  - ë§Œì•½ Featureê°€ 30ê°œë¼ë©´ ê°€ì¹˜ê°€ 30ê°œë¡œ ë¶„ì‚°ë˜ì–´ì„œ ì„¤ëª…ë ¥ì´ ì ì–´ì§„ë‹¤.

## Mapping í™•ì¸

```py
from category_encoders import OrdinalEncoder

enc = OrdinalEncoder(handle_missing="value")
X = [['Male', 1, 'Yes'], ['Female', 3, 'No'], ['Female', 2, 'None']]
enc.fit(X)
'''
OrdinalEncoder(cols=[0, 2],
               mapping=[{'col': 0, 'data_type': dtype('O'),
                         'mapping': Male      1
Female    2
NaN      -2
dtype: int64},
                        {'col': 2, 'data_type': dtype('O'),
                         'mapping': Yes     1
No      2
None    3
NaN    -2
dtype: int64}])
'''

# transform ì‚¬ìš©í•´ì„œ ë°ì´í„° ì£¼ì…
enc.transform([['Male',1,'No'],['Female', 10]])
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-18 14 22 40](https://user-images.githubusercontent.com/79494088/129841786-b875379d-7ef0-4723-b4c8-bca4437e1178.png)

```py
enc.category_mapping
'''
[{'col': 0,
  'mapping': Male      1
  Female    2
  NaN      -2
  dtype: int64,
  'data_type': dtype('O')},
 {'col': 2,
  'mapping': Yes     1
  No      2
  None    3
  NaN    -2
  dtype: int64,
  'data_type': dtype('O')}]
'''
```

## H1N1 Dataì—ì„œ í™•ì¸
- ì‹¤í–‰ì†ë„ ë³€í™” ë¹„êµ

```py
%%time

# ordinal encoding
pipe_ord = make_pipeline(
    OrdinalEncoder(), 
    SimpleImputer(), 
    RandomForestClassifier(random_state=10, n_jobs=-1, oob_score=True)
)

pipe_ord.fit(X_train, y_train)
print('ê²€ì¦ ì •í™•ë„', pipe_ord.score(X_val, y_val))
'''
ê²€ì¦ ì •í™•ë„ 0.8254062388803226
CPU times: user 5.23 s, sys: 242 ms, total: 5.47 s
Wall time: 1.38 s
'''

# íŠ¹ì„±ì˜ ìˆ˜ ë¹„êµ(Onhot vs Ordinal)
print('Shape  before: ', X_train.shape)

# OneHotEncoder
enc = pipe.named_steps['onehotencoder']
encoded = enc.transform(X_train)
print('OneHot  shape: ', encoded.shape)

# OrdinalEncoder
enc = pipe_ord.named_steps['ordinalencoder']
encoded = enc.transform(X_train)
print('Ordinal shape: ', encoded.shape)
'''
Shape  before:  (33723, 32)
OneHot  shape:  (33723, 108)
Ordinal shape:  (33723, 32)
'''
```

## Random Forests íŠ¹ì„± ì¤‘ìš”ë„ ë¹„êµ
- ëœë¤í¬ë ˆìŠ¤íŠ¸ì—ì„œëŠ” í•™ìŠµ í›„ì˜ íŠ¹ì„±ë“¤ì˜ ì¤‘ìš”ë„ ì •ë³´(Gini importance)ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì œê³µí•œë‹¤.
- ì¤‘ìš”ë„ëŠ” ë…¸ë“œë“¤ì˜ ì§€ë‹ˆë¶ˆìˆœë„(Gini impurity)ë¥¼ ê°€ì§€ê³  ê³„ì‚°í•œë‹¤.
- **ë…¸ë“œê°€ ì¤‘ìš”í• ìˆ˜ë¡ ë¶ˆìˆœë„ê°€ í¬ê²Œ ê°ì†Œí•œë‹¤.**
- ë…¸ë“œëŠ” í•œ íŠ¹ì„±ì˜ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬ë˜ê¸° ë•Œë¬¸ì— ë¶ˆìˆœë„ë¥¼ í¬ê²Œ ê°ì†Œí•˜ëŠ”ë° ë§ì´ ì‚¬ìš©ëœ íŠ¹ì„±ì´ ì¤‘ìš”ë„ê°€ ì˜¬ë¼ê°ˆ ê²ƒì´ë‹¤.

```py
import matplotlib.pyplot as plt

# íŠ¹ì„± ì¤‘ìš”ë„(onehot)
rf = pipe.named_steps['randomforestclassifier']
colnames = pipe.named_steps['onehotencoder'].get_feature_names()
importances = pd.Series(rf.feature_importances_, colnames)

n = 10
plt.figure(figsize=(10,n/4))
plt.title(f'Top {n} features with onehotencoder')
importances.sort_values()[-n:].plot.barh();


# íŠ¹ì„± ì¤‘ìš”ë„(ordinal)
rf_ord = pipe_ord.named_steps['randomforestclassifier']
importances_ord = pd.Series(rf_ord.feature_importances_, X_train.columns)

plt.figure(figsize=(10,n/4))
plt.title(f'Top {n} features with ordinalencoder')
importances_ord.sort_values()[-n:].plot.barh();
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-18 14 36 22](https://user-images.githubusercontent.com/79494088/129843092-d9e37bb8-510a-4726-b828-d1ff22c0007b.png)

- ì´ ë‘ê°€ì§€ ì¸ì½”ë”© ë°©ë²•ì´ ì„ í˜• ëª¨ë¸ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ê¹Œ?

```py
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

pipe_lr = make_pipeline(
    OneHotEncoder(), 
    SimpleImputer(), 
    LogisticRegression(n_jobs=-1)
)
pipe_lr.fit(X_train, y_train)

print('ê²€ì¦ì„¸íŠ¸ ì •í™•ë„', pipe_lr.score(X_val, y_val))
'''
ê²€ì¦ì„¸íŠ¸ ì •í™•ë„ 0.8204246234135927
'''

pipe_lr = make_pipeline(
    OrdinalEncoder(), 
    SimpleImputer(),  
    LogisticRegression(n_jobs=-1)
)
pipe_lr.fit(X_train, y_train)

print('ê²€ì¦ì„¸íŠ¸ ì •í™•ë„', pipe_lr.score(X_val, y_val))
'''
ê²€ì¦ì„¸íŠ¸ ì •í™•ë„ 0.797532914245048
'''
```

- ìˆœì„œí˜•ì¸ì½”ë”©ì—ì„œ ì£¼ì˜í•´ì•¼ í•  ì ì€ ë²”ì£¼ë“¤ì„ ìˆœì„œê°€ ìˆëŠ” ìˆ«ìí˜•ìœ¼ë¡œ ë°”ê¾¸ë©´ ì›ë˜ ê·¸ ë²”ì£¼ì— ì—†ë˜ ìˆœì„œì •ë³´ê°€ ìƒê¸´ë‹¤.
- ìˆœì„œí˜•ì¸ì½”ë”©ì€ ë²”ì£¼ë“¤ ê°„ì˜ ë¶„ëª…í•œ ìˆœìœ„ê°€ ìˆì„ ë•Œ ê·¸ ì—°ê´€ì„±ì— ë§ê²Œ ìˆ«ìë¥¼ ì •í•´ì£¼ëŠ” ê²ƒì´ ì¢‹ë‹¤.
- ì˜¤ë””ë„ì¸ì½”ë”ë¡œ ë¬´ì‘ìœ„ë¡œ ìˆ˜ì¹˜ë¥¼ ì¸ì½”ë”©í–ˆì§€ë§Œ, ì •í™•í•œ ë²”ì£¼ì˜ ìˆœìœ„ë¥¼ ì•Œê³  ìˆë‹¤ë©´ `mapping` íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•´ ì§€ì •í•´ì¤„ ìˆ˜ ìˆë‹¤. 

# RFëª¨ë¸ì´ DTëª¨ë¸ëª¨ë‹¤ ìƒëŒ€ì ìœ¼ë¡œ ê³¼ì í•©ì„ í”¼í•  ìˆ˜ ìˆëŠ” ì´ìœ 
- ëœë¤í¬ë ˆìŠ¤íŠ¸ì˜ ëœë¤ì„±ì€ ë‘ê°€ì§€ì—ì„œ ë‚˜ì˜¨ë‹¤.
  - ëœë¤í¬ë ˆìŠ¤íŠ¸ì—ì„œ í•™ìŠµë˜ëŠ” íŠ¸ë¦¬ë“¤ì€ ë°°ê¹…ì„ í†µí•´ ë§Œë“¤ì–´ì§„ë‹¤.(`bootstrap = true`)ì´ë•Œ ê° ê¸°ë³¸íŠ¸ë¦¬ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ê°€ ëœë¤ìœ¼ë¡œ ì„ íƒëœë‹¤.
  - ê°ê° íŠ¸ë¦¬ëŠ” ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ íŠ¹ì„±ë“¤ì„ ê°€ì§€ê³  ë¶„ê¸°ë¥¼ ìˆ˜í–‰í•œë‹¤.(`max_features = auto`)
- ê²°ì •íŠ¸ë¦¬ëŠ” ë°ì´í„° ì¼ë¶€ì— ê³¼ì í•©í•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤.<br>
ê·¸ë˜ì„œ ë‹¤ë¥´ê²Œ ìƒ˜í”Œë§ëœ ë°ì´í„°ë¡œ ê³¼ì í•©ëœ íŠ¸ë¦¬ë¥¼ ë§ì´ ë§Œë“¤ê³  ê·¸ ê²°ê³¼ë¥¼ í‰ê·  ë‚´ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì´ ëœë¤í¬ë ˆìŠ¤íŠ¸ì´ë‹¤.
- ì´ë ‡ê²Œ í•˜ë©´ ê³¼ì í•©ì´ ì¤„ê³  ì„±ëŠ¥ì´ ìœ ì§€ëœë‹¤.

## ë¹„ì„ í˜• ê´€ê³„ì˜ ë°ì´í„°ë¥¼ ì í•©í•˜ëŠ” ëª¨ìŠµ

```py
columns = ['mobility', 'density']
data = [[80.574, -3.067]
,[84.248, -2.981]
,[87.264, -2.921]
,[87.195, -2.912]
,[89.076, -2.84]
,[89.608, -2.797]
,[89.868, -2.702]
,[90.101, -2.699]
,[92.405, -2.633]
,[95.854, -2.481]
,[100.696, -2.363]
,[101.06, -2.322]
,[401.672, -1.501]
,[390.724, -1.46]
,[567.534, -1.274]
,[635.316, -1.212]
,[733.054, -1.1]
,[759.087, -1.046]
,[894.206, -0.915]
,[990.785, -0.714]
,[1090.109, -0.566]
,[1080.914, -0.545]
,[1122.643, -0.4]
,[1178.351, -0.309]
,[1260.531, -0.109]
,[1273.514, -0.103]
,[1288.339, 0.01]
,[1327.543, 0.119]
,[1353.863, 0.377]
,[1414.509, 0.79]
,[1425.208, 0.963]
,[1421.384, 1.006]
,[1442.962, 1.115]
,[1464.35, 1.572]
,[1468.705, 1.841]
,[1447.894, 2.047]
,[1457.628, 2.2]]

thurber = pd.DataFrame(columns=columns, data=data)
X_thurber = thurber[['mobility']]
y_thurber = thurber['density']

%matplotlib inline
import matplotlib.pyplot as plt
from ipywidgets import interact
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor

def trees(max_depth=1, n_estimators=1):
    models = [DecisionTreeRegressor(max_depth=max_depth), 
              RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators)]
    
    for model in models:
        name = model.__class__.__name__
        model.fit(X_thurber, y_thurber)
        ax = thurber.plot('mobility', 'density', kind='scatter', title=name)
        ax.step(X_thurber, model.predict(X_thurber), where='mid')
        plt.show()
        
interact(trees, max_depth=(1,10,1), n_estimators=(10,50,10));
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-18 14 44 21](https://user-images.githubusercontent.com/79494088/129843853-4306ad9d-3163-46e4-820b-42acfd6df9f4.png)

## ëœë¤í¬ë ˆìŠ¤íŠ¸ ì•Œê³ ë¦¬ì¦˜
- ëœë¤í¬ë ˆìŠ¤íŠ¸ì˜ ì˜ì‚¬ì½”ë“œ(Pseudo code)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-18 14 45 22](https://user-images.githubusercontent.com/79494088/129843971-de466d0d-499a-4d9f-a487-ad52938cee40.png)