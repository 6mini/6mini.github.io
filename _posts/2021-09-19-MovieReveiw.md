---
title: 'Beautifulsoup Naver Movie Reveiw Web Scraping and Exeport SQLite in Python'
description: íŒŒì´ì¬ì„ ì´ìš©í•˜ì—¬ ë„¤ì´ë²„ ì˜í™”ì—ì„œ ë¦¬ë·°ì˜ í•œì¤„í‰ê³¼ ì ìˆ˜ë¥¼ beautifulsoupë¡œ ìŠ¤í¬ë˜í•‘í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ ë° í‰ê·  ì ìˆ˜ë¥¼ êµ¬í•˜ê³  SQLiteë¥¼ í†µí•´ DBë¥¼ ì €ì¥í•˜ëŠ” ê³¼ì •
categories:
 - Did Unknown
tags: [Did Unknown, Python, beautifulsoup, Naver Movie, Web Scraping, SQLite, íŒŒì´ì¬, ë„¤ì´ë²„ ì˜í™”, ìŠ¤í¬ë˜í•‘, í¬ë¡¤ë§]
mathjax: enable
# 0ï¸âƒ£1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£7ï¸âƒ£8ï¸âƒ£9ï¸âƒ£ğŸ”Ÿ
---

# 1ï¸âƒ£ Web Scraping
- ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ êµ¬í˜„
- TEST Movie : ìƒ¹ì¹˜ì™€ í… ë§ì¦ˆì˜ ì „ì„¤

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-09-17 17 25 47](https://user-images.githubusercontent.com/79494088/133750472-1b9b330e-1c78-43ec-acc9-4d4a5406c5c4.png)

```py
import requests
from bs4 import BeautifulSoup

BASE_URL = "https://movie.naver.com/movie"
```

## Page Parsing
- URLì„ ë°›ì•„ í˜ì´ì§€ ê°€ì ¸ì™€ì„œ íŒŒì‹±í•œ ë‘ ê²°ê³¼ ë¦¬í„´

```py
def get_page(page_url):
    page = requests.get(page_url)
    soup = BeautifulSoup(page.content, 'html.parser')
    return soup, page
```

## Movie Code

### ê²€ìƒ‰ í˜ì´ì§€ ì ‘ì†

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-09-17 17 28 27](https://user-images.githubusercontent.com/79494088/133750927-e73d4c47-5ea9-4188-842a-f1a4c6c5c82b.png)

### ì†ì„± í™•ì¸
- ê²€ì‚¬ë¥¼ í†µí•´ ê°€ì ¸ì™€ì•¼ í•  ì†ì„±ì„ í™•ì¸í•œë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-09-17 17 30 08](https://user-images.githubusercontent.com/79494088/133751200-095dc4f4-bc4a-4ae4-a148-5ee81c46f3e7.png)

- 'reult_thumb' classì—ì„œ hrefë¥¼ ê°€ì ¸ì™€ '='ë¡œ splití•œ ë’¤ ì¶”ì¶œí•œë‹¤.

```py
def get_movie_code(movie_title):
    search_url = f"{BASE_URL}/search/result.naver?query={movie_title}&section=all&ie=utf8"
    soup = get_page(search_url)[0]
    movie_code = int(soup.find(class_='result_thumb').find('a')['href'].split('=')[1])
    return movie_code

print(get_movie_code('ìƒ¹ì¹˜')) # 187348
```

## Review list ìƒì„±

### í˜ì´ì§€ ìœ„ì¹˜
- dictionary í˜•íƒœ

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-09-17 17 37 04](https://user-images.githubusercontent.com/79494088/133752178-f4cbda0c-41f7-4b51-9bca-87eaa563012e.png)

- 'title' classë¥¼ ëª¨ë‘ ê°€ì ¸ì™€ forë¬¸ìœ¼ë¡œ ì¶”ì¶œ
- text : textí™” ì‹œì¼œ '\n'ì„ ê¸°ì¤€ìœ¼ë¡œ splití•œ í›„ ì„ íƒ
- star : emì„ ê°€ì ¸ì™€ textë§Œ ì¶”ì¶œ í›„ intí™”

```py
def get_reviews(movie_code, page_num=1):
    review_url = f"{BASE_URL}/point/af/list.naver?st=mcode&sword={movie_code}&target=after&page={page_num}"
    review_list = []
    soup = get_page(review_url)[0] # ìœ„ì—ì„œ ë§Œë“  Get page í•¨ìˆ˜ ì¤‘ suopë§Œ ê°€ì ¸ì˜¤ê¸°
    for i in soup.find_all(class_='title'):
        review_list.append({
            'review_text': i.text.split('\n')[5],
            'review_star': int(i.find('em').text)
        })
    return review_list

print(get_reviews(get_movie_code('ìƒ¹ì¹˜')))
'''
[
{'review_text': '', 'review_star': 10},
{'review_text': 'CGì™€ BMWë¡œ ì–¼ë£©ì§„ ë§ˆë¸”íŒ *** â€˜ë½•â€™ ì˜í™” ', 'review_star': 6},
{'review_text': 'í‰ì´ ì•ˆì¢‹ì•„ì„œ ë³¼ê¹Œë§ê¹Œ í–ˆìœ¼ë‚˜ ê²°ë¡ ì ìœ¼ë¡œ ë‚œ ì¬ë°Œì—ˆë‹¤ ', 'review_star': 10},
{'review_text': 'ê°ë…ì´ *** ì•Œê³  ê¹Œë¼ ìŠ¤í† ë¦¬ê°€ ë³„ë¡œì•¼ ê·¸ëƒ¥ ìº¡ë§ˆê°™ì•„ ', 'review_star': 6},
{'review_text': '***', 'review_star': 7},
{'review_text': 'ë§ˆë¸”ì´ ë§ˆë¸”í–ˆë‹¤. ì—„ì§€ì²™. ', 'review_star': 8},
{'review_text': 'ì´ë ‡ê²Œ ëƒ„ìƒˆë‚˜ëŠ” ë””ì¦ˆë‹ˆ ì˜í™”ëŠ” ì²¨ì´ë„¤ ', 'review_star': 1},
{'review_text': 'í‰ì ì´ ì™œ ë‚®ì€ì§€ ë„ë¬´ì§€ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.ê°ë™ì ì¸ ì˜í™”ë¼ ì‹œê°„ê°€ëŠ”ì¤„ ëª°ëìŠµë‹ˆë‹¤.ê³ ë§™ìŠµë‹ˆë‹¤. ', 'review_star': 10},
{'review_text': 'ì¬ë°‹ëŠ”ë° ì™œ ë‚œë¦¬ë“¤ì´ì§€ *** ê± ì‹«ì–´í•˜ëŠ”ë“¯ã… ', 'review_star': 9},
{'review_text': 'ë§ˆë¸” ì°íŒ¬ì¸ë° í‰ê°€í•  ê°€ì¹˜ë„ì—†ë‹¤ ', 'review_star': 1}
]
'''
```

### ë¦¬ë·° ìˆ˜
- ì˜í™” ì´ë¦„ê³¼ ì´ ìŠ¤í¬ë˜í•‘í•  ë¦¬ë·° ìˆ˜ë¥¼ ë°›ì•„ í•´ë‹¹ ìˆ˜ë§Œí¼ í•­ëª©ì´ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸ ë¦¬í„´

```py
def scrape_by_review_num(movie_title, review_num):
    reviews = []
    page_num = 1
    while len(reviews) < review_num:
        reviews += get_reviews(get_movie_code(movie_title), page_num)
        page_num += 1
    return reviews[:review_num]
```

### í˜ì´ì§€ ìˆ˜
- ì˜í™” ì´ë¦„ê³¼ ì´ ìŠ¤í¬ë˜í•‘í•  í˜ì´ì§€ ìˆ˜ë¥¼ ë°›ì•„ í•´ë‹¹ í˜ì´ì§€ë§Œí¼ í•­ëª©ì´ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸ ë¦¬í„´

```py
def scrape_by_page_num(movie_title, page_num=10):
    reviews = []
    for i in range(page_num):
        reviews += get_reviews(get_movie_code(movie_title), i)
    return reviews
```

## í‰ê·  ë³„ì 
- ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ í‰ê·  ë³„ì ì„ êµ¬í•´ ë¦¬í„´

```py
def get_avg_stars(reviews):
    star = []
    for i in reviews:
        star += [i['review_star']]
    avg = sum(star) / len(star)
    return avg

print(get_avg_stars(scrape_by_page_num('ìƒ¹ì¹˜'))) # 6.27
```

# 2ï¸âƒ£ Exeport SQLite
- ì˜í™”ì œëª©, í˜ì´ì§€ ìˆ˜ë¥¼ ë°›ì•„ ìŠ¤í¬ë˜í•‘í•œ ë’¤ DBì— ì €ì¥

```py
import os
import sqlite3
from src import Web_Scraping

DATABASE_PATH = os.path.join(os.getcwd(), 'scrape_data.db')
conn = sqlite3.connect(DATABASE_PATH)

def store_by_page_num(movie_title, page_num=10, conn=conn):
    cur = conn.cursor()
    Review = Web_Scraping.scrape_by_page_num(movie_title, page_num)
    id = 0
    for row in Review:
        cur.execute(
        "INSERT INTO Review (id, review_text, review_star, movie_title) VALUES (?, ?, ?, ?)",
        (id, row['review_text'], row['review_star'], movie_title)
        )
        id += 1
    conn.commit()

def init_db(conn=conn): # Review í…Œì´ë¸” ì´ˆê¸°í™” í•¨ìˆ˜
    create_table = """CREATE TABLE Review (
                        id INTEGER,
                        review_text TEXT,
                        review_star FLOAT,
                        movie_title VARCHAR(128),
                        PRIMARY KEY (id)
                        );"""

    drop_table_if_exists = "DROP TABLE IF EXISTS Review;"
    cur = conn.cursor()
    cur.execute(drop_table_if_exists)
    cur.execute(create_table)
    cur.close()
```