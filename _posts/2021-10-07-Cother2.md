---
title: '[Data Pipeline Project 2] COVID-19 & Weather 2. LightGBM regression'
description: 코드스테이츠 Section3(Data Engineering) Data Pipeline 구축 프로젝트 LightGBM 회귀 예측 모델링
categories:
 - Project
tags: [Project, Python, LightGBM, Regression]
---

# Postgre to CSV

```py
import requests
import psycopg2
import logging
import sys
import json
import csv

host = "covid.cjwptwa04yyi.ap-northeast-2.rds.amazonaws.com"
port = 5432
username = "sixmini"
database = "postgres"
password = ""


def main():
    # postgreSQL 연결
    try:
        conn = psycopg2.connect(
            host=host,
            database=database,
            user=username,
            password=password)
        cursor = conn.cursor()
    except:
        logging.error("could not connect to rds")
        sys.exit()

    sql = "COPY (SELECT * FROM weather) TO STDOUT WITH CSV DELIMITER ','"
    with open("weather.csv", "w") as file:
        cursor.copy_expert(sql, file)


if __name__=='__main__':
    main()

```

# LightGBM regression

```py
# 라이브러리 Import
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.externals import joblib
import lightgbm as lgb
import seaborn as sns
import pandas as pd
import numpy as np
import joblib
import shap
```

- Postgres에서 csv로 exeport 시 컬럼명이 지정되어있지 않으므로 header 지정
- 모든 column을 사용하고 싶지만, 예측에는 예보 기상이 활용되어야 하기 때문에 예보에서 확인할 수 있는 column으로만 modeling 진행
    - avgRhm: 습도
    - ddMes: 적설량
    - sumSsHr: 일조시간
    - avgPs: 해면기압
    - avgTca: 전운량
    - minTa: 최저기온
    - maxTa: 최고기온
    - avgWs: 풍속
    - sumRn: 강수량
    - avgTa: 평균기온
    - avgTd: 평균 이슬점온도


```py
weather = pd.read_csv('weather.csv', names=['date', 'avgTa', 'minTa', 'minTaHrmt', 'maxTa', 'maxTaHrmt', 'mi10MaxRn', 'mi10MaxRnHrmt', 'hr1MaxRn', 'hr1MaxRnHrmt', 'sumRnDur', 'sumRn', 'maxInsWs', 'maxInsWsWd', 'maxInsWsHrmt', 'maxWs', 'maxWsWd', 'maxWsHrmt', 'avgWs', 'hr24SumRws', 'maxWd', 'avgTd', 'minRhm', 'minRhmHrmt', 'avgRhm', 'avgPv', 'avgPa', 'maxPs', 'maxPsHrmt', 'minPs', 'minPsHrmt', 'avgPs', 'ssDur', 'sumSsHr', 'hr1MaxIcsrHrmt', 'hr1MaxIcsr', 'sumGsr', 'ddMefs', 'ddMefsHrmt', 'ddMes', 'ddMesHrmt', 'sumDpthFhsc', 'avgTca', 'avgLmac', 'avgTs', 'minTg', 'avgCm5Te', 'avgCm10Te', 'avgCm20Te', 'avgCm30Te', 'avgM05Te', 'avgM10Te', 'avgM15Te', 'avgM30Te', 'avgM50Te', 'sumLrgEv', 'sumSmlEv', 'n99Rn', 'iscs', 'sumFogDur'])
weather.set_index('date', inplace=True)
weather = weather[['avgRhm', 'ddMes', 'sumSsHr', 'avgPs', 'avgTca', 'avgTd', 'minTa', 'maxTa', 'avgWs', 'sumRn', 'avgTa']]
weather.head(1)
```

![스크린샷 2021-10-10 06 42 23](https://user-images.githubusercontent.com/79494088/136674383-6e3192bb-af63-4e35-8367-41368415be80.png)

```py
confirmed = pd.read_csv('covid-confirmed-in-seoul.csv', names=['date', 'confirmed'])
confirmed.set_index('date', inplace=True)
confirmed.head(1)
```

![스크린샷 2021-10-10 06 43 00](https://user-images.githubusercontent.com/79494088/136674398-c2527dd2-9434-4cbc-b05a-197abe04085c.png)

```py
# index 기준 merge
df = pd.merge(weather, confirmed, how='inner', on='date')
train, test= train_test_split(df, random_state=42)
train.shape, test.shape
'''
((275, 12), (92, 12))
'''
```

- 빠른 modeling 진행

```py
target = 'confirmed' 
features = df.columns.drop('confirmed')

X_train = train[features]
y_train = train[target]
X_test = test[features]
y_test = test[target]

train_ds = lgb.Dataset(X_train, label = y_train) 
test_ds = lgb.Dataset(X_test, label = y_test)

params = {'learning_rate': 0.01, 
          'max_depth': 10,
          'objective': 'regression', 
          'metric': 'mse', 
          'is_training_metric': True, 
          'num_leaves': 144, 
          'feature_fraction': 0.9, 
          'bagging_fraction': 0.7, 
          'bagging_freq': 5, 
          'seed':2018}

model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=100)
'''
Training until validation scores don't improve for 100 rounds.
[100]	valid_0's l2: 31347.2
[200]	valid_0's l2: 27725.6
[300]	valid_0's l2: 26771
[400]	valid_0's l2: 26554.9
[500]	valid_0's l2: 26491.7
[600]	valid_0's l2: 25947.4
[700]	valid_0's l2: 25973.2
Early stopping, best iteration is:
[620]	valid_0's l2: 25752
'''
```

```py
predict_train = model.predict(X_train)
predict_test = model.predict(X_test)

mse = mean_squared_error(y_test, predict_test)
r2 = r2_score(y_test, predict_test)
print('Mean squared error: ', mse)
print('R2 score: ', r2)
'''
Mean squared error:  25752.024720112582
R2 score:  0.5061622922193673
'''
```

- 사실 모든 column을 사용했을 때보다 평가 점수는 만족할 수 없지만, 0.5가 넘으므로 모델 사용 예정
- 날씨와 코로나의 상관관계가 적고 데이터 또한 적기 때문에 과적합의 위험이 굉장히 크다.

```py
final_result = pd.concat([y_test.reset_index(drop=True), pd.DataFrame(predict_test)], axis = 1)
final_result.columns = ['label','predict']
sns.regplot(x = 'label', y = 'predict', data = final_result);
```

![스크린샷 2021-10-10 06 48 44](https://user-images.githubusercontent.com/79494088/136674497-4233cd4e-7746-43ee-b0a5-1f6ad38d7fb5.png)

- LightGBM을 처음 사용했는데 별 설정을 안해줘도 엄청난 분석능력을 자랑한다.

## SHAP
- 대략적인 특성 중요도 확인

```py
explainer = shap.TreeExplainer(model)

shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test)
```

![스크린샷 2021-10-10 06 51 01](https://user-images.githubusercontent.com/79494088/136674538-1bdb44c1-aa02-44d5-b131-9a74f0cc683e.png)

# Pickle
- flask에서 사용하기 위해 joblib 이용 모델 pkl 형태로 save

```py
# save model
joblib.dump(model, 'lgb.pkl')
 
# load model
load_model = joblib.load('lgb.pkl')
load_model
'''
<lightgbm.basic.Booster at 0x7fe75b464c90>
'''
```