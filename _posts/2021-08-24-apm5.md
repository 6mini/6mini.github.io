---
title: '[Applied Predictive Modeling] Choose your ML problems'
description: ëª¨ë¸ì„ íƒì„ ìœ„í•œ êµì°¨ê²€ì¦ ë°©ë²•ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ìµœì í™”ë¥¼ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ ì„¤ëª…
categories:
 - Machine Learning
tags: [Machine Learning, Model Selection, Cross Validation, êµì°¨ê²€ì¦, í•˜ì´í¼íŒŒë¼ë¯¸í„°, ëª¨ë¸ì„ íƒ]
mathjax: enable
# 0ï¸âƒ£1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£7ï¸âƒ£8ï¸âƒ£9ï¸âƒ£ğŸ”Ÿ
---

# 1ï¸âƒ£ Choose your ML problems

- ì´ˆì½œë¦¿ ë°” í‰ì  ë°ì´í„°ì„¸íŠ¸ ì‚¬ìš©

```py
import pandas as pd
import numpy as np
pd.options.display.max_columns = None
df = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/chocolate_bar_ratings/flavors_of_cacao.csv')
```

## ë°ì´í„° ê³¼í•™ì ì‹¤ë¬´ í”„ë¡œì„¸ìŠ¤
1. ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ
  - ì‹¤ë¬´ìë“¤ê³¼ ëŒ€í™”ë¥¼ í†µí•´ ë¬¸ì œë¥¼ ë°œê²¬
2. ë°ì´í„° ë¬¸ì œ
  - ë¬¸ì œì™€ ê´€ë ¨ëœ ë°ì´í„°ë¥¼ ë°œê²¬
3. ë°ì´í„° ë¬¸ì œ í•´ê²°
  - ë°ì´í„° ì²˜ë¦¬, ì‹œê°í™”
  - ë¨¸ì‹ ëŸ¬ë‹/í†µê³„
4. ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ í•´ê²°
  - ë°ì´í„° ë¬¸ì œ í•´ê²°ì„ í†µí•´ ì‹¤ë¬´ìë“¤ê³¼ í•¨ê»˜ í•´ê²°

- ìºê¸€ ëŒ€íšŒë¥¼ ìˆ˜í–‰ì€ ì—¬ëŸ¬ ëª¨ë¸ì„ ê²€ì¦í•´ë³´ë©° ê¸°ìˆ ì„ ìµíˆëŠ”ë° í›Œë¥­í•œ ë°©ë²•ì´ì§€ë§Œ ì´ ê³¼ì •ë„ ë°ì´í„° ê³¼í•™ ì—…ë¬´ì˜ í•œ ë¶€ë¶„ì´ë‹¤.
- ë¬¸ì œì •ì˜ê³¼ì •ì€ ëˆ„êµ°ê°€ì— ì˜í•´ ì •í•´ì ¸ ìˆì—ˆê³  ê¸°ìˆ ì ìœ¼ë¡œ ë°ì´í„°ë¡œì˜ ë¬¸ì œí•´ê²°ì—ë§Œ ì§‘ì¤‘í–ˆë‹¤.

## Choose Target
- ì§€ë„í•™ìŠµì—ì„œëŠ” ì˜ˆì¸¡í•´ì•¼í•˜ëŠ” íƒ€ê²Ÿì„ ëª…í™•íˆ ì •í•˜ê³  ê·¸ ë¶„í¬ë¥¼ ì‚´í´ë³¸ë‹¤.
- ì–´ë–¤ ë¬¸ì œëŠ” íšŒê·€/ë¶„ë¥˜ê°€ ì‰½ê²Œ êµ¬ë¶„ë˜ì§€ ì•ŠëŠ”ë‹¤.
  - ì´ì‚°í˜•, ìˆœì„œí˜•, ë²”ì£¼í˜• íƒ€ê²ŸíŠ¹ì„±ë„ **íšŒê·€ë¬¸ì œ** ë˜ëŠ” **ë‹¤ì¤‘í´ë˜ìŠ¤ë¶„ë¥˜ë¬¸ì œ**ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.
  - íšŒê·€, ë‹¤ì¤‘í´ë˜ìŠ¤ë¶„ë¥˜ ë¬¸ì œë“¤ë„ **ì´ì§„ë¶„ë¥˜ë¬¸ì œ**ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤.

```py
df. head()
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 09 59 01](https://user-images.githubusercontent.com/79494088/130538604-c35e244f-4907-490a-a722-e4f07518867c.png)


```py
df.columns
'''
Index(['Company \n(Maker-if known)', 'Specific Bean Origin\nor Bar Name',
       'REF', 'Review\nDate', 'Cocoa\nPercent', 'Company\nLocation', 'Rating',
       'Bean\nType', 'Broad Bean\nOrigin'],
      dtype='object')
'''

# ì»¬ëŸ¼ëª… ì •ë¦¬
df.columns = ['company','specificOrigin','ref','reviewDate','cocoaPercent','companyLocation','rating','beanType','broadOrigin']

# ê²°ì¸¡ì¹˜ í™•ì¸, ëª‡ ê°œ ì•ˆë˜ì–´ í›„ì— ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì œê±°
[(x, df[x].isnull().sum()) for x in df.columns if df[x].isnull().any()]
'''
[('beanType', 1), ('broadOrigin', 1)]
'''

# íƒ€ê²Ÿ í™•ì¸
df.dtypes
'''
company             object
specificOrigin      object
ref                  int64
reviewDate           int64
cocoaPercent        object
companyLocation     object
rating             float64
beanType            object
broadOrigin         object
dtype: object
'''

df.describe(include='all').T
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 00 58](https://user-images.githubusercontent.com/79494088/130538744-ed4a2a1f-7421-4ba6-a10f-814cef6c969c.png)

```py
# ratingì´ íƒ€ê²ŸíŠ¹ì„± : ì‹¤ìˆ˜í˜•
df['rating'].describe()
'''
count    1795.000000
mean        3.185933
std         0.478062
min         1.000000
25%         2.875000
50%         3.250000
75%         3.500000
max         5.000000
Name: rating, dtype: float64
'''

# ë¶„í¬í™•ì¸
import seaborn as sns
import matplotlib.pyplot as plt
sns.displot(df['rating'],kde=True);
plt.axvline(3.7, color='red');
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 02 08](https://user-images.githubusercontent.com/79494088/130538823-c454f137-c51b-4007-8955-bcdf3cf56510.png)

```py
# ratingì„ ì´ì§„íƒ€ì…ìœ¼ë¡œ ë³€í˜•ì‹œì¼œ ë¶„ë¥˜ë¬¸ì œë¡œ ë³€ê²½
# recommend íŠ¹ì„± ë§Œë“¤ì–´ ì´ì§„ë¶„ë¥˜ë¬¸ì œë¡œ ë³€í™˜
df['recommend'] = df['rating'] >= 3.7
df['recommend'].nunique()
'''
2
'''

df['recommend'].value_counts()
'''
False    1485
True      310
Name: recommend, dtype: int64
'''

# ë°ì´í„° í™•ì¸ ë° ê°„ë‹¨í•œ ì „ì²˜ë¦¬
df['cocoaPercent'].head()
'''
0    63%
1    70%
2    70%
3    70%
4    70%
Name: cocoaPercent, dtype: object
'''

df['broadOrigin'].unique()
'''
array(['Sao Tome', 'Togo', 'Peru', 'Venezuela', 'Cuba', 'Panama',
       'Madagascar', 'Brazil', 'Ecuador', 'Colombia', 'Burma',
       'Papua New Guinea', 'Bolivia', 'Fiji', 'Mexico', 'Indonesia',
       'Trinidad', 'Vietnam', 'Nicaragua', 'Tanzania',
       'Dominican Republic', 'Ghana', 'Belize', '\xa0', 'Jamaica',
       'Grenada', 'Guatemala', 'Honduras', 'Costa Rica',
       'Domincan Republic', 'Haiti', 'Congo', 'Philippines', 'Malaysia',
       'Dominican Rep., Bali', 'Venez,Africa,Brasil,Peru,Mex', 'Gabon',
       'Ivory Coast', 'Carribean', 'Sri Lanka', 'Puerto Rico', 'Uganda',
       'Martinique', 'Sao Tome & Principe', 'Vanuatu', 'Australia',
       'Liberia', 'Ecuador, Costa Rica', 'West Africa', 'Hawaii',
       'St. Lucia', 'Cost Rica, Ven', 'Peru, Madagascar',
       'Venezuela, Trinidad', 'Trinidad, Tobago',
       'Ven, Trinidad, Ecuador', 'South America, Africa', 'India',
       'Africa, Carribean, C. Am.', 'Tobago', 'Ven., Indonesia, Ecuad.',
       'Trinidad-Tobago', 'Peru, Ecuador, Venezuela',
       'Venezuela, Dom. Rep.', 'Colombia, Ecuador', 'Solomon Islands',
       'Nigeria', 'Peru, Belize', 'Peru, Mad., Dom. Rep.', nan,
       'PNG, Vanuatu, Mad', 'El Salvador', 'South America', 'Samoa',
       'Ghana, Domin. Rep', 'Trinidad, Ecuador', 'Cameroon',
       'Venezuela, Java', 'Venezuela/ Ghana', 'Venezuela, Ghana',
       'Indonesia, Ghana', 'Peru(SMartin,Pangoa,nacional)', 'Principe',
       'Central and S. America', 'Ven., Trinidad, Mad.',
       'Carribean(DR/Jam/Tri)', 'Ghana & Madagascar',
       'Ven.,Ecu.,Peru,Nic.', 'Madagascar & Ecuador',
       'Guat., D.R., Peru, Mad., PNG', 'Peru, Dom. Rep',
       'Dom. Rep., Madagascar', 'Gre., PNG, Haw., Haiti, Mad',
       'Mad., Java, PNG', 'Ven, Bolivia, D.R.', 'DR, Ecuador, Peru',
       'Suriname', 'Peru, Ecuador', 'Ecuador, Mad., PNG',
       'Ghana, Panama, Ecuador', 'Venezuela, Carribean'], dtype=object)
'''

import re

# broadOrigin í…ìŠ¤íŠ¸ ìˆ˜ì • í•¨ìˆ˜
def txt_prep(text):
    replacements = [
        ['-', ', '], ['/ ', ', '], ['/', ', '], ['\(', ', '], [' and', ', '], [' &', ', '], ['\)', ''],
        ['Dom Rep|DR|Domin Rep|Dominican Rep,|Domincan Republic', 'Dominican Republic'],
        ['Mad,|Mad$', 'Madagascar, '],
        ['PNG', 'Papua New Guinea, '],
        ['Guat,|Guat$', 'Guatemala, '],
        ['Ven,|Ven$|Venez,|Venez$', 'Venezuela, '],
        ['Ecu,|Ecu$|Ecuad,|Ecuad$', 'Ecuador, '],
        ['Nic,|Nic$', 'Nicaragua, '],
        ['Cost Rica', 'Costa Rica'],
        ['Mex,|Mex$', 'Mexico, '],
        ['Jam,|Jam$', 'Jamaica, '],
        ['Haw,|Haw$', 'Hawaii, '],
        ['Gre,|Gre$', 'Grenada, '],
        ['Tri,|Tri$', 'Trinidad, '],
        ['C Am', 'Central America'],
        ['S America', 'South America'],
        [', $', ''], [',  ', ', '], [', ,', ', '], ['\xa0', ' '],[',\s+', ','],
        ['\.',''],
        [' Bali', ',Bali']
    ]
    for i, j in replacements:
        text = re.sub(i, j, text)
    return text

# ê°„ë‹¨í•˜ê²Œ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ë§Œ ì „ì²˜ë¦¬
def preprocess (df):

    df.dropna(inplace=True)
    
    df['cocoaPercent'] = df['cocoaPercent'].str.replace('%','').astype(float)/100
    
    df['broadOrigin'] = df['broadOrigin'].apply(txt_prep)
    
    df['companyLocation'] = df['companyLocation']\
        .str.replace('Amsterdam', 'Holland')\
        .str.replace('U.K.', 'England')\
        .str.replace('Niacragua', 'Nicaragua')\
        .str.replace('Domincan Republic', 'Dominican Republic')
    
    df['beanType'] = df['beanType'].apply(lambda x : 'Missing' if (x is "\xa0") else x)
    
    df['is_blend'] = np.where(
    np.logical_or(
        np.logical_or(df['specificOrigin'].str.lower().str.contains(',|blend|;'),
                      df['broadOrigin'].str.len() == 1),
        df['broadOrigin'].str.lower().str.contains(',')
    )
    , 1
    , 0
)
    
    return df

df = preprocess(df)

df['is_blend'].value_counts()
'''
0    1095
1     698
Name: is_blend, dtype: int64
'''
```

# 2ï¸âƒ£ ì •ë³´ì˜ ëˆ„ìˆ˜(Leakage) í™•ì¸
- ëª¨ë¸ì„ ë§Œë“¤ê³  í‰ê°€í–ˆì„ ë•Œ ì˜ˆì¸¡ì„ 100% ê°€ê¹ê²Œ ì˜ í•˜ëŠ” ê²½ìš°ë¥¼ ë³´ê²Œ ëœë‹¤.
- ì´ ë•Œ **ì •ë³´ì˜ ëˆ„ìˆ˜ê°€ ì¡´ì¬í•  ê°€ëŠ¥ì„±**ì´ í¬ë‹¤.
  - íƒ€ê²Ÿë³€ìˆ˜ ì™¸ì˜ ì˜ˆì¸¡ì‹œì ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ í•™ìŠµ
  - í›ˆë ¨ë°ì´í„°ì™€ ê²€ì¦ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ì§€ ëª»í•œ ê²½ìš°
- ì •ë³´ì˜ ëˆ„ìˆ˜ê°€ ì¼ì–´ë‚˜ **ê³¼ì í•©ì„ ì¼ìœ¼í‚¤ê³  ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ì´ ê¸‰ê²©íˆ ë–¨ì–´ì§„ë‹¤.**

```py
# ë°ì´í„° ì •ë¦¬
df.isna().sum().sort_values()
'''
company            0
specificOrigin     0
ref                0
reviewDate         0
cocoaPercent       0
companyLocation    0
rating             0
beanType           0
broadOrigin        0
recommend          0
is_blend           0
dtype: int64
'''

df['reviewDate'].value_counts().sort_index()
'''
2006     72
2007     77
2008     93
2009    123
2010    111
2011    164
2012    194
2013    184
2014    247
2015    285
2016    219
2017     24
Name: reviewDate, dtype: int64
'''

# ë°ì´í„° ë¶„ë¦¬
from sklearn.model_selection import train_test_split
train, val = train_test_split(df, test_size=0.2, random_state=2)
train.shape, val.shape
'''
((1434, 11), (359, 11))
'''

# ëˆ„ìˆ˜ê°€ ì¼ì–´ë‚œ íŠ¹ì„±ì„ ì œê±°í•˜ì§€ ì•Šì•˜ì„ ë•Œì˜ ê²°ê³¼
from category_encoders import OrdinalEncoder
from sklearn.pipeline import make_pipeline
from sklearn.tree import DecisionTreeClassifier

target = 'recommend'
features = df.columns.drop([target, 'reviewDate'])
X_train = train[features]
y_train = train[target]
X_val = val[features]
y_val = val[target]

pipe = make_pipeline(
    OrdinalEncoder(), 
    DecisionTreeClassifier(max_depth=5, random_state=2)
)

pipe.fit(X_train, y_train)
print('ê²€ì¦ ì •í™•ë„: ', pipe.score(X_val, y_val))
'''
ê²€ì¦ ì •í™•ë„:  1.0
'''

# íŠ¸ë¦¬ í™•ì¸
import graphviz
from sklearn.tree import export_graphviz

tree = pipe.named_steps['decisiontreeclassifier']

dot_data = export_graphviz(
    tree,
    feature_names=X_train.columns, 
    class_names=y_train.unique().astype(str), 
    filled=True, 
    proportion=True
)

graphviz.Source(dot_data)
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 07 49](https://user-images.githubusercontent.com/79494088/130539214-a82a169a-4127-42e0-839b-d36dca2583c2.png)

```py
# ì •ë³´ ëˆ„ìˆ˜ê°€ ì¼ì–´ë‚œ ì»¬ëŸ¼ ì œê±°
features = df.columns.drop([target
                            , 'reviewDate'
                            , 'rating'
                            , 'ref'
                           ])
X_train = train[features]
y_train = train[target]
X_val = val[features]
y_val = val[target]

pipe = make_pipeline(
    OrdinalEncoder(), 
    DecisionTreeClassifier(max_depth=5, random_state=2)
)

pipe.fit(X_train, y_train)
print('ê²€ì¦ ì •í™•ë„', pipe.score(X_val, y_val))
'''
ê²€ì¦ ì •í™•ë„ 0.83008356545961
'''

# ì‹œê°í™” í™•ì¸
tree = pipe.named_steps['decisiontreeclassifier']

dot_data = export_graphviz(
    tree, 
    feature_names=X_train.columns, 
    class_names=y_train.unique().astype(str), 
    filled=True, 
    proportion=True
)

graphviz.Source(dot_data)
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 09 07](https://user-images.githubusercontent.com/79494088/130539333-4e5afb1d-53f1-4cf9-a4d4-946f575ddbc0.png)

## ë¬¸ì œì— ì í•©í•œ í‰ê°€ì§€í‘œ ì„ íƒ
- ì˜ˆì¸¡ëª¨ë¸ í‰ê°€ëŠ” ë¬¸ì œì˜ ìƒí™©ì— ë”°ë¼ ë‹¤ë¥´ë‹¤. íŠ¹íˆ, ë¶„ë¥˜ & íšŒê·€ ëª¨ë¸ì˜ í‰ê°€ì§€í‘œëŠ” ë”ìš± ë‹¤ë¥´ë‹¤.
- ë¶„ë¥˜ë¬¸ì œì—ì„œ íƒ€ê²Ÿ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ 70% ì´ìƒ ì°¨ì´ë‚  ê²½ìš° ì •í™•ë„ë§Œ ì‚¬ìš©í•˜ë©´ íŒë‹¨ì„ ì •í™•íˆ í•  ìˆ˜ ì—†ë‹¤.
- **Precision, Recall, ROC curve, AUC** ë“±ì„ ê°™ì´ ì‚¬ìš©í•´ì•¼ í•œë‹¤.

```py
from sklearn.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
pcm = plot_confusion_matrix(pipe, X_val, y_val,
                            cmap=plt.cm.Blues,
                            ax=ax);
plt.title(f'Confusion matrix, n = {len(y_val)}', fontsize=15)
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 14 10](https://user-images.githubusercontent.com/79494088/130539725-5a8e7da6-bfc5-4f18-a503-9aa22b851b2b.png)

```py
pipe = make_pipeline(
    OrdinalEncoder(), 
    DecisionTreeClassifier(max_depth=5, random_state=2)
)

pipe.fit(X_train, y_train)
print('ê²€ì¦ ì •í™•ë„', pipe.score(X_val, y_val))
'''
ê²€ì¦ ì •í™•ë„ 0.83008356545961
'''

# false ì˜ˆì¸¡ ì •í™•ë„ëŠ” ë†’ì§€ë§Œ TrueëŠ” í˜„ì €íˆ ë‚®ë‹¤.
from sklearn.metrics import classification_report
y_pred = pipe.predict(X_val)
print(classification_report(y_val, y_pred))
'''
              precision    recall  f1-score   support

       False       0.84      0.98      0.91       302
        True       0.17      0.02      0.03        57

    accuracy                           0.83       359
   macro avg       0.50      0.50      0.47       359
weighted avg       0.73      0.83      0.77       359
'''

from sklearn.metrics import roc_auc_score

y_pred_proba = pipe.predict_proba(X_val)[:, -1]
print('AUC score: ', roc_auc_score(y_val, y_pred_proba))
'''
AUC score:  0.5991634715928895
'''

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)

plt.scatter(fpr, tpr, color='blue')
plt.plot(fpr, tpr, color='green')
plt.title('ROC curve')
plt.xlabel('FPR')
plt.ylabel('TPR')
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 15 29](https://user-images.githubusercontent.com/79494088/130539833-b2fb2161-1eee-457c-9605-567f1fd39ebd.png)

## ë¶ˆê· í˜• í´ë˜ìŠ¤
- íƒ€ê²Ÿ íŠ¹ì„±ì˜ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ì°¨ì´ê°€ ë‚˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.
- Scikit-learn ë¶„ë¥˜ê¸°ë“¤ì€ `class_weight`ê°™ì€ í´ë˜ìŠ¤ì˜ ë°¸ëŸ°ìŠ¤ë¥¼ ë§ì¶”ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ê°–ê³  ìˆë‹¤.
  - ë°ì´í„°ê°€ ì ì€ ë²”ì£¼ì˜ ì†ì‹¤ì„ ê³„ì‚°í•  ë•Œ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ì—¬ ë°ì´í„°ì˜ ê· í˜•ì„ ë§ì¶”ê±°ë‚˜
  - ì ì€ ë²”ì£¼ ë°ì´í„°ë¥¼ ì¶”ê°€ìƒ˜í”Œë§(Oversampling)í•˜ê±°ë‚˜ ë°˜ëŒ€ë¡œ ë§ì€ ë²”ì£¼ ë°ì´í„°ë¥¼ ì ê²Œ ìƒ˜í”Œë§(Undersampling)í•˜ëŠ” ë°©ë²•ì´ ìˆë‹¤.

```py
# ë²”ì£¼ ë¹„ìœ¨ í™•ì¸
# class_weightì—ì„œ ì›í•˜ëŠ” ë¹„ìœ¨ì„ ì ìš©í•˜ê±°ë‚˜ class_weight='balance' ì˜µì…˜ì„ ì‚¬ìš©
y_train.value_counts(normalize=True)
'''
False    0.824268
True     0.175732
Name: recommend, dtype: float64
'''

# class weights ê³„ì‚°
# n_samples / (n_classes * np.bincount(y))
custom = len(y_train)/(2*np.bincount(y_train))
custom
'''
array([0.60659898, 2.8452381 ])
'''

# íŒŒì´í”„ë¼ì¸
pipe = make_pipeline(
    OrdinalEncoder(), 
#     DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=2)
    DecisionTreeClassifier(max_depth=5, class_weight={False:custom[0],True:custom[1]}, random_state=2)
)

pipe.fit(X_train, y_train)
print('ê²€ì¦ ì •í™•ë„: ', pipe.score(X_val, y_val))
'''
ê²€ì¦ ì •í™•ë„:  0.584958217270195
'''

fig, ax = plt.subplots()
pcm = plot_confusion_matrix(pipe, X_val, y_val,
                            cmap=plt.cm.Blues,
                            ax=ax);
plt.title(f'Confusion matrix, n = {len(y_val)}', fontsize=15)
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 20 38](https://user-images.githubusercontent.com/79494088/130540255-39415583-8fe1-4a1c-9986-8bce9a2dda85.png)

- ì™„í™”ë˜ì—ˆë‹¤.

```py
# True ë²”ì£¼ì˜ ìˆ˜ì¹˜ ë¹„êµ
y_pred = pipe.predict(X_val)
print(classification_report(y_val, y_pred))
'''
              precision    recall  f1-score   support

       False       0.86      0.60      0.71       302
        True       0.19      0.49      0.27        57

    accuracy                           0.58       359
   macro avg       0.53      0.55      0.49       359
weighted avg       0.76      0.58      0.64       359
'''

y_pred_proba = pipe.predict_proba(X_val)[:, -1]
print('AUC score: ', roc_auc_score(y_val, y_pred_proba))
fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)
plt.scatter(fpr, tpr, color='blue')
plt.plot(fpr, tpr, color='green')
plt.title('ROC curve')
plt.xlabel('FPR')
plt.ylabel('TPR')
'''
AUC score:  0.624056000929476
'''
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 22 12](https://user-images.githubusercontent.com/79494088/130540373-ac2e6720-a0d3-4c59-a412-22b3c6afb2b1.png)

# 3ï¸âƒ£ íƒ€ê²Ÿì˜ ë¶„í¬
- íšŒê·€ë¬¸ì œì—ì„œ íƒ€ê²Ÿ ë¶„í¬ë¥¼ ì£¼ì˜ê¹Šê²Œ ì‚´í´ì•¼í•œë‹¤.

```py
# house price ì‚¬ìš©
df = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/house-prices/house_prices_train.csv')

# íƒ€ê²Ÿ ì„ íƒ
target = df['SalePrice']
```

## ë¹„ëŒ€ì¹­ í˜•íƒœì¸ì§€ í™•ì¸
- ì„ í˜•íšŒê·€ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ íŠ¹ì„±ê³¼ íƒ€ê²Ÿê°„ì˜ ì„ í˜•ê´€ê³„ë¥¼ ê°€ì •í•œë‹¤.
- íŠ¹ì„± ë³€ìˆ˜ë“¤ê³¼ íƒ€ê²Ÿë³€ìˆ˜ì˜ ë¶„í¬ê°€ **ì •ê·œë¶„í¬ì¼ë•Œ ì¢‹ì€ ì„±ëŠ¥**ì„ ë³´ì¸ë‹¤.
- íƒ€ê²Ÿë³€ìˆ˜ê°€ ì™œê³¡ëœ í˜•íƒœì˜ ë¶„í¬(skewed)ì¼ë•Œ ì˜ˆì¸¡ ì„±ëŠ¥ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹œë‹¤.
- ë“±ë¶„ì‚°ì„±
  - ë¶„ì‚°ì´ ê°™ë‹¤ëŠ” ê²ƒì´ê³ , íŠ¹ì •í•œ íŒ¨í„´ì—†ì´ ê³ ë¥´ê²Œ ë¶„í¬í–ˆë‹¤ëŠ” ì˜ë¯¸
  - ë“±ë¶„ì‚°ì„±ì˜ ì£¼ì²´ëŠ” ì”ì°¨

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 26 32](https://user-images.githubusercontent.com/79494088/130540659-87e43995-28fa-4764-801c-46c1b7a88c0e.png)

```py
# íƒ€ê²Ÿ ë¶„í¬ê°€ right(positively) skewed
sns.displot(target);
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 27 45](https://user-images.githubusercontent.com/79494088/130540754-72eab738-96d8-47ef-b190-8724440f9066.png)

```py
# ì´ìƒì¹˜ ì²˜ë¦¬
# ëª‡ëª‡ ê°€ê²©ì´ë‚˜ ë‹¤ë¥¸ ìˆ˜ì¹˜ëŠ” ë†’ì•„ì„œ ë¬¸ì œë  ìˆ˜ ìˆë‹¤.
import numpy as np

# íƒ€ê²Ÿ ì´ìƒì¹˜(outlier)ë¥¼ ì œê±°
df['SalePrice'] = df[df['SalePrice'] < np.percentile(df['SalePrice'], 99.5)]['SalePrice']

# ëª‡ëª‡ ë³€ìˆ˜ í•©ì¹˜ê³  ì´ìƒì¹˜ ì œê±°
df['All_Flr_SF'] = df['1stFlrSF'] + df['2ndFlrSF']
df['All_Liv_SF'] = df['All_Flr_SF'] + df['LowQualFinSF'] + df['GrLivArea']
df = df.drop(['1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea'], axis=1)

df['All_Flr_SF'] = df[df['All_Flr_SF'] < np.percentile(df['All_Flr_SF'], 99.5)]['All_Flr_SF']
df['All_Liv_SF'] = df[df['All_Liv_SF'] < np.percentile(df['All_Liv_SF'], 99.5)]['All_Liv_SF']

df['SalePrice']
'''
0       208500.0
1       181500.0
2       223500.0
3       140000.0
4       250000.0
          ...   
1455    175000.0
1456    210000.0
1457    266500.0
1458    142125.0
1459    147500.0
Name: SalePrice, Length: 1460, dtype: float64
'''

# ë¶„í¬ì˜ ì¹˜ìš°ì¹¨ì´ ì–´ëŠì •ë„ ê°œì„ ë˜ì—ˆì§€ë§Œ ì—¬ì „íˆ right-skewed ìƒíƒœ
target = df['SalePrice']
sns.displot(target);
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 29 37](https://user-images.githubusercontent.com/79494088/130540903-a0ce867c-ee43-4ea3-a3d7-2a9625d21892.png)

## ë¡œê·¸ë³€í™˜(Log-Transform)
- ë¡œê·¸ë³€í™˜ ì‚¬ìš© ì‹œ ë¹„ëŒ€ì¹­ ë¶„í¬í˜•íƒœë¥¼ ì •ê·œë¶„í¬í˜•íƒœë¡œ ë³€í™˜ì‹œì¼œì¤€ë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 30 25](https://user-images.githubusercontent.com/79494088/130540961-c77eaad4-cea3-4dd1-b8dd-661b3a59e292.png)

- [log1p](https://numpy.org/doc/stable/reference/generated/numpy.log1p.html): `ln(1 + x)`
- [expm1](https://numpy.org/doc/stable/reference/generated/numpy.expm1.html#numpy.expm1): `exp(x) - 1`, the inverse of log1p.

```py
plots=pd.DataFrame()
plots['original']=target
plots['transformed']=np.log1p(target)
plots['backToOriginal']=np.expm1(np.log1p(target))

fig, ax = plt.subplots(1,3,figsize=(15,5))
sns.histplot(plots['original'], ax=ax[0]);
sns.histplot(plots['transformed'], ax=ax[1]);
sns.histplot(plots['backToOriginal'], ax=ax[2]);
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-24 10 31 09](https://user-images.githubusercontent.com/79494088/130541015-ec644dc4-9a5e-4a80-a48e-f7ad08035c74.png)


### Transformed TargetRegressor
```py
target = 'SalePrice'
from sklearn.model_selection import train_test_split

df = df[df[target].notna()]

train, val = train_test_split(df, test_size=260, random_state=2)

features = train.drop(columns=[target]).columns

X_train = train[features]
y_train = train[target]
X_val = val[features]
y_val = val[target]


from category_encoders import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.compose import TransformedTargetRegressor

pipe = make_pipeline(
    OrdinalEncoder(), 
    SimpleImputer(),
    RandomForestRegressor(random_state=2)
)


pipe.fit(X_train, y_train)
pipe.score(X_val, y_val)
'''
0.8853294698484703
'''


from category_encoders import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.compose import TransformedTargetRegressor

pipe = make_pipeline(
    OrdinalEncoder(), 
    SimpleImputer(),
    RandomForestRegressor(random_state=2)
)

tt = TransformedTargetRegressor(regressor=pipe,
                                func=np.log1p, inverse_func=np.expm1)

tt.fit(X_train, y_train)
tt.score(X_val, y_val)
'''
0.8886126974296943
'''
```

# 4ï¸âƒ£ ì°¸ê³ ìë£Œ
- [How to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)
- [Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/)
- [Top 3 Methods for Handling Skewed Data](https://towardsdatascience.com/top-3-methods-for-handling-skewed-data-1334e0debf45)
- [Handling Imbalanced Datasets in Deep Learning](https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758)
- [Basic Intuition about Skewness](https://www.kaggle.com/getting-started/176174)