---
title: '[Tree Based Model] ê²°ì •íŠ¸ë¦¬(Decision Trees)'
description: ì‚¬ì´í‚·ëŸ°ì˜ íŒŒì´í”„ë¼ì¸ê³¼ ê²°ì •íŠ¸ë¦¬ë¥¼ ì´í•´í•˜ê³  ì‚¬ìš©í•˜ë©° ê²°ì •íŠ¸ë¦¬ì˜ íŠ¹ì„±ì¤‘ìš”ë„ í™œìš© ë° ì¥ì ì„ ì´í•´í•˜ê³  ì„ í˜•íšŒê·€ëª¨ë¸ê³¼ì˜ ë¹„êµ
categories:
 - Machine Learning
tags: [Machine Learning, Tree Based Model, Decision Trees, Scikit-learn, Pipelines, Feature importances, ì‚¬ì´í‚·ëŸ°, íŒŒì´í”„ë¼ì¸, ê²°ì •íŠ¸ë¦¬, íŠ¹ì„± ì¤‘ìš”ë„]
mathjax: enable
# 0ï¸âƒ£1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£7ï¸âƒ£8ï¸âƒ£9ï¸âƒ£ğŸ”Ÿ
---

# 1ï¸âƒ£ ê°œìš”
- ê²°ì •íŠ¸ë¦¬ëª¨ë¸
  - ê²°ì •íŠ¸ë¦¬ ëª¨ë¸ì€ íŠ¹ì„±ì„ í•´ì„í•˜ê¸° ì¢‹ë‹¤. 
  - ë‹¤ë¥¸ ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ì¡°ê¸ˆ ë–¨ì–´ì§„ë‹¤ê³  í•˜ë”ë¼ë„ í•´ì„í•˜ê¸°ê°€ ì¢‹ì•„ ë§ì´ ì“°ì¸ë‹¤.
  - ë¬¼ë¡  ìƒ˜í”Œì— ë¯¼ê°í•´ì„œ íŠ¹ì´êµ¬ì¡°ê°€ ë°”ë€Œê¸° ì‰½ë‹¤ëŠ” ë‹¨ì ë„ ìˆëŠ”ë° ê·¸ëŸ¬ë©´ í•´ì„ë„ ë°”ë€Œê²Œ ëœë‹¤.
  - ë˜ í•˜ë‚˜ì˜ ì¥ì ì€ íšŒê·€ë‚˜ ë¶„ë¥˜ë¬¸ì œì— ì ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.
  - ë‹¤ìŒì— ë°°ìš¸ ì•™ìƒë¸” ê¸°ë²•ì— ê¸°ì´ˆê°€ ëœë‹¤.

## ì‹¤ìŠµ ì „ ì „ì²˜ë¦¬
- 2009ë…„ ë§ì—ì„œ 2010ë…„ ì´ˆê¹Œì§€ H1N1 ë…ê°ê´€ë ¨ëœ ì„¤ë¬¸ì¡°ì‚¬

```py
import pandas as pd
from sklearn.model_selection import train_test_split

# ë°ì´í„° import
target = 'vacc_h1n1_f'
# target = 'vacc_seas_f'
train = pd.merge(pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train.csv'), 
                 pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train_labels.csv')[target], left_index=True, right_index=True)
test = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/test.csv')
sample_submission = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/submission.csv')

# í›ˆë ¨/ê²€ì¦ ë‚˜ëˆ„ê¸°
train, val = train_test_split(train, train_size=0.80, test_size=0.20, 
                              stratify=train[target], random_state=2)


train.shape, val.shape, test.shape
# ((33723, 39), (8431, 39), (28104, 38))

# íƒ€ê²Ÿì˜ ë¹„ìœ¨
train[target].value_counts(normalize=True)
'''
0    0.760935
1    0.239065
Name: vacc_h1n1_f, dtype: float64

í´ë˜ìŠ¤ê°€ 2ê°œ(0, 1)ì¸ ë¶„ë¥˜ ë¬¸ì œì´ë‹¤.
ê°€ì¥ í° ë²”ì£¼(0)ê°€ 76.15%
í´ë˜ìŠ¤ê°€ ë¶ˆê· í˜•(imbalanced)í•œ ë¶„ë¥˜ ë¬¸ì œ
'''

# ì¤‘ë³µëœ íŠ¹ì„± í™•ì¸
train.T.duplicated()
'''
h1n1_concern                   False
h1n1_knowledge                 False
behavioral_antiviral_meds      False
behavioral_avoidance           False
behavioral_face_mask           False
behavioral_wash_hands          False
behavioral_large_gatherings    False
behavioral_outside_home        False
behavioral_touch_face          False
doctor_recc_h1n1               False
doctor_recc_seasonal           False
chronic_med_condition          False
child_under_6_months           False
health_insurance               False
health_worker                  False
opinion_h1n1_vacc_effective    False
opinion_h1n1_risk              False
opinion_h1n1_sick_from_vacc    False
opinion_seas_vacc_effective    False
opinion_seas_risk              False
opinion_seas_sick_from_vacc    False
agegrp                         False
education_comp                 False
raceeth4_i                     False
sex_i                          False
inc_pov                        False
marital                        False
rent_own_r                     False
employment_status              False
census_region                  False
census_msa                     False
n_adult_r                      False
household_children             False
n_people_r                     False
employment_industry            False
employment_occupation          False
hhs_region                     False
state                          False
vacc_h1n1_f                    False
dtype: bool
'''

# ì¹´ë””ë„ë¦¬í‹° í™•ì¸
train.describe(exclude='number').T.sort_values(by='unique')
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 10 22 16](https://user-images.githubusercontent.com/79494088/129648752-65fa568f-fca0-4fd0-9181-1a5d479189d4.png)

```py
# ì¹´í…Œê³ ë¦¬ ë§ì´ ê°€ì§€ëŠ” íŠ¹ì„±ë“¤ì˜ ë²”ì£¼ í™•ì¸
train['employment_occupation'].value_counts()
'''
Management Occupations                                       1769
Office and Administrative Support Occupations                1556
Education, Training, and Library Occupations                 1286
Healthcare Practitioners and Technical Occupations           1200
Sales and Related Occupations                                1108
Business and Financial Operations Occupations                 764
Construction and Extraction Occupations                       538
Production Occupations                                        483
Transportation and Material Moving Occupations                483
Computer and Mathematical Occupations                         475
Food Preparation and Serving Related Occupations              405
Architecture and Engineering Occupations                      367
Arts, Design, Entertainment, Sports and Media Occupations     366
Personal Care and Service Occupations                         353
Community and Social Services Occupations                     335
Building and Grounds Cleaning and Maintenance Occupations     330
Installation, Maintenance, and Repair Occupations             299
Healthcare Support Occupations                                294
Not ascertained                                               268
Legal Occupations                                             242
Life, Physical, and Social Science Occupations                236
Protective Service Occupations                                229
Military Specific Occupations                                 158
Farming, Fishing, and Forestry Occupations                    106
Refused, classified                                            64
Name: employment_occupation, dtype: int64
'''

# íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
import numpy as np

def engineer(df):
    """íŠ¹ì„±ì„ ì—”ì§€ë‹ˆì–´ë§ í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    
    # ë†’ì€ ì¹´ë””ë„ë¦¬í‹°ë¥¼ ê°€ì§€ëŠ” íŠ¹ì„± ì œê±°
    selected_cols = df.select_dtypes(include=['number', 'object'])
    labels = selected_cols.nunique() # íŠ¹ì„±ë³„ ì¹´ë””ë„ë¦¬í‹° ë¦¬ìŠ¤íŠ¸
    selected_features = labels[labels <= 30].index.tolist() # ì¹´ë””ë„ë¦¬í‹°ê°€ 30ë³´ë‹¤ ì‘ì€ íŠ¹ì„±ë§Œ ì„ íƒ
    df = df[selected_features]
    
    # ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±
    behaviorals = [col for col in df.columns if 'behavioral' in col] 
    df['behaviorals'] = df[behaviorals].sum(axis=1)
    
    
    dels = [col for col in df.columns if ('employment' in col or 'seas' in col)]
    df.drop(columns=dels, inplace=True)
        
    return df


train = engineer(train)
val = engineer(val)
test = engineer(test)

# íƒ€ê²Ÿê³¼ íŠ¹ì„± ë¶„ë¦¬
features = train.drop(columns=[target]).columns

# í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ íŠ¹ì„±ê³¼ íƒ€ê²Ÿìœ¼ë¡œ ë¶„ë¦¬
X_train = train[features]
y_train = train[target]
X_val = val[features]
y_val = val[target]
X_test = test[features]
```



# 2ï¸âƒ£ ì‚¬ì´í‚·ëŸ¿ íŒŒì´í”„ë¼ì¸(Pipelines)
- ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ìŠ¤ì¼€ì¼ë§, ëª¨ë¸í•™ìŠµ ë“± ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì„¸ìŠ¤ì—ì„œ [íŒŒì´í”„ë¼ì¸(Pipelines)](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)ì„ ì‚¬ìš©í•˜ë©´ ì¤‘ë³µ ì½”ë“œë¥¼ ìµœì†Œí™”í•˜ì—¬ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆë‹¤.
- ì—¬ëŸ¬ ML ëª¨ë¸ì„ ê°™ì€ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ì— ì—°ê²°ì‹œí‚¬ ìˆ˜ ìˆë‹¤.
- ê·¸ë¦¬ë“œì„œì¹˜(grid search)(?)ë¥¼ í†µí•´ ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆë‹¤.
  - ê·¸ë¦¬ë“œì„œì¹˜ : ê´€ì‹¬ ìˆëŠ” ë§¤ê°œë³€ìˆ˜ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•©ì„ ì‹œë„í•˜ì—¬ ìµœì ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì°¾ëŠ” ë°©ë²•

```py
from category_encoders import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline

enc = OneHotEncoder()
imp_mean = SimpleImputer()
scaler = StandardScaler()
model_lr = LogisticRegression(n_jobs=-1)

X_train_encoded = enc.fit_transform(X_train)
X_train_imputed = imp_mean.fit_transform(X_train_encoded)
X_train_scaled = scaler.fit_transform(X_train_imputed)
model_lr.fit(X_train_scaled, y_train)

X_val_encoded = enc.transform(X_val)
X_val_imputed = imp_mean.transform(X_val_encoded)
X_val_scaled = scaler.transform(X_val_imputed)

# score method: Return the mean accuracy on the given test data and labels
print('ê²€ì¦ì„¸íŠ¸ ì •í™•ë„', model_lr.score(X_val_scaled, y_val))

X_test_encoded = enc.transform(X_test)
X_test_imputed = imp_mean.transform(X_test_encoded)
X_test_scaled = scaler.transform(X_test_imputed)

y_pred = model_lr.predict(X_test_scaled)

# ê²€ì¦ì„¸íŠ¸ ì •í™•ë„ 0.8185268651405527
```

- ì´ë¬ë˜ ì½”ë“œê°€ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ë©´

```py
pipe = make_pipeline(
    OneHotEncoder(), 
    SimpleImputer(), 
    StandardScaler(), 
    LogisticRegression(n_jobs=-1)
)
pipe.fit(X_train, y_train)

print('ê²€ì¦ì„¸íŠ¸ ì •í™•ë„', pipe.score(X_val, y_val))

y_pred = pipe.predict(X_test)

# ê²€ì¦ì„¸íŠ¸ ì •í™•ë„ 0.8185268651405527
```

- ì´ë ‡ê²Œ ì½”ë“œê°€ ê°„ê²°í•´ì§€ê³  ê°€ë…ì„±ì´ ì¦ê°€í•œë‹¤.

## íŒŒì´í”„ë¼ì¸ì—ì„œ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ë“±ê³¼ ê°™ì€ ì •ë³´ í™•ì¸í•˜ëŠ” ë°©ì‹
- `named_steps` ì†ì„±ì„ ì‚¬ìš©í•´ì„œ íŒŒì´í”„ë¼ì¸ì˜ ê° ìŠ¤í…ì— ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë‹¤.
  - ìœ ì‚¬ ë”•ì…”ë„ˆë¦¬ ê°ì²´(dictionary-like object)ë¡œ íŒŒì´í”„ë¼ì¸ ë‚´ ê³¼ì •ì— ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•œë‹¤.

```py
pipe.named_steps
'''
{'onehotencoder': OneHotEncoder(cols=['opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',
                     'opinion_h1n1_sick_from_vacc', 'agegrp', 'census_msa']),
 'simpleimputer': SimpleImputer(),
 'standardscaler': StandardScaler(),
 'logisticregression': LogisticRegression(n_jobs=-1)}
'''

import matplotlib.pyplot as plt

model_lr = pipe.named_steps['logisticregression']
enc = pipe.named_steps['onehotencoder']
encoded_columns = enc.transform(X_val).columns
coefficients = pd.Series(model_lr.coef_[0], encoded_columns)
plt.figure(figsize=(10,30))
coefficients.sort_values().plot.barh();
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 10 27 15](https://user-images.githubusercontent.com/79494088/129649091-c26e1e12-1063-4888-919c-f3ad0315a22c.png)

# 3ï¸âƒ£ ê²°ì •íŠ¸ë¦¬(Decision Tree)
- [ê²°ì •íŠ¸ë¦¬ëª¨ë¸](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)ì€ íŠ¹ì„±ë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ ìƒ˜í”Œì„ ë¶„ë¥˜í•´ ë‚˜ê°€ëŠ”ë° ê·¸ í˜•íƒœê°€ ë‚˜ë¬´ì˜ ê°€ì§€ê°€ ë»—ì–´ë‚˜ê°€ëŠ” ëª¨ìŠµê³¼ ë¹„ìŠ·í•´ì„œ ê²°ì •íŠ¸ë¦¬ë¼ëŠ” ì´ë¦„ì„ ê°–ê³  ìˆë‹¤.
- íŠ¹ì„±ë“¤ì˜ ìˆ˜ì¹˜ë¥¼ ê°€ì§€ê³  ì§ˆë¬¸ì„ í†µí•´ ì •ë‹µ í´ë˜ìŠ¤ë¥¼ ì°¾ì•„ëŠ” ê³¼ì •ì´ë‹¤. 
- ì§ˆë¬¸ì´ë‚˜ ë§ë‹¨ì˜ ì •ë‹µì„ ë…¸ë“œ(node)ë¼ í•˜ë©° ë…¸ë“œë¥¼ ì—°ê²°í•˜ëŠ” ì„ ì„ ì—£ì§€(edge)ë¼ í•œë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 10 30 47](https://user-images.githubusercontent.com/79494088/129649353-d7aa0d9e-0a6f-4efb-bf31-2b20614010c2.png)

- ê²°ì •íŠ¸ë¦¬ì˜ ê° ë…¸ë“œ(node)ëŠ” ë¿Œë¦¬(root)ë…¸ë“œ, ì¤‘ê°„(internal)ë…¸ë“œ, ë§ë‹¨(external, leaf, terminal) ë…¸ë“œë¡œ ë‚˜ë‰œë‹¤.
- ê²°ì •íŠ¸ë¦¬ëŠ” ë¶„ë¥˜ì™€ íšŒê·€ë¬¸ì œ ëª¨ë‘ ì ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.
- ê²°ì •íŠ¸ë¦¬ëŠ” ë°ì´í„°ë¥¼ ë¶„í• í•´ê°€ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
- ë¶„ë¥˜ ê³¼ì •ì€ ìƒˆë¡œìš´ ë°ì´í„°ê°€ íŠ¹ì • ë§ë‹¨ ë…¸ë“œì— ì†í•œë‹¤ëŠ” ì •ë³´ë¥¼ í™•ì¸í•œ ë’¤ ë§ë‹¨ë…¸ë“œì˜ ë¹ˆë„ê°€ ê°€ì¥ ë†’ì€ ë²”ì£¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•œë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 10 32 26](https://user-images.githubusercontent.com/79494088/129649483-d3cfbb09-cd78-4b16-886f-5f5d107444d9.png)

- ê²°ì •íŠ¸ë¦¬ëŠ” ë¶„ë¥˜ê³¼ì •ì„ íŠ¸ë¦¬êµ¬ì¡°ë¡œ ì§ê´€ì ìœ¼ë¡œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.
- ì—¬ëŸ¬ íŠ¸ë¦¬ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì•™ìƒë¸”(ensemble) ê¸°ë²•ì¸ ëœë¤í¬ë ˆìŠ¤íŠ¸(Random Forests)ì™€ ê·¸ë ˆë””ì–¸íŠ¸ë¶€ìŠ¤íŒ…íŠ¸ë¦¬(Gradint Boosted Trees) ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ ê²°ì •íŠ¸ë¦¬ê°€ ê¸°ì´ˆê°€ ëœë‹¤.

## ê²°ì •íŠ¸ë¦¬ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜
- ê²°ì •íŠ¸ë¦¬ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì€ ë…¸ë“œë¥¼ ì–´ë–»ê²Œ ë¶„í• í•˜ëŠ”ê°€ì— ëŒ€í•œ ë¬¸ì œì´ë‹¤.
- ë…¸ë“œ ë¶„í•  ë°©ë²•ì— ë”°ë¼ ë‹¤ë¥¸ ëª¨ì–‘ì˜ íŠ¸ë¦¬êµ¬ì¡°ê°€ ë§Œë“¤ì–´ì§€ê²Œ ë  ê²ƒì´ë‹¤.
- ê²°ì •íŠ¸ë¦¬ì˜ ë¹„ìš©í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³  ê·¸ê²ƒì„ ìµœì†Œí™” í•˜ë„ë¡ ë¶„í• í•˜ëŠ” ê²ƒì´ íŠ¸ë¦¬ëª¨ë¸ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì´ ëœë‹¤.
- íŠ¸ë¦¬í•™ìŠµì— ìì£¼ ì“°ì´ëŠ” ë¹„ìš©í•¨ìˆ˜ ì¤‘ ì§€ë‹ˆë¶ˆìˆœë„ì™€ ì—”íŠ¸ë¡œí”¼ê°€ ìˆë‹¤.

### ì§€ë‹ˆ ë¶ˆìˆœë„ì™€ ì—”íŠ¸ë¡œí”¼

#### ì§€ë‹ˆ ë¶ˆìˆœë„(Gini Impurity or Gini Index)

$${\displaystyle {I}_{G}(p)=\sum _{i=1}^{J}p_{i}(1-p_{i})=1-\sum _{i=1}^{J}{p_{i}}^{2}}$$

- íŠ¸ë¦¬ í•œ ë…¸ë“œì˜ ëª¨ë“  ìƒ˜í”Œì´ ê°™ì€ í´ë˜ìŠ¤ì— ì†í•´ìˆì„ ë•Œ ê°’ì´ 0ì´ ë˜ê³  ì´ ë•Œë¥¼ ìˆœìˆ˜í•˜ë‹¤ê³  ë§í•˜ëŠ”ë° ë²”ì£¼ë“¤ì´ ì„ì—¬ìˆì„ìˆ˜ë¡ ì´ ìˆ˜ì¹˜ê°€ ì»¤ì§€ê²Œ ë˜ì–´ìˆë‹¤.

#### ì—”íŠ¸ë¡œí”¼(Entropy)

$${\displaystyle \mathrm {H} (T)=\operatorname {I} _{E}\left(p_{1},p_{2},...,p_{J}\right)=-\sum _{i=1}^{J}{p_{i}\log _{2}p_{i}}}$$

- ì›ë˜ ì—´ì—­í•™ì—ì„œ ì“°ì´ëŠ” í‘œí˜„ì¸ë° ì§€ë‹ˆ ë¶ˆìˆœë„ì™€ ê°™ì´ í•œ ë…¸ë“œì—ì„œ ëª¨ë“  ìƒ˜í”Œì´ ê°™ì€ í´ë˜ìŠ¤ì¼ ë•Œ 0ì´ ëœë‹¤.
- ì‹¸ì´í‚·ëŸ°ì—ì„œ íŠ¸ë¦¬ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ ë””í´íŠ¸ë¡œ ì§€ë‹ˆ ë¶ˆìˆœë„ë¥¼ ë§ì´ ì“°ì§€ë§Œ ë”°ë¡œ ì—”íŠ¸ë¡œí”¼ë¥¼ ê³„ì‚°í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.
- ì—”íŠ¸ë¡œí”¼ê°€ ì¡°ê¸ˆ ë” ê· í˜•ì¡íŒ íŠ¸ë¦¬ë¥¼ ë§Œë“ ë‹¤ê³ ëŠ” í•˜ì§€ë§Œ ì§€ë‹ˆ ë¶ˆìˆœë„ê°€ ê³„ì‚°ì´ ì¡°ê¸ˆ ë” ë¹ ë¥´ê¸° ë•Œë¬¸ì— ë””í´íŠ¸ë¡œ ì§€ë‹ˆ ë¶ˆìˆœë„ë¥¼ ì‚¬ìš©í•œë‹¤.
- ê²°ì •íŠ¸ë¦¬ëŠ” ë¶„ë¥˜ê³¼ì •ì„ ì§ê´€ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
- ì—¬ê¸°ì„œ ë¶ˆìˆœë„(impurity) ë¼ëŠ” ê°œë…ì€ ì—¬ëŸ¬ ë²”ì£¼ê°€ ì„ì—¬ ìˆëŠ” ì •ë„ë¥¼ ì´ì•¼ê¸°í•œë‹¤.
- ì˜ˆë¥¼ë“¤ì–´ A, B ë‘ í´ë˜ìŠ¤ê°€ í˜¼í•©ëœ ë°ì´í„°ê°€ ìˆì„ ë•Œ (A, B) ë¹„ìœ¨ì´
  - (45%, 55%)ì¸ ìƒ˜í”Œ(ë‘ ë²”ì£¼ ìˆ˜ê°€ ë¹„ìŠ·)ì€ ë¶ˆìˆœë„ê°€ ë†’ì€ ê²ƒ
  - (80%, 20%)ì¸ ìƒ˜í”Œì´ ìˆë‹¤ë©´ ìƒëŒ€ì ìœ¼ë¡œ ìœ„ì˜ ìƒíƒœë³´ë‹¤ ë¶ˆìˆœë„ê°€ ë‚®ì€ ê²ƒ(ìˆœìˆ˜ë„(purity)ëŠ” ë†’ìŒ)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 12 39 41](https://user-images.githubusercontent.com/79494088/129659934-5abc5954-2bd0-4bbb-835b-20be82f40859.png)

- ë‘ ë¶ˆìˆœë„ì˜ ì°¨ì´ê°’ì„ ë¶ˆìˆœë„ì˜ ê°ì†Œê°’ì´ë¼ê³  í•˜ëŠ”ë° ì´ ê°’ì„ ìµœëŒ€í•œìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” íŠ¹ì„±ê³¼ ë¶„í• ì ì„ ì„ íƒí•´ì„œ ë°ì´í„°ë¡œ íŠ¸ë¦¬êµ¬ì¡°ë¥¼ ë§Œë“œëŠ” ê²ƒì´ íŠ¸ë¦¬í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.
- ì§€ë‹ˆë¶ˆìˆœë„ë‚˜ ì—”íŠ¸ë¡œí”¼ëŠ” ìœ„ì˜ ë¶ˆìˆœë„ ê°œë…ì—ì„œ ë³´ë©´ ëœë‹¤.
- ë¶ˆìˆœë„ê°€ ë‚®ì€ ê²½ìš° ì§€ë‹ˆë¶ˆìˆœë„ë‚˜ ì—”íŠ¸ë¡œí”¼ëŠ” ë‚®ì€ ê°’ì„ ê°€ì§€ê²Œ ëœë‹¤.
- ë…¸ë“œë¥¼ ë¶„í• í•˜ëŠ” ì‹œì ì—ì„œ ê°€ì¥ ë¹„ìš©í•¨ìˆ˜ë¥¼ ì¤„ì´ëŠ” ë¶„í• íŠ¹ì„±ê³¼ ë¶„í• ì§€ì ì„ ì°¾ì•„ë‚´ëŠ” í”„ë¡œì„¸ìŠ¤ê°€ í•„ìš”í•˜ë‹¤
- ë¶ˆìˆœë„ì˜ ê°ì†Œì •ë„ë¥¼ ì—”íŠ¸ë¡œí”¼ë¥¼ ì‚¬ìš©í•˜ë©´ ì •ë³´íšë“ì´ë¼ê³ ë„ ë§ì„ í•œë‹¤. **ì¦‰, ë¶ˆìˆœë„ ê°ì†Œê°€ í¬ë©´ ì •ë³´íšë“ì´ í¬ë‹¤.** 
- ë¶„í• ì— ì‚¬ìš©í•  íŠ¹ì„±ì´ë‚˜ ë¶„í• ì§€ì (ê°’)ì€ íƒ€ê²Ÿë³€ìˆ˜ë¥¼ ê°€ì¥ ì˜ êµ¬ë³„í•´ ì£¼ëŠ”(ë¶ˆìˆœë„ì˜ ê°ì†Œê°€ ìµœëŒ€ê°€ ë˜ëŠ”, ì •ë³´íšë“ì´ ê°€ì¥ í°)ê²ƒì„ ì„ íƒí•œë‹¤.
- ì •ë³´íšë“(Information Gain)ì€ íŠ¹ì •í•œ íŠ¹ì„±ì„ ì‚¬ìš©í•´ ë¶„í• í–ˆì„ ë•Œ ì—”íŠ¸ë¡œí”¼ì˜ ê°ì†ŒëŸ‰ì„ ëœ»í•œë‹¤.
  - ${\displaystyle IG(T,a)=\mathrm {H} {(T)}-\mathrm {H} {(T \vert a)}}$ = ë¶„í•  ì „ ë…¸ë“œ ë¶ˆìˆœë„ - ë¶„í•  í›„ ìì‹ë…¸ë“œë“¤ì˜ ë¶ˆìˆœë„
  
![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 12 46 53](https://user-images.githubusercontent.com/79494088/129660513-142cf518-59f5-4659-9b30-4bb4ab9cfc9d.png)

## ì‚¬ì´í‚·ëŸ° ì‚¬ìš© ê²°ì •íŠ¸ë¦¬ êµ¬í˜„
- íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ë©´ ìœ„ì—ì„œ ë³¸ ì½”ë“œì—ì„œ ë‹¨wl ë¶„ë¥˜ê¸°ë§Œ ë°”ê¾¸ì–´ì£¼ë©´ ëœë‹¤.
- ê²°ì •íŠ¸ë¦¬ì—ì„œëŠ” StandardScalerëŠ” ë„ì›€ì´ ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì œì™¸í•˜ê³  í•™ìŠµí•œë‹¤.
  - ì´ìœ  : í•˜ë‚˜ì˜ í”¼ì³ì—ì„œë§Œ êµ¬ë¶„ì„ í•˜ê¸° ë•Œë¬¸ì—(?)

```py
from sklearn.tree import DecisionTreeClassifier

# ê²°ì •íŠ¸ë¦¬ì˜ ì¥ì  ì¤‘ í•œê°€ì§€ëŠ” ì´ì „ì— ë°°ìš´ íšŒê·€ëª¨ë¸ì— ë¹„í•´ì„œ ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •ì¤‘ ëœ ì‹ ê²½ì¨ë„ ë˜ëŠ” ì ë“¤ì´ ìˆë‹¤.
# ì˜ˆë¥¼ ë“¤ì–´ ë°ì´í„°ì˜ íŠ¹ì„±ë“¤ì˜ ìŠ¤ì¼€ì¼ì„ ë§ì¶°ì¤„ í•„ìš”ê°€ ì—†ë‹¤.

pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True),  
    SimpleImputer(), 
    DecisionTreeClassifier(random_state=1, criterion='entropy')
)

pipe.fit(X_train, y_train)
print('í›ˆë ¨ ì •í™•ë„: ', pipe.score(X_train, y_train))
print('ê²€ì¦ ì •í™•ë„: ', pipe.score(X_val, y_val))
# í›ˆë ¨ ì •í™•ë„:  0.9908667674880646
# ê²€ì¦ ì •í™•ë„:  0.7572055509429486

y_val.value_counts(normalize=True)
'''
0    0.761001
1    0.238999
Name: vacc_h1n1_f, dtype: float64
'''
```

- í•™ìŠµë°ì´í„°ëŠ” 99%ì´ìƒ ë§ì¶”ëŠ”ë° ê²€ì¦ì„¸íŠ¸ì˜ ì •í™•ë„ëŠ” ë‹¤ìˆ˜ë²”ì£¼(0)ì˜ ë¹„ìœ¨ê³¼ ê°™ê²Œ ë‚˜ì˜¨ë‹¤.
- í™•ì‹¤í•œ ê³¼ì í•¨ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ëŒ€ë¶€ë¶„ 0ìœ¼ë¡œ ì˜ˆì¸¡í–ˆë‹¤.
- ë‹¤ìˆ˜ ë²”ì£¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì´ ê¸°ì¤€ëª¨ë¸ì´ë¼ê³  ë³´ë©´, ê¸°ì¤€ëª¨ë¸ê³¼ ë™ì¼í•œ ì„±ëŠ¥ì´ ë‚˜ì˜¤ë¯€ë¡œ í•™ìŠµì´ ì˜ ë˜ì—ˆë‹¤ê³  íŒë‹¨í•  ìˆ˜ ì—†ë‹¤.

### ë§Œë“¤ì–´ì§„ íŠ¸ë¦¬ í™•ì¸
- ê±°ëŒ€í•œ íŠ¸ë¦¬ëŠ” í•œ ëˆˆì— ê´€ì°°í•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì— depth ì œí•œì„ 3ìœ¼ë¡œ ë‘ê³  ê²°ì •íŠ¸ë¦¬ë¥¼ ê·¸ë¦°ë‹¤.

```py
# graphviz ì„¤ì¹˜ë°©ë²•: conda install -c conda-forge python-graphviz
import graphviz
from sklearn.tree import export_graphviz

model_dt = pipe.named_steps['decisiontreeclassifier']
enc = pipe.named_steps['onehotencoder']
encoded_columns = enc.transform(X_val).columns

dot_data = export_graphviz(model_dt
                          , max_depth=3
                          , feature_names=encoded_columns
                          , class_names=['no', 'yes']
                          , filled=True
                          , proportion=True)


display(graphviz.Source(dot_data))
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 12 54 44](https://user-images.githubusercontent.com/79494088/129661124-9c89d52b-2102-41a1-a2be-89a7638ab297.png)

### ê³¼ì í•© í•´ê²°
- ë³µì¡í•œ íŠ¸ë¦¬ëŠ” ê³¼ì í•© ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ë•Œë¬¸ì— ë³µì¡ë„ë¥¼ ë‚®ì¶”ì–´ ì¼ë°˜í™”ë¥¼ ìœ ë„í•œë‹¤.
- íŠ¸ë¦¬ì˜ ë³µì¡ë„ë¥¼ ì¤„ì´ê¸°ìœ„í•´ ìì£¼ ì‚¬ìš©í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤
  - min_samples_split
  - min_samples_leaf
  - max_depth

```py
# min_samples_leafë¥¼ ì‚¬ìš©í•´ ë§ë‹¨ ë…¸ë“œ(external node)ì— ìµœì†Œí•œ ì¡´ì¬í•´ì•¼ í•˜ëŠ” ìƒ˜í”Œë“¤ì˜ ìˆ˜ë¥¼ ì •í•œë‹¤.
pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True), 
    SimpleImputer(), 
    DecisionTreeClassifier(min_samples_leaf=10, random_state=2)
)

pipe.fit(X_train, y_train)
print('í›ˆë ¨ ì •í™•ë„', pipe.score(X_train, y_train))
print('ê²€ì¦ ì •í™•ë„', pipe.score(X_val, y_val))
# í›ˆë ¨ ì •í™•ë„ 0.8577528689618361
# ê²€ì¦ ì •í™•ë„ 0.8029889692800379

# ë¹„ìŠ·í•œ ë°©ë²•ìœ¼ë¡œ max_depth ì œí•œ
pipe = make_pipeline(
    OneHotEncoder(use_cat_names=True), 
    SimpleImputer(), 
    DecisionTreeClassifier(max_depth=6, random_state=2)
)

pipe.fit(X_train, y_train)
print('í›ˆë ¨ ì •í™•ë„', pipe.score(X_train, y_train))
print('ê²€ì¦ ì •í™•ë„', pipe.score(X_val, y_val))
# í›ˆë ¨ ì •í™•ë„ 0.8283367434688491
# ê²€ì¦ ì •í™•ë„ 0.8269481674771676
```

### íŠ¹ì„± ì¤‘ìš”ë„(Feature importance)
- ì„ í˜•ëª¨ë¸ì—ì„œ íšŒê·€ ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤ë©´, ê²°ì •íŠ¸ë¦¬ì—ì„œëŠ” ëŒ€ì‹  íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ í™•ì¸í•œë‹¤.
- íšŒê·€ê³„ìˆ˜ì™€ ë‹¬ë¦¬ íŠ¹ì„±ì¤‘ìš”ë„ëŠ” í•­ìƒ ì–‘ìˆ˜ê°’ì„ ê°€ì§„ë‹¤.
- ì´ ê°’ì„ í†µí•´ íŠ¹ì„±ì´ ì–¼ë§ˆë‚˜ ì¼ì° ê·¸ë¦¬ê³  ìì£¼ ë¶„ê¸°ì— ì‚¬ìš©ë˜ëŠ”ì§€ ê²°ì •ëœë‹¤.

```py
model_dt = pipe.named_steps['decisiontreeclassifier']

importances = pd.Series(model_dt.feature_importances_, encoded_columns)
plt.figure(figsize=(10,30))
importances.sort_values().plot.barh();
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 12 59 47](https://user-images.githubusercontent.com/79494088/129661531-de9c9e0e-1bac-4a48-aaa3-0a426f6ddcbc.png)

- ê²°ì •íŠ¸ë¦¬ëª¨ë¸ì€ ì„ í˜•ëª¨ë¸ê³¼ ë‹¬ë¦¬ ë¹„ì„ í˜•, ë¹„ë‹¨ì¡°(Non-monotonic), íŠ¹ì„±ìƒí˜¸ì‘ìš©(Feature interactions) íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„° ë¶„ì„ì— ìš©ì´í•˜ë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 00 57](https://user-images.githubusercontent.com/79494088/129661625-c95ea119-5943-4140-9898-9c88a4a99ddf.png)

- [ë‹¨ì¡°(Monotonic)](https://en.wikipedia.org/wiki/Monotonic_function), ë¹„ë‹¨ì¡°(Non-monotonic) í•¨ìˆ˜(?)
  - ë‹¨ì¡°í•¨ìˆ˜ : ì£¼ì–´ì§„ ìˆœì„œë¥¼ ë³´ì¡´í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. ê¸°í•˜í•™ì ìœ¼ë¡œ, ì‹¤ìˆ˜ ë‹¨ì¡° í•¨ìˆ˜ì˜ ê·¸ë˜í”„ëŠ” ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¤„ê³§ ìƒìŠ¹í•˜ê±°ë‚˜ ì¤„ê³§ í•˜ê°•í•œë‹¤. ëŒ€ìˆ˜í•™ì ìœ¼ë¡œ, ë‹¨ì¡° í•¨ìˆ˜ëŠ” ë‘ ìˆœì„œ ì§‘í•© ì‚¬ì´ì˜ ì¤€ë™í˜•ì´ë‹¤.
- íŠ¹ì„±ìƒí˜¸ì‘ìš©
  - íŠ¹ì„±ë“¤ë¼ë¦¬ ì„œë¡œ ìƒí˜¸ì‘ìš©ì„ í•˜ëŠ” ê²½ìš°ë¥¼ ë§í•œë‹¤.
  - íšŒê·€ë¶„ì„ì—ì„œëŠ” ì„œë¡œ ìƒí˜¸ì‘ìš©ì´ ë†’ì€ íŠ¹ì„±ë“¤ì´ ìˆìœ¼ë©´ ê°œë³„ ê³„ìˆ˜ë¥¼ í•´ì„í•˜ëŠ”ë° ì–´ë ¤ì›€ì´ ìˆê³  í•™ìŠµì´ ì˜¬ë°”ë¥´ê²Œ ë˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ íŠ¸ë¦¬ëª¨ë¸ì€ ì´ëŸ° ìƒí˜¸ì‘ìš©ì„ ìë™ìœ¼ë¡œ ê±¸ëŸ¬ë‚´ëŠ” íŠ¹ì§•ì´ ìˆë‹¤.

# 4ï¸âƒ£ íŠ¹ì„±ìƒí˜¸ì‘ìš©(Feature Interaction)
- ì˜ˆì œ ë°ì´í„°ë¡œ íŠ¹ì„±ìƒí˜¸ì‘ìš©ì„ ë§Œë“¤ì–´ ì„ í˜•íšŒê·€ëª¨ë¸ê³¼ íŠ¸ë¦¬ëª¨ë¸ì˜ ì°¨ì´ë¥¼ í™•ì¸
  - ê¸°ë³¸ê°€ê²© : 150,000
  - Location : goodì¼ ë•Œ +50,000
  - Size : bigì¼ ë•Œ +100,000

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 08 00](https://user-images.githubusercontent.com/79494088/129662135-a9f70593-b27e-44a6-ad7d-3550659ad457.png)

  - good and bigì¸ ê²½ìš° +100,000 ê·œì¹™ ì¶”ê°€(íŠ¹ì„±ìƒí˜¸ì‘ìš©)
  
![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 08 43](https://user-images.githubusercontent.com/79494088/129662175-6b554c1b-c8e3-45f0-a032-29a4b062dd4e.png)

```py
cols = ['location','size','price']
# location: 1:good, 0:bad
# size: 1:big, 0:small
# bigì€ smallë³´ë‹¤ 100,000 ë¹„ì‹¸ê³ , goodì€ badë³´ë‹¤ 50,000 ê°€ê²©ì´ ë” ë‚˜ê°‘ë‹ˆë‹¤.
features = [[1, 1], 
            [1, 0], 
            [0, 1], 
            [0, 0]]

price = [[300000], 
        [200000], 
        [250000], 
        [150000]]

X_house = pd.DataFrame(columns=cols[:2], data=features)
y_house = pd.DataFrame(columns=[cols[2]], data=price)
```

## ì„ í˜•íšŒê·€

```py
from sklearn.linear_model import LinearRegression
linear = LinearRegression()
linear.fit(X_house, y_house)
print('R2: ', linear.score(X_house, y_house))
print('Intercept: ', linear.intercept_[0])
print('Coefficients')
pd.DataFrame(columns=cols[:2], data=linear.coef_)
'''
R2:  1.0
Intercept:  150000.0
Coefficients
'''
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 10 59](https://user-images.githubusercontent.com/79494088/129662373-ef3adddc-fe5e-4cf8-a8c0-0d6689a049d3.png)

## íšŒê·€íŠ¸ë¦¬

```py
import graphviz
## jupyterlab ì‚¬ìš©ì‹œ: jupyter labextension install @jupyter-widgets/jupyterlab-manager
from ipywidgets import interact
from sklearn.tree import DecisionTreeRegressor, export_graphviz

# íŠ¸ë¦¬êµ¬ì¡° ê·¸ë¦¬ëŠ” í•¨ìˆ˜
def show_tree(tree, colnames):
    dot = export_graphviz(tree, feature_names=colnames, filled=True, rounded=True)   
    return graphviz.Source(dot)

from sklearn.tree import DecisionTreeRegressor
tree = DecisionTreeRegressor(criterion="mae")
tree.fit(X_house, y_house)
print('R2', tree.score(X_house, y_house))
show_tree(tree, colnames=X_house.columns)
# R2 1.0
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 12 10](https://user-images.githubusercontent.com/79494088/129662462-4d749d75-c11a-4f80-ab8e-28381f5ac11e.png)

## ë°ì´í„°ì— íŠ¹ì„±ìƒí˜¸ì‘ìš©ì´ ì¡´ì¬í•˜ë„ë¡ ìˆ˜ì •

```py
y_house.loc[0, 'price'] = 400000
y_house
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 14 46](https://user-images.githubusercontent.com/79494088/129662676-b4245459-6d5c-4dba-a0eb-f0d216fa5b2d.png)

### ì„ í˜•íšŒê·€

```py
linear = LinearRegression()
linear.fit(X_house, y_house)
print('R2: ', linear.score(X_house, y_house))
print('Intercept: ', linear.intercept_[0])
print('Coefficients')
pd.DataFrame(columns=cols[:2], data=linear.coef_)
'''
R2:  0.9285714285714286
Intercept:  125000.00000000003
Coefficients
'''
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 15 50](https://user-images.githubusercontent.com/79494088/129662751-8ef1f7ce-0ef9-44a4-99a6-32fd9b118850.png)

### íšŒê·€íŠ¸ë¦¬

```py
tree = DecisionTreeRegressor(criterion="mae")
tree.fit(X_house, y_house)
print('R2', tree.score(X_house, y_house))
show_tree(tree, colnames=X_house.columns)
# R2 1.0
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 16 28](https://user-images.githubusercontent.com/79494088/129662790-43d61bfa-f5de-4408-a296-afc0a500d3d4.png)

- íŠ¸ë¦¬ëª¨ë¸ì€ ì„ í˜•íšŒê·€ëª¨ë¸ê³¼ ë‹¬ë¦¬ íŠ¹ì„±ìƒí˜¸ì‘ìš©ì—ë„ ë¬¸ì œì—†ì´ ê°€ê²©ì„ ì˜ˆì¸¡í•œë‹¤.

## ê²°ì •íŠ¸ë¦¬ë¥¼ ë¹„ì„ í˜• íšŒê·€ë¬¸ì œì— ì ìš©

```py
columns = ['mobility', 'density']
data = [[80.574, -3.067]
,[84.248, -2.981]
,[87.264, -2.921]
,[87.195, -2.912]
,[89.076, -2.84]
,[89.608, -2.797]
,[89.868, -2.702]
,[90.101, -2.699]
,[92.405, -2.633]
,[95.854, -2.481]
,[100.696, -2.363]
,[101.06, -2.322]
,[401.672, -1.501]
,[390.724, -1.46]
,[567.534, -1.274]
,[635.316, -1.212]
,[733.054, -1.1]
,[759.087, -1.046]
,[894.206, -0.915]
,[990.785, -0.714]
,[1090.109, -0.566]
,[1080.914, -0.545]
,[1122.643, -0.4]
,[1178.351, -0.309]
,[1260.531, -0.109]
,[1273.514, -0.103]
,[1288.339, 0.01]
,[1327.543, 0.119]
,[1353.863, 0.377]
,[1414.509, 0.79]
,[1425.208, 0.963]
,[1421.384, 1.006]
,[1442.962, 1.115]
,[1464.35, 1.572]
,[1468.705, 1.841]
,[1447.894, 2.047]
,[1457.628, 2.2]]

thurber = pd.DataFrame(columns=columns, data=data)

# ì‹œê°í™”
thurber.plot('mobility', 'density', kind='scatter', title='Thurber');
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 17 56](https://user-images.githubusercontent.com/79494088/129662894-68b54cb4-543e-49e6-820c-d38ba9b50db1.png)

### ì„ í˜•íšŒê·€

```py
X_thurber = thurber[['mobility']]
y_thurber = thurber['density']
linear = LinearRegression()
linear.fit(X_thurber, y_thurber)
print('R2: ', linear.score(X_thurber, y_thurber))
ax = thurber.plot('mobility', 'density', kind='scatter', title='Thurber')
ax.plot(X_thurber, linear.predict(X_thurber));
# R2:  0.9210137417351627
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 19 20](https://user-images.githubusercontent.com/79494088/129662991-c9c65869-8a24-4ed1-8336-6b9013e064db.png)

### íŠ¸ë¦¬íšŒê·€

```py
from ipywidgets import interact
from sklearn.tree import DecisionTreeRegressor, export_graphviz

def thurber_tree(max_depth=1):
    tree = DecisionTreeRegressor(max_depth=max_depth)
    tree.fit(X_thurber, y_thurber)
    print('R2: ', tree.score(X_thurber, y_thurber))
    ax = thurber.plot('mobility', 'density', kind='scatter', title='Thuber')
    ax.step(X_thurber, tree.predict(X_thurber), where='mid')
    plt.show()
    display(show_tree(tree, colnames=['mobility']))

interact(thurber_tree, max_depth=(1,6,1));
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 21 56](https://user-images.githubusercontent.com/79494088/129663175-9d2a4d6a-3da5-426d-9c0e-2d76789d528c.png)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-17 13 22 05](https://user-images.githubusercontent.com/79494088/129663192-fc3ac106-f75f-422f-92c6-59ef5959c799.png)

- max_depth = 1ì¸ ê²½ìš°ëŠ” ì„ í˜•íšŒê·€ ë³´ë‹¤ ì„±ëŠ¥ì´ ì•ˆ ì¢‹ì•„ ë³´ì´ì§€ë§Œ max_depthë¥¼ ë”í•  ìˆ˜ë¡ ì„ ì— ì í•©ì´ ë˜ì–´ ë¹„ì„ í˜• ë°ì´í„°ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆìŒì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
