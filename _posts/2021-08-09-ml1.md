---
title: '[Linear Models] ì„ í˜•íšŒê·€(Linear Regression)'
description: ì„ í˜•íšŒê·€ëª¨ë¸ê³¼ ì§€ë„í•™ìŠµì„ ì´í•´í•˜ê³  íšŒê·€ëª¨ë¸ì— ê¸°ì¤€ëª¨ë¸ì„ ì„¤ì •í•˜ë©° Scikit-learnì„ ì´ìš©í•´ ì„ í˜•íšŒê·€ëª¨ë¸ì„ ë§Œë“¤ê³  ì‚¬ìš©í•˜ë©° í•´ì„
categories:
 - Machine Learning
tags: [Machine Learning, Linear Models, Supervised Learning, ì„ í˜•íšŒê·€ëª¨ë¸, ì§€ë„í•™ìŠµ, ê¸°ì¤€ëª¨ë¸, Scikit learn]
mathjax: enable
# 0ï¸âƒ£1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£4ï¸âƒ£5ï¸âƒ£6ï¸âƒ£7ï¸âƒ£8ï¸âƒ£9ï¸âƒ£ğŸ”Ÿ
---

# 1ï¸âƒ£ ë¨¸ì‹  ëŸ¬ë‹(Machine Learning)
- AIëŠ” ë°”ë¡œ ë¨¸ì‹  ëŸ¬ë‹(Machine Learning)ê³¼ ë¨¸ì‹  ëŸ¬ë‹ì˜ í•œ ê°ˆë˜ì¸ ë”¥ ëŸ¬ë‹(Deep Learning)ì„ ì˜ë¯¸
- ë¨¸ì‹  ëŸ¬ë‹ì€ ì´ë¯¸ì§€ ì¸ì‹, ì˜ìƒ ì²˜ë¦¬, ì•ŒíŒŒê³ ì™€ ê°™ì€ ë¶„ì•¼ ë¿ë§Œ ì•„ë‹ˆë¼ ìì—°ì–´ ì²˜ë¦¬ì— ìˆì–´ì„œë„ ìœ ìš©í•˜ê²Œ ì“°ì¸ë‹¤.
- íŠ¹íˆ ë¨¸ì‹  ëŸ¬ë‹ì˜ í•œ ê°ˆë˜ì¸ ë”¥ ëŸ¬ë‹ì€ ê¸°ì¡´ì˜ í†µê³„ ê¸°ë°˜ì—ì„œ ì ‘ê·¼í–ˆë˜ ìì—°ì–´ ì²˜ë¦¬ì˜ ì„±ëŠ¥ì„ í›¨ì”¬ ë›°ì–´ ë„˜ëŠ” ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆì–´, í˜„ì¬ì— ì´ë¥´ëŸ¬ì„œëŠ” ìì—°ì–´ ì²˜ë¦¬ì— ìˆì–´ ë”¥ ëŸ¬ë‹ì€ í•„ìˆ˜ê°€ ë˜ì—ˆë‹¤.

## ë¨¸ì‹ ëŸ¬ë‹ì´ë€?

### ë¨¸ì‹ ëŸ¬ë‹ì´ ì•„ë‹Œ ì ‘ê·¼ ë°©ë²•ì˜ í•œê³„
- ê¸°ì¡´ì˜ í”„ë¡œê·¸ë˜ë° ì ‘ê·¼ ë°©ë²•ìœ¼ë¡œ ê³ ì–‘ì´ë‚˜ ê°•ì•„ì§€ë¥¼ íŒë³„í•˜ê¸° ì–´ë µë‹¤.
- ì• ì´ˆì— ìˆ«ìë¥¼ ì •ë ¬í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ëª…í™•í•œ ì•Œê³ ë¦¬ì¦˜ì´ ì• ì´ˆì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.

### ë¨¸ì‹ ëŸ¬ë‹ì€ ê¸°ì¡´ í”„ë¡œê·¸ë˜ë°ì˜ í•œê³„ì— ëŒ€í•œ í•´ê²°ì±…

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 21 13 48](https://user-images.githubusercontent.com/79494088/128704412-002ed126-1490-4840-8938-9b5b94a630b9.png)

## ë¨¸ì‹ ëŸ¬ë‹ í†ºì•„ë³´ê¸°

### ë¨¸ì‹ ëŸ¬ë‹ëª¨ë¸ì˜ í‰ê°€

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 21 22 54](https://user-images.githubusercontent.com/79494088/128705436-3fe10e18-fa53-4ee2-9424-127724e72bef.png)

- ì‹¤ì œ ëª¨ë¸ì„ í‰ê°€í•˜ê¸° ìœ„í•´ì„œ ë°ì´í„°ë¥¼ í›ˆë ¨ìš©, ê²€ì¦ìš©, í…ŒìŠ¤íŠ¸ìš© ì´ë ‡ê²Œ ì„¸ ê°€ì§€ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì 
- ê²€ì¦ìš© ë°ì´í„°ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìš©ë„ê°€ ì•„ë‹ˆë¼, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¡°ì •í•˜ê¸° ìœ„í•œ ìš©ë„<br>
ê³¼ì í•©ì´ ë˜ê³  ìˆëŠ”ì§€ íŒë‹¨í•˜ê±°ë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ì¡°ì •ì„ ìœ„í•œ ìš©ë„
- í•˜ì´í¼íŒŒë¼ë¯¸í„°(ì´ˆë§¤ê°œë³€ìˆ˜)ë€ ê°’ì— ë”°ë¼ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì˜í–¥ì„ ì£¼ëŠ” ë§¤ê°œë³€ìˆ˜
- ê°€ì¤‘ì¹˜ì™€ í¸í–¥ê³¼ ê°™ì€ í•™ìŠµì„ í†µí•´ ë°”ë€Œì–´ì ¸ê°€ëŠ” ë³€ìˆ˜ëŠ” ë§¤ê°œë³€ìˆ˜
- í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ë§¤ê°œë³€ìˆ˜ì˜ ê°€ì¥ í° ì°¨ì´ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ë³´í†µ ì‚¬ìš©ìê°€ ì§ì ‘ ì •í•´ì¤„ ìˆ˜ ìˆëŠ” ë³€ìˆ˜
- í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì‚¬ëŒì´ ì •í•˜ëŠ” ë³€ìˆ˜ì¸ ë°˜ë©´, ë§¤ê°œë³€ìˆ˜ëŠ” ê¸°ê³„ê°€ í›ˆë ¨ì„ í†µí•´ì„œ ë°”ê¾¸ëŠ” ë³€ìˆ˜
- í›ˆë ¨ìš© ë°ì´í„°ë¡œ í›ˆë ¨ì„ ëª¨ë‘ ì‹œí‚¨ ëª¨ë¸ì€ ê²€ì¦ìš© ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ë¥¼ ê²€ì¦í•˜ë©° í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹(tuning)í•œë‹¤.
- ì´ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ê²€ì¦ìš© ë°ì´í„°ë¡œ ì •í™•ë„ê°€ ê²€ì¦ë˜ëŠ” ê³¼ì •ì—ì„œ ì ì°¨ ê²€ì¦ìš© ë°ì´í„°ì— ì ì  ë§ì¶”ì–´ì ¸ ê°€ê¸° ì‹œì‘í•œë‹¤.
- ê²€ì¦ì´ ëë‚¬ë‹¤ë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ëª¨ë¸ì˜ ì§„ì§œ ì„±ëŠ¥ì„ í‰ê°€
- í›ˆë ¨ ë°ì´í„°ëŠ” ë¬¸ì œì§€, ê²€ì¦ ë°ì´í„°ëŠ” ëª¨ì˜ê³ ì‚¬, í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì‹¤ë ¥ì„ ìµœì¢…ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ìˆ˜ëŠ¥ ì‹œí—˜

### ë¶„ë¥˜(Classification)ì™€ íšŒê·€(Regression)
- ì„ í˜• íšŒê·€ë¥¼ í†µí•´ íšŒê·€ ë¬¸ì œì— ëŒ€í•´ì„œ í•™ìŠµ
- ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ í†µí•´ (ì´ë¦„ì€ íšŒê·€ì´ì§€ë§Œ) ë¶„ë¥˜ ë¬¸ì œë¥¼ í•™ìŠµ

#### 1. ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ(Binary Classification)
- ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ì„œ ë‘˜ ì¤‘ í•˜ë‚˜ì˜ ë‹µì„ ì •í•˜ëŠ” ë¬¸ì œ
- EX) ì‹œí—˜ ì„±ì ì— ëŒ€í•´ì„œ í•©ê²©, ë¶ˆí•©ê²©ì¸ì§€ íŒë‹¨í•˜ê³  ë©”ì¼ë¡œë¶€í„° ì •ìƒ ë©”ì¼, ìŠ¤íŒ¸ ë©”ì¼ì¸ì§€ë¥¼ íŒë‹¨í•˜ëŠ” ë¬¸ì œ

#### 2. ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜(Multi-class Classification)
- ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ì„œ ë‘ ê°œ ì´ìƒì˜ ì •í•´ì§„ ì„ íƒì§€ ì¤‘ì—ì„œ ë‹µì„ ì •í•˜ëŠ” ë¬¸ì œ
- EX) ì„œì  ì•„ë¥´ë°”ì´íŠ¸ë¥¼ í•˜ëŠ”ë° ê³¼í•™, ì˜ì–´, IT, í•™ìŠµì§€, ë§Œí™”ë¼ëŠ” ë ˆì´ë¸”ì´ ê°ê° ë¶™ì—¬ì ¸ ìˆëŠ” 5ê°œì˜ ì±…ì¥ì´ ìˆë‹¤. ìƒˆ ì±…ì´ ì…ê³ ë˜ë©´, ì´ ì±…ì€ ë‹¤ì„¯ ê°œì˜ ì±…ì¥ ì¤‘ì—ì„œ ë¶„ì•¼ì— ë§ëŠ” ì ì ˆí•œ ì±…ì¥ì— ì±…ì„ ë„£ì–´ì•¼ í•œë‹¤. ì´ ë•Œì˜ ë‹¤ì„¯ ê°œì˜ ì„ íƒì§€ë¥¼ ì£¼ë¡œ ì¹´í…Œê³ ë¦¬ ë˜ëŠ” ë²”ì£¼ ë˜ëŠ” í´ë˜ìŠ¤ë¼ê³  í•˜ë©°, ì£¼ì–´ì§„ ì…ë ¥ìœ¼ë¡œë¶€í„° ì •í•´ì§„ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•˜ëŠ” ê²ƒì„ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œë¼ê³  í•œë‹¤.

#### 3. íšŒê·€ ë¬¸ì œ(Regression)
- ë¶„ë¥˜ ë¬¸ì œì²˜ëŸ¼ 0 ë˜ëŠ” 1ì´ë‚˜ ê³¼í•™ ì±…ì¥, IT ì±…ì¥ ë“±ê³¼ ê°™ì´ ë¶„ë¦¬ëœ(ë¹„ì—°ì†ì ì¸) ë‹µì´ ê²°ê³¼ê°€ ì•„ë‹ˆë¼ ì—°ì†ëœ ê°’ì„ ê²°ê³¼ë¡œ ê°€ì§„ë‹¤.
- EX) ì˜ˆë¥¼ ë“¤ì–´ ì‹œí—˜ ì„±ì ì„ ì˜ˆì¸¡í•˜ëŠ”ë° 5ì‹œê°„ ê³µë¶€í•˜ì˜€ì„ ë•Œ 80ì , 5ì‹œê°„ 1ë¶„ ê³µë¶€í•˜ì˜€ì„ ë•ŒëŠ” 80.5ì , 7ì‹œê°„ ê³µë¶€í•˜ì˜€ì„ ë•ŒëŠ” 90ì  ë“±ì´ ë‚˜ì˜¤ëŠ” ê²ƒê³¼ ê°™ì€ ë¬¸ì œê°€ ìˆë‹¤. ê·¸ ì™¸ì—ë„ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì£¼ê°€ ì˜ˆì¸¡, ìƒì‚°ëŸ‰ ì˜ˆì¸¡, ì§€ìˆ˜ ì˜ˆì¸¡ ë“±ì´ ì´ì— ì†í•œë‹¤.

### ì§€ë„ í•™ìŠµ(Supervised Learning)ê³¼ ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)

#### 1. ì§€ë„ í•™ìŠµ
- ë ˆì´ë¸”(Label)ì´ë¼ëŠ” ì •ë‹µê³¼ í•¨ê»˜ í•™ìŠµí•˜ëŠ” ê²ƒ
- $y$, ì‹¤ì œê°’ ë“±ìœ¼ë¡œ ë¶€ë¥´ê¸°ë„ í•œë‹¤.
- ì´ë•Œ ê¸°ê³„ëŠ” ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ì¸ ì˜¤ì°¨ë¥¼ ì¤„ì´ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ í•˜ê²Œ ë˜ëŠ”ë° ì˜ˆì¸¡ê°’ì€ $\hat{y}$ê³¼ ê°™ì´ í‘œí˜„í•˜ê¸°ë„ í•œë‹¤.

#### 2. ë¹„ì§€ë„ í•™ìŠµ
- ë ˆì´ë¸”ì´ ì—†ì´ í•™ìŠµí•˜ëŠ” ê²ƒ
- EX) í´ëŸ¬ìŠ¤í„°ë§

### ìƒ˜í”Œ(Sample)ê³¼ íŠ¹ì„±(Feature)
- ë§ì€ ë¨¸ì‹  ëŸ¬ë‹ ë¬¸ì œê°€ 1ê°œ ì´ìƒì˜ ë…ë¦½ ë³€ìˆ˜ $x$ë¥¼ ê°€ì§€ê³  ì¢…ì† ë³€ìˆ˜ $y$ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œ
- ë§ì€ ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ë“¤, íŠ¹íˆ ì¸ê³µ ì‹ ê²½ë§ ëª¨ë¸ì€ ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜, ê°€ì¤‘ì¹˜, í¸í–¥ ë“±ì„ í–‰ë ¬ ì—°ì‚°ì„ í†µí•´ ì—°ì‚°í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.
- ë…ë¦½ ë³€ìˆ˜ $x$ì˜ í–‰ë ¬ì„ Xë¼ê³  í•˜ì˜€ì„ ë•Œ, ë…ë¦½ ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ nê°œì´ê³  ë°ì´í„°ì˜ ê°œìˆ˜ê°€ mì¸ í–‰ë ¬ X

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 21 54 25](https://user-images.githubusercontent.com/79494088/128709351-926b3dd3-ee4f-4b8e-bdd5-d54bd32a3e41.png)

- ì´ë•Œ ë¨¸ì‹  ëŸ¬ë‹ì—ì„œëŠ” í•˜ë‚˜ì˜ ë°ì´í„°, í•˜ë‚˜ì˜ í–‰ì„ ìƒ˜í”Œ(Sample)ì´ë¼ê³  ë¶€ë¥¸ë‹¤.(ë°ì´í„°ë² ì´ìŠ¤ì—ì„œëŠ” ë ˆì½”ë“œë¼ê³  ë¶€ë¥´ëŠ” ë‹¨ìœ„)
- ì¢…ì† ë³€ìˆ˜ $y$ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ê°ê°ì˜ ë…ë¦½ ë³€ìˆ˜ $x$ë¥¼ íŠ¹ì„±(Feature)ì´ë¼ê³  ë¶€ë¥¸ë‹¤. 

# 2ï¸âƒ£ ì„ í˜• íšŒê·€(Linear Regression)
- ì–´ë–¤ ë³€ìˆ˜ì˜ ê°’ì— ë”°ë¼ì„œ íŠ¹ì • ë³€ìˆ˜ì˜ ê°’ì´ ì˜í–¥ì„ ë°›ëŠ”ë‹¤.
- ë³€ìˆ˜ì˜ ê°’ì„ ë³€í•˜ê²Œí•˜ëŠ” ë³€ìˆ˜ë¥¼ $x$, ë³€ìˆ˜ $x$ì— ì˜í•´ì„œ ê°’ì´ ì¢…ì†ì ìœ¼ë¡œ ë³€í•˜ëŠ” ë³€ìˆ˜ $y$ë¼ê³  í•  ë•Œ, ë³€ìˆ˜ $x$ì˜ ê°’ì€ ë…ë¦½ì ìœ¼ë¡œ ë³€í•  ìˆ˜ ìˆëŠ” ê²ƒì— ë°˜í•´, $y$ê°’ì€ ê³„ì†í•´ì„œ $x$ì˜ ê°’ì— ì˜í•´ì„œ, ì¢…ì†ì ìœ¼ë¡œ ê²°ì •ë˜ë¯€ë¡œ $x$ë¥¼ ë…ë¦½ ë³€ìˆ˜, $y$ë¥¼ ì¢…ì† ë³€ìˆ˜ë¼ê³  í•œë‹¤.
- ì„ í˜• íšŒê·€ëŠ” í•œ ê°œ ì´ìƒì˜ ë…ë¦½ ë³€ìˆ˜ $x$ì™€ $y$ì˜ ì„ í˜• ê´€ê³„ë¥¼ ëª¨ë¸ë§í•œë‹¤. ë§Œì•½, ë…ë¦½ ë³€ìˆ˜ $x$ê°€ 1ê°œë¼ë©´ ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¼ê³  í•œë‹¤.

# 3ï¸âƒ£ ì£¼íƒ íŒë§¤ ê°€ê²© ì˜ˆì¸¡

```py
import pandas as pd
# ì£¼ì–´ì§„ url ì£¼ì†Œë¥¼ ì´ìš©í•´ house prices ë°ì´í„° import
df = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/house-prices/house_prices_train.csv')
df_t = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/house-prices/house_prices_test.csv')

df.head()
df_t.head()
```

![](/assets/images/8.png)

![](/assets/images/9.png)

```py
# ì—¬ëŸ¬ íŠ¹ì„± ì¤‘ 'GrLivArea', 'LotArea', 'SalePrice'ë¥¼ ì‚¬ìš©
# SalePrice: ì˜ˆì¸¡í•´ì•¼ í•˜ëŠ” íƒ€ê²Ÿê°’ìœ¼ë¡œ ì£¼íƒíŒë§¤ê°€ê²©(ë‹¬ëŸ¬)
# LotArea: ì§‘ê³¼ ë§ˆë‹¹ì˜ ì‚¬ì´ì¦ˆ(square feet)
# GrLivArea: ì§€ìƒ ìƒí™œë©´ì (square feet)
df = df[['GrLivArea', 'LotArea', 'SalePrice']]
df_t = df_t[['GrLivArea', 'LotArea']]

# í…Œì´ë¸” í˜•í…Œ ì¶œë ¥, ì´ëŸ° í˜•íƒœì˜ ë°ì´í„° : tabular data
# íŠ¹ì§• 3ê°€ì§€
# Observations - í…Œì´ë¸”ì˜ í–‰ì˜ ìœ„ì¹˜
# Variables - í…Œì´ë¸”ì˜ ì—´ì— ìœ„ì¹˜
# Relationship - í•œ í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼ ë‹¤ìŒê³¼ ì—°ê²°
df
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 10 22 50](https://user-images.githubusercontent.com/79494088/128652118-8e656215-4c04-4473-8510-cb2b165c5be3.png)

## ì˜ˆì¸¡ ë°©ë²•

### 1. ê¸°ì¡´ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡
- ë³´í†µ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ê¸°ë„ í•˜ì§€ë§Œ, ì‚¬ëŒë§ˆë‹¤ í¸ê²¬ì´ ì¡´ì¬í•˜ë©° ì˜¤ë¥˜ì— ë¹ ì§ˆ ìœ„í—˜ì´ ë†’ë‹¤.

### 2. í†µê³„ì •ë³´ë¥¼ í™œìš©

```py
df['SalePrice'].describe()

'''
count     1,460.0
mean    180,921.2
std      79,442.5
min      34,900.0
25%     129,975.0
50%     163,000.0
75%     214,000.0
max     755,000.0
Name: SalePrice, dtype: float64
'''

import matplotlib.pyplot as plt
import seaborn as sns

## SalePriceì˜ í™•ë¥ ë°€ë„í•¨ìˆ˜
sns.displot(df['SalePrice'], kde=True)

## í‰ê· ê³¼, ì¤‘ê°„ê°’ ìˆ˜ì§ì„ 
plt.axvline(df['SalePrice'].mean(), color='blue')
plt.axvline(df['SalePrice'].median(), color='red');
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 10 26 11](https://user-images.githubusercontent.com/79494088/128652258-8b053aa2-e39b-4ecc-b603-c72bb850281d.png)

- ë§Œì¼ ê°€ê²©ì„ ì²˜ìŒìœ¼ë¡œ ì˜ˆì¸¡í•  ë•Œ, ê°€ì¥ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ ë°©ë²•ìœ¼ë¡œ í‰ê· ì´ë‚˜ ì¤‘ê°„ê°’ì„ ì´ìš©í•´ ë³´ëŠ” ê²ƒë„ ì¢‹ì€ ì„ íƒì¼ ê²ƒì´ë‹¤.

## ê¸°ì¤€ëª¨ë¸(Baseline Model)
- ì˜ˆì¸¡ëª¨ë¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë§Œë“¤ê¸° ì „ì— ê°€ì¥ ê°„ë‹¨í•˜ë©´ì„œë„ ì§ê´€ì ì´ë©´ì„œ ìµœì†Œí•œì˜ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸°ì¤€ì´ ë˜ëŠ” ëª¨ë¸
- í‰ê· ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ 'í‰ê· ê¸°ì¤€ëª¨ë¸'
- ë¬¸ì œë³„ë¡œ ê¸°ì¤€ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•œë‹¤.
  - ë¶„ë¥˜ë¬¸ì œ : íƒ€ê²Ÿì˜ ìµœë¹ˆ í´ë˜ìŠ¤
  - íšŒê·€ë¬¸ì œ : íƒ€ê²Ÿì˜ í‰ê· ê°’
  - ì‹œê³„ì—´íšŒê·€ë¬¸ì œ : ì´ì „ íƒ€ì„ ìŠ¤íƒ¬í”„ì˜ ê°’

```py
# predict: ìš°ë¦¬ê°€ ì •í•œ ê¸°ì¤€ëª¨ë¸ì¸ í‰ê· ìœ¼ë¡œ ì˜ˆì¸¡
predict = df['SalePrice'].mean()

# í‰ê· ê°’ìœ¼ë¡œ ì˜ˆì¸¡í•  ë•Œ ìƒ˜í”Œ ë³„ í‰ê· ê°’ê³¼ì˜ ì°¨ì´(error)ë¥¼ ì €ì¥
errors = predict - df['SalePrice']

errors

'''
0      -27,578.8
1         -578.8
2      -42,578.8
3       40,921.2
4      -69,078.8
          ...   
1455     5,921.2
1456   -29,078.8
1457   -85,578.8
1458    38,796.2
1459    33,421.2
Name: SalePrice, Length: 1460, dtype: float64
'''

# mean_absolute_error(MAE), errorì— ì ˆëŒ€ê°’ì„ ì·¨í•œ í›„ í‰ê· ì„ ê³„ì‚°
mean_absolute_error = errors.abs().mean()
```

- MAE(Mean Absolute Error, í‰ê· ì ˆëŒ€ì˜¤ì°¨)ëŠ” ì˜ˆì¸¡ Errorì˜ ì ˆëŒ€ê°’ í‰ê· ì„ ë‚˜íƒ€ëƒ„

> **MSE, MAEì˜ ì°¨ì´**
> - MSEëŠ” ì œê³±ì„ í•´ì£¼ê³  / MAEëŠ” ì œê³±ì€ í•˜ì§€ ì•Šê³  ì ˆëŒ€ê°’ì„ êµ¬í•œë‹¤.
> - í‰ê·  ì œê³± ì˜¤ì°¨(MSE)ëŠ” íšŒê·€ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì†ì‹¤ í•¨ìˆ˜ë¡œì¨ ì •í™•ë„ ê°œë…ì€ íšŒê·€ì— ì ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤.
> - ì¼ë°˜ì ì¸ íšŒê·€ ì§€í‘œëŠ” í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(MAE)
> - MSEëŠ” ì†ì‹¤í•¨ìˆ˜ë¡œì¨ ì“°ì¸ë‹¤.
> - MAEëŠ” íšŒê·€ì§€í‘œë¡œì¨ ì“°ì¸ë‹¤. 

$$Error = (price - guess)$$

$$
\begin{align}mae = (\frac{1}{n})\sum_{i=1}^{n}\left | price_{i} - guess_{i} \right |\end{align}
$$

```py
x = df['GrLivArea']
y = df['SalePrice']

predict = df['SalePrice'].mean()
errors = predict - df['SalePrice']
mean_absolute_error = errors.abs().mean()

sns.lineplot(x=x, y=predict, color='red')
sns.scatterplot(x=x, y=y, color='blue');
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 10 51 57](https://user-images.githubusercontent.com/79494088/128653268-7bbce9d8-17d1-4314-8eb6-cd8e431f2235.png)

```py
print(f'ì˜ˆì¸¡í•œ ì£¼íƒ ê°€ê²©ì´ ${predict:,.0f}ì´ë©° ì ˆëŒ€í‰ê· ì—ëŸ¬ê°€ ${mean_absolute_error:,.0f}ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')

# ì˜ˆì¸¡í•œ ì£¼íƒ ê°€ê²©ì´ $180,921ì´ë©° ì ˆëŒ€í‰ê· ì—ëŸ¬ê°€ $57,435ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```

- í‰ê· ì˜ˆì¸¡ì€ ì—ëŸ¬ê°€ ìƒë‹¹íˆ í¬ë‹¤.

```py
# ì£¼íƒ ê°€ê²©ì´ ì „ì²´ê³µê°„í¬ê¸°(LotArea)ì™€ ê°™ì€ ë‹¤ë¥¸ íŠ¹ì„±ê³¼ ì–´ë–¤ ìƒê´€ê´€ê³„(dependent)ê°€ ìˆì„ê¹Œ?

sns.set(style='whitegrid', context='notebook')
cols = ['GrLivArea', 'LotArea','SalePrice']
sns.pairplot(df[cols], height=2);
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 14 23 39](https://user-images.githubusercontent.com/79494088/128663374-7bfad9b7-4fad-488d-a77a-2ceaf351c408.png)

## ì˜ˆì¸¡ëª¨ë¸(Predictive Model) í™œìš©
- Scatter plotì— ê°€ì¥ ì˜ ë§ëŠ” (Base fit) ì§ì„ ì„ ê·¸ë ¤ì£¼ë©´ ê·¸ê²ƒì´ íšŒê·€ ì˜ˆì¸¡ëª¨ë¸ì´ ëœë‹¤.

### íšŒê·€ì§ì„ ì„ ë§Œë“œëŠ” ë°©ë²•
- íšŒê·€ë¶„ì„ì—ì„œ ì¤‘ìš”í•œ ê°œë…ì€ ì˜ˆì¸¡ê°’ê³¼ ì”ì°¨(Residual)
  - ì˜ˆì¸¡ê°’ : ë§Œë“¤ì–´ì§„ ëª¨ë¸ì´ ì¶”ì •í•˜ëŠ” ê°’
  - ì”ì°¨ : ì˜ˆì¸¡ê°’ê³¼ ê´€ì¸¡ê°’ì˜ ì°¨ì´<br>
  (ì˜¤ì°¨(Error) : ëª¨ì§‘ë‹¨ì—ì„œì˜ ì˜ˆì¸¡ê°’ê³¼ ê´€ì¸¡ê°’ì˜ ì°¨ì´)
- íšŒê·€ì„ ì€ ì”ì°¨ ì œê³±ë“¤ì˜ í•©ì¸ RSS(Residual sum of Squares)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì§ì„ 
  - RSS : SSE(Sum of Square Error)ë¼ê³ ë„ ë§í•˜ë©° ì´ ê°’ì´ íšŒê·€ëª¨ë¸ì˜ ë¹„ìš©í•¨ìˆ˜(Cost Function)ê°€ ëœë‹¤.
- ë¨¸ì‹ ëŸ¬ë‹ì—ì„œëŠ” ë¹„ìš©í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ëª¨ë¸ì„ ì°¾ëŠ” ê³¼ì •ì„ í•™ìŠµì´ë¼ê³  í•œë‹¤.

$${\displaystyle \operatorname {RSS} =\sum _{i=1}^{n}(\varepsilon _{i})^{2}=\sum _{i=1}^{n}(y_{i}-f(x_{i}))^{2}=\sum _{i=1}^{n}(y_{i}-(\alpha x_{i} + \beta))^{2}}$$

- ì—¬ê¸°ì„œ ê³„ìˆ˜ $a$ì™€ $b$ëŠ” RSSë¥¼ ìµœì†Œí™”í•˜ëŠ” ê°’ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµì„ í†µí•´ ì–»ì–´ì§€ëŠ” ê°’.
- ì”ì°¨ ì œê³±í•©ì„ ìµœì†Œí™”í•˜ëŠ” ë°©ë²•ì„ ìµœì†Œì œê³±íšŒê·€ or OLS(Ordinary Least Squares)ë¼ê³  ë¶€ë¥¸ë‹¤.
- OLSëŠ” ê³„ìˆ˜ ê³„ì‚°ì„ ìœ„í•´ ë‹¤ìŒ ê³µì‹ì„ ì‚¬ìš©í•œë‹¤.

{% raw %}$$\beta =\displaystyle {\bar {y}}-\alpha{\bar {x}}$${% endraw %}

{% raw %}$$\alpha ={\frac {S_{xy}}{S_{xx}}}$${% endraw %}

{% raw %}$${\displaystyle S_{xy}=\sum _{i=1}^{n}(x_{i}-{\bar {x}})(y_{i}-{\bar {y}})}$${% endraw %}

{% raw %}$${\displaystyle S_{xx}=\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}$${% endraw %}

- ìµœì†Œì œê³±ë²•ìœ¼ë¡œ ì„ í˜• íšŒê·€ê³„ìˆ˜ë¥¼ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.

```py
# Seaborn regplotìœ¼ë¡œ ê·¸ë¦¬ë©´, 
sns.regplot(x=df['GrLivArea'], y=df['SalePrice']);
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 13 33 02](https://user-images.githubusercontent.com/79494088/128660669-9be27d55-f279-4fb2-ad64-3d55751b5869.png)

```py
# GrLivArea > 3500 & GrLivArea < 4500 ì‚¬ì´ì˜ ë°ì´í„°
df[(df['GrLivArea'] > 3500) & (df['GrLivArea'] < 4500)]
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 13 33 54](https://user-images.githubusercontent.com/79494088/128660732-d004e108-4b92-44d7-9a62-f6b65374159a.png)

- ì„ í˜•íšŒê·€ëŠ” ì£¼ì–´ì ¸ ìˆì§€ ì•Šì€ ì ì˜ í•¨ìˆ˜ê°’ì„ ë³´ê°„(Interpolate)í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ”ë° ë„ì›€ì„ ì¤€ë‹¤.
- ì„ í˜•íšŒê·€ëª¨ë¸ì„ ì‚¬ìš©í•´ 4000sqft ì£¼íƒ ê°€ê²©ì„ ì–´ë¦¼ì¡ì•„ ì˜ˆì¸¡í•´ ë³¼ ìˆ˜ ìˆë‹¤.
- ì„ í˜•íšŒê·€ëª¨ë¸ì€ ê¸°ì¡´ ë°ì´í„°ì˜ ë²”ìœ„ë¥¼ ë„˜ì–´ì„œëŠ” ê°’ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ì™¸ì‚½(Extrapolate)ë„ ì œê³µí•œë‹¤.

# 4ï¸âƒ£ Scikit-Learn í™œìš© ì„ í˜•íšŒê·€ëª¨ë¸
- í˜„ì¬ ë‹¤ë£¨ëŠ” ë°ì´í„°ì— 6000sqft ì´ìƒì¸ ì£¼íƒì˜ ê±°ë˜ ì •ë³´ê°€ ì—†ë‹¤.

## ì´ëŸ° ê²½ìš° ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•
- ì„ í˜•íšŒê·€ ì§ì„ ì€ ë…ë¦½ë³€ìˆ˜(Independent Variable, $x$)ì™€ ì¢…ì†ë³€ìˆ˜(Dependent Variable, $y$) ê°„ì˜ ê´€ê³„ë¥¼ ìš”ì•½í•´ì¤€ë‹¤.
  - ì¢…ì†ë³€ìˆ˜
    - ì—°êµ¬ìê°€ ë…ë¦½ë³€ìˆ˜ì˜ ë³€í™”ì— ë”°ë¼ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì•Œê³  ì‹¶ì–´í•˜ëŠ” ë³€ìˆ˜
    - ë°˜ì‘ë³€ìˆ˜(Response), Label, Target ë“±
  - ë…ë¦½ë³€ìˆ˜
    - ì—°êµ¬ìê°€ ì˜ë„ì ìœ¼ë¡œ ë³€í™”ì‹œí‚¤ëŠ” ë³€ìˆ˜
    - ë‹¤ë¥¸ ë³€ìˆ˜ì— ì˜í–¥ì„ ë°›ì§€ ì•Šê³  ì˜¤íˆë ¤ ì¢…ì†ë³€ìˆ˜ì— ì˜í–¥ì„ ì¤€ë‹¤.
    - ì˜ˆì¸¡ë³€ìˆ˜(Predictor), ì„¤ëª…(Explanatory), íŠ¹ì„±(Feature) ë“±

## Scikit-Learn Data êµ¬ì¡°

<img src="https://www.researchgate.net/publication/301946040/figure/fig1/AS:362519232303116@1463442728351/Data-representation-in-scikit-learn.png" alt="Data representation in scikit-learn"/>

- Scikit-Learnì„ í™œìš©í•´ ëª¨ë¸ì„ ë§Œë“¤ê³  ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´ì„œëŠ” ìœ„ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤. 
- íŠ¹ì • ë°ì´í„°ì™€ íƒ€ê²Ÿ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì–´ì¤€ë‹¤.
- íŠ¹ì„±í–‰ë ¬ì€ ì£¼ë¡œ `X`ë¡œ í‘œí˜„í•˜ê³  ë³´í†µ 2ì°¨ì› í–‰ë ¬ì´ë‹¤.<br>
ì£¼ë¡œ Numpy í–‰ë ¬ì´ë‚˜ Pandas ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ í‘œí˜„
- íƒ€ê²Ÿë°°ì—´ì€ ì£¼ë¡œ `y`ë¡œ í‘œí˜„í•˜ê³  ë³´í†µ 1ì°¨ì› í˜•íƒœì´ë‹¤.<br>
ì£¼ë¡œ Numpy í–‰ë ¬ì´ë‚˜ Pandas ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ í‘œí˜„

## Scikit-Learnì˜ ìˆ˜ë§ì€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸
- ëª¨ë‘ ìœ ì‚¬í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. 
- ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•˜ì—¬ í´ë˜ìŠ¤ë¥¼ ì°¾ì•„ë³¸ í›„ ê´€ë ¨ ì†ì„±ì´ë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•œë‹¤.
- `fit()` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµ
- `predict()` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡
- [Scikit-Learn ì†Œê°œ](https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html#Basics-of-the-API)

# 5ï¸âƒ£ Simple Linear Regression (ë‹¨ìˆœ ì„ í˜• íšŒê·€)
- [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)

```py
# Scikit-Learn ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì‚¬ìš©í•  ì˜ˆì¸¡ëª¨ë¸ í´ë˜ìŠ¤ Import
from sklearn.linear_model import LinearRegression

# ì˜ˆì¸¡ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
model = LinearRegression()

# X íŠ¹ì„±ë“¤ì˜ í…Œì´ë¸”ê³¼, y íƒ€ê²Ÿ ë²¡í„° ìƒì„±
feature = ['GrLivArea']
target = ['SalePrice']
X_train = df[feature]
y_train = df[target]

# ëª¨ë¸í•™ìŠµ(fit)
model.fit(X_train, y_train)

# LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)

# ìƒˆë¡œìš´ ë°ì´í„° í•œ ìƒ˜í”Œì„ ì„ íƒí•´ í•™ìŠµí•œ ëª¨ë¸ì„ í†µí•´ ì˜ˆì¸¡
X_test = [[4000]]
y_pred = model.predict(X_test)

print(f'{X_test[0][0]} sqft GrLivAreaë¥¼ ê°€ì§€ëŠ” ì£¼íƒì˜ ì˜ˆìƒ ê°€ê²©ì€ ${int(y_pred)} ì…ë‹ˆë‹¤.')

# 4000 sqft GrLivAreaë¥¼ ê°€ì§€ëŠ” ì£¼íƒì˜ ì˜ˆìƒ ê°€ê²©ì€ $447090 ì…ë‹ˆë‹¤.

# ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ë¸ì„ í†µí•´ ì˜ˆì¸¡
X_test = [[x] for x in df_t['GrLivArea']]
y_pred = model.predict(X_test)

# ì „ì²´ ì˜ˆì¸¡ê°’
y_pred

'''
array([[114557.82748987],
       [160945.27292207],
       [193084.38061182],
       ...,
       [149696.58523066],
       [122485.47405334],
       [232829.74378814]])
'''

# train ë°ì´í„°ì™€ ì˜ˆì¸¡ì— ëŒ€í•œ ê·¸ë˜í”„
plt.scatter(X_train, y_train, color='black', linewidth=1)
plt.scatter(X_test, y_pred, color='blue', linewidth=1);
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 13 59 08](https://user-images.githubusercontent.com/79494088/128661948-c17210d7-bc4b-4773-9f16-a6b6f3790ad4.png)

- ìœ„ ì½”ë“œëŠ” ì´ [ë‹¤ì´ì–´ê·¸ë¨](https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/tutorial/text_analytics/general_concepts.html#supervised-learning-model-fit-x-y)ì—ì„œ í‘œí˜„í•œ ì¼ë°˜ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì„¸ìŠ¤
- íŒŒë€ìƒ‰ì€ í•™ìŠµ, ì´ˆë¡ìƒ‰ì€ í…ŒìŠ¤íŠ¸ë¥¼ ëœ»í•¨.

<img src="https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/_images/plot_ML_flow_chart_12.png" width="75%">

- ë¨¸ì‹ ëŸ¬ë‹ì„ ìƒˆë¡œìš´ í”„ë¡œê·¸ë˜ë° íŒ¨ëŸ¬ë‹¤ì„ìœ¼ë¡œì¨ì˜ ê´€ì 

<img src="https://pbs.twimg.com/media/ECQDlFOWkAEJzlY.jpg" width="70%">

- ë°ì´í„°ë¥¼ ì…ë ¥í•˜ê³  ì–´ë–¤ ë£°ì— ë”°ë¼ ë‹µì„ êµ¬í•´ë‚´ëŠ” ì¼ë°˜ì ì¸ í”„ë¡œê·¸ë˜ë°ê³¼ ë‹¬ë¦¬ ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ì™€ ë‹µì„ í†µí•´ ë£°ì„ ì°¾ì•„ë‚´ëŠ” ë°©ë²•

# 6ï¸âƒ£ ì„ í˜•íšŒê·€ëª¨ë¸ì˜ ê³„ìˆ˜(Coefficients)
- ëª¨ë¸ì´ ì£¼íƒì˜ í¬ê¸°ì™€ ê°€ê²© ì‚¬ì´ì˜ ì–´ë–¤ ê´€ê³„ë¥¼ í•™ìŠµí–ˆëŠ”ì§€ ë³´ê¸° ìœ„í•´ `LinearRegression` ê°ì²´ì˜ `coef_`, `intercept_` ì†ì„±ì„ í™•ì¸
- íšŒê·€ê³„ìˆ˜ : 

```py
# ê³„ìˆ˜(coefficient)
model.coef_

# array([[107.13035897]])

# ì ˆí¸(intercept)
model.intercept_

# array([18569.02585649])
```

## Coefficientsì˜ ì˜í–¥
- ì˜ˆì¸¡í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ìƒˆë¡œìš´ ë°ì´í„° ë°˜ë³µí•´ì„œ ì˜ˆì¸¡

```py
def explain_prediction(sqft):
    y_pred = model.predict([[sqft]])
    pred = f"{int(sqft)} sqft ì£¼íƒ ê°€ê²© ì˜ˆì¸¡: ${int(y_pred[0])} (1 sqftë‹¹ ì¶”ê°€ê¸ˆ: ${int(model.coef_[0])})"

    return pred

# square_feet = 4000 ì¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡
print(explain_prediction(4000))

# 4000 sqft ì£¼íƒ ê°€ê²© ì˜ˆì¸¡: $447090 (1 sqftë‹¹ ì¶”ê°€ê¸ˆ: $107)
```

## ipywidgets ì‚¬ìš©

```py
from ipywidgets import interact

# ë°ì½”ë ˆì´í„° interactë¥¼ ì¶”ê°€
@interact
def explain_prediction(sqft=(500,10000)):
    y_pred = model.predict([[sqft]])
    pred = f"{int(sqft)} sqft ì£¼íƒ ê°€ê²© ì˜ˆì¸¡: ${int(y_pred[0])} (1 sqftë‹¹ ì¶”ê°€ê¸ˆ: ${int(model.coef_[0])})"

    return pred
```

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-08-09 14 14 39](https://user-images.githubusercontent.com/79494088/128662853-1ca5c8f4-7aa0-4b81-a559-9347b256302c.png)

# 7ï¸âƒ£ ì°¸ê³ ìë£Œ

#### ê¸°ì¤€ëª¨ë¸
- [Always start with a stupid model, no exceptions](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa)

#### Scikit-Learn
- [Python Data Science Handbook, Chapter 5.2: Introducing Scikit-Learn](https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html#Basics-of-the-API)
- [2.4.2.2. Supervised Learning](https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/tutorial/text_analytics/general_concepts.html#supervised-learning-model-fit-x-y)
- [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
- [sklearn.metrics.mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)

#### ì½ì–´ë³´ì„¸ìš”
- [Art of Choosing Metrics in Supervised Models](https://towardsdatascience.com/art-of-choosing-metrics-in-supervised-models-part-1-f960ae46902e)
- [The Discovery of Statistical Regression](https://priceonomics.com/the-discovery-of-statistical-regression/)

#### ìµœì†Œì œê³±ë²•
- [ìˆ˜í•™ì‚°ì±…-ìµœì†Œì œê³±ë²•](https://terms.naver.com/entry.nhn?cid=58944&docId=3569970&categoryId=58970)

#### (ì°¸ê³ ) ë” ì„¸ë ¨ëœ ì‹œê°í™”íˆ´: Plotly
- [Plotly Express](https://plot.ly/python/plotly-express/)
- [plotly_express.scatter](https://www.plotly.express/plotly_express/#plotly_express.scatter)

#### ipywidgets interact
- [Using Interact](https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html#Using-Interact)

#### ë‹¨ìˆœì„ í˜•íšŒê·€ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•œ ì¢‹ì€ íŠ¹ì„±
1. ì„ í˜•ì„±
  - ì„ í˜•ì€ íšŒê·€ë¶„ì„ì—ì„œ ì¤‘ìš”í•œ ê¸°ë³¸ê³¼ì •
  - ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ì¢…ì†ë³€ìˆ˜ yì™€ ë…ë¦½ë³€ìˆ˜ xê°„ì— ì„ í˜•ì„±ì„ ë§Œì¡±í•˜ëŠ” íŠ¹ì„±
  - ë…ë¦½ë³€ìˆ˜ë“¤ì— ëŒ€í•´ í¸ë¯¸ë¶„ì„ í•˜ë©´ ìƒìˆ˜ê°€ ë‚˜ì™€ì•¼ í•¨
    - ì²«ì§¸ë¡œ ë‹¤ë¥¸ ìƒˆë¡œìš´ ë³€ìˆ˜ë¥¼ ì¶”ê°€
    - ë‘˜ì§¸ë¡œëŠ” ë¡œê·¸, ì§€ìˆ˜, ë£¨íŠ¸ ë“± ë³€ìˆ˜ ë³€í™˜ì„ ì·¨í•´ë³´ëŠ” ê²ƒ
    - ì„¸ë²ˆì§¸ë¡œëŠ” ì•„ì˜ˆ ì„ í˜•ì„±ì„ ë§Œì¡±í•˜ì§€ ì•ŠëŠ” ë³€ìˆ˜ë¥¼ ì œê±°í•˜ëŠ” ê²ƒ
    - ë„¤ë²ˆì§¸ë¡œëŠ” ì¼ë‹¨ ì„ í˜• íšŒê·€ëª¨ë¸ì„ ë§Œë“¤ê³  ë³€ìˆ˜ ì„ íƒë²•ì„ í†µê³¼ì‹œí‚¤ëŠ” ê²ƒ
    - ë„¤ë²ˆì§¸ ë°©ë²•ì„ ê°€ì¥ ì¶”ì²œ
    - ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ ë§ì•„ì§€ë©´ ê°œë³„ ë³€ìˆ˜ë¥¼ íŒŒì•…í•˜ê¸°ê°€ ì–´ë ¤ì›Œì§€ê¸° ë•Œë¬¸ì´ë‹¤.
    - ë‘ë²ˆì§¸ ë°©ë²•ì€ ë¹„ì¶”ì²œ
    - ë³€í™˜ëœ ë³€ìˆ˜ì˜ ì˜ë¯¸ë¥¼ í•´ì„í•˜ê¸°ê°€ ì–´ë µê¸° ë•Œë¬¸
2. ë…ë¦½ì„±
  - ë…ë¦½ì„±ì€ "ë‹¤ì¤‘" íšŒê·€ë¶„ì„ì—ì„œ ì¤‘ìš”í•œ ê¸°ë³¸ê°€ì •ìœ¼ë¡œ, ë‹¹ì—°íˆ "ë‹¨ìˆœ" íšŒê·€ë¶„ì„ì—ì„œëŠ” í•´ë‹¹í•˜ì§€ ì•ŠëŠ”ë‹¤.
  - ë…ë¦½ë³€ìˆ˜ x ê°„ì— ìƒê´€ê´€ê³„ê°€ ì—†ì´ ë…ë¦½ì„±ì„ ë§Œì¡±í•˜ëŠ” íŠ¹ì„±
  - ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì‹œì ì˜ ì˜¤ì°¨í•­ ì‚¬ì´ì— ê³µë¶„ì‚°ì´ 0ì¼ ê²ƒ
3. ë“±ë¶„ì‚°ì„±
  - ë“±ë¶„ì‚°ì„±ì´ë€ ë¶„ì‚°ì´ ê°™ë‹¤ëŠ” ê²ƒì´ê³ , ë¶„ì‚°ì´ ê°™ë‹¤ëŠ” ê²ƒì€ íŠ¹ì •í•œ íŒ¨í„´ ì—†ì´ ê³ ë¥´ê²Œ ë¶„í¬í–ˆë‹¤ëŠ” ì˜ë¯¸
  - ì–´ëŠ ì‹œì ì—ì„œ ê´€ì¸¡í•˜ë”ë¼ë„ ë™ì¼í•œ ë¶„ì‚°ì´ ë‚˜ì˜¬ ê²ƒ.
4. ì •ê·œì„±
  - ë§ˆì§€ë§‰ ì •ê·œì„±ì€ ë˜í•œ ì”ì°¨ê°€ ì •ê·œì„±ì„ ë§Œì¡±í•˜ëŠ”ì§€ ì—¬ë¶€ë¡œ, ì •ê·œë¶„í¬ë¥¼ ë„ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì˜ë¯¸
5. ê°€ìš°ìŠ¤ ë§ˆì½”í”„ ì •ë¦¬ì˜ ì¡°ê±´ë“¤ì„ ë§Œì¡±í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.
  - ê°€ìš°ìŠ¤ ë§ˆì½”í”„ ì •ë¦¬ : íŠ¹ì • ê°€ì •/ì¡°ê±´ì„ ë§Œì¡±í•  ê²½ìš°, ìš°ë¦¬ê°€ êµ¬í•œ ìµœì†Œì œê³±ì¶”ì •ëŸ‰(OLSì˜ ì¶”ì •ëŸ‰)ì´ BLUE(Best Linear Unbiased Estimator)ì´ë‹¤.<br>ê°€ì¥ ì¢‹ì€ íšŒê·€ëª¨í˜•ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤ ìƒê°í•˜ë©´ ëœë‹¤. <br>*BLUE : ì¶”ì •ì¹˜ ì¤‘ ê°€ì¥ ì¢‹ì€ ë¶ˆí¸ ì¶”ì •

#### OLS(Ordinary Least Squares): ìµœì†ŒììŠ¹ë²•
- ì”ì°¨ ì œê³±í•©(RSS)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê°€ì¤‘ì¹˜(ë‹¨ìˆœì„ í˜•íšŒê·€ì—ì„œëŠ” ê¸°ìš¸ê¸°, íšŒê·€ê³„ìˆ˜)ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•
- í†µê³„ë¥¼ ì²˜ìŒ ë°°ìš¸ ë•Œ ê°€ì¥ ì ‘í•˜ê²Œ ë˜ë©´ì„œ ë‹¨ìˆœí•˜ë©´ì„œ ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ë°©ë²•
- ì„ í˜•íšŒê·€ëª¨ë¸ì˜ ì¶”ì •ë°©ë²• ì¤‘ì— í•˜ë‚˜ì´ì§€ë§Œ ì„ í˜•íšŒê·€ëª¨ë¸ ìì²´ëŠ” ì•„ë‹ˆë‹¤.
- ë°ì´í„°ì˜ ì¶”ì„¸ì„ ì„ ê·¸ë¦¬ê³  ì‹¶ì„ ë•Œ ì“°ëŠ” ë°©ë²•
- ì”ì°¨ì˜ ì œê³±ì˜ í•©ì„ ìµœì†Œë¡œ í•˜ëŠ” ë°©ë²•