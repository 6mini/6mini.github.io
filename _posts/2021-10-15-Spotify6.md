---
title: '[Data Pipeline Project(1)] Spotify recommend(6) 자동화'
description: 스포티파이 API 이용 데이터 파이프라인 구축 토이 프로젝트 EC2 Crontab과 Lambda 이용 자동화 시스템 구축
categories:
 - Project
tags: [Project, Data Engineering, Data Pipeline, EC2, Crontab, Lambda]
---

# Data Pipeline

## Data Workflow
- 아래와 같은 서비스를 S3에 모아 Athena 같은 서비스로 분석해준 뒤 그 결과를 저장해놓는 일련의 데이터 작업의 흐름

![image](https://user-images.githubusercontent.com/79494088/137546020-94a29a6d-181e-4be6-a8ee-2fd02ffe31ef.png)

## DAGs
- 하나의 job이 시작되거나 어떠한 event에 trigger가 됐을 때, 또 다른 job으로 연결이 되는 이런 정보들을 DAGs(Directed Acyclic Graphs)라고 부른다.

![image](https://user-images.githubusercontent.com/79494088/137545829-37d543ae-6c55-488a-9ace-2c5b8f7059dd.png)

# ETL
- 보통은 Extract -> Transform -> Load순으로 작업을 해 왔지만, 최근에는 Extract -> Load -> Transform 순으로 작업을 하기도 한다.
- 데이터 파이프 라인의 연장선
- 하나의 예시를 들자면, 하루의 정해진 시간에 의한 스케쥴링인 Amazon CloudWatch Event와 Automation Script를 통해서 machine이 시작하면, AWS안에 AWS Step Functions는 각 과정에서 그 다음과정으로의 연결에 대한 여러가지 경우의 수에 대한 룰을 정해놓는 서비스로 쉽게 말하면, 임의의 단계에서 fail이 일어나면 어떤 event를 발생시켜야 하고, success를 하면 어떤 event를 발생시켜야 하는지를 관리할 수 있도록 도와주는 서비스이다.
- 이런 Step Function안의 ETL Flow state machine이 시작하고, 이후에는 다양한 job들이 작동하게 된다.
- 이러한 ETL job들의 log를 CloudWatch에 저장을 하고, 아래와 같은 Flow를 갖게된다.

![image](https://user-images.githubusercontent.com/79494088/137546310-20b6421f-b07e-4703-976f-7089536a2458.png)

![image](https://user-images.githubusercontent.com/79494088/137546361-e89e0b75-9db8-4e92-9568-0f1bed4baaf9.png)

## AWS Glue

- AWS의 Step function에 관해 조금 더 말하자면, 아래 그림과 같이 사용할 수 있다.
- start가 되면 job이 submit이 되고, job이 finish될때 까지 기다려 줄 수 있게끔 Wait Seconds를 사용할 수도 있다.
- Athena는 어느 정도 빅데이터를 처리하는 시스템이기 때문에 MySQL이나 PostgreSQL보다는 느린 부분이 있다.
- 이런 경우 위와 같이 time sleep을 통해 python script를 잠깐 멈춰두고 그 다음에 해당 시간이 지났을때 그 query에 대한 결과들을 가져올 수 있다.
- 이후에는 다시 job status를 받고 job이 끝났는지 아닌지에 따라 작업을 진행하는 flow를 볼 수 있다. 
- 이런 service들이 없었을 때는 하나하나 monitoring을 통해서 수동으로 관리를 해야 했다.

![image](https://user-images.githubusercontent.com/79494088/137546527-79abe867-eda1-44c2-92e8-385dbf7996fc.png)

- 좋은 부분은 SQL 같은 경우, 만들어놓은 스키마에 맞춰 데이터를 넣었는데, 이젠 데이터가 방대해지고 형식도 다른데, 이런것을 Glue 한다는 의미의 서비스
- 많이 쓰여지는 부분 중 하나가 Crawler인데 Crawler를 사용하면 자동으로 해당 data를 크롤링해서 data가 어떤 형식인지에 대해 지속적으로 스키마 관리가 들어간다.
- 그러므로 data와 column이 많을 때 사용하면 좋다.
- AWS Glue 페이지를 보면 아래 그림과 같이 table과 ETL, Trigger등 다양한 작업을 할 수 있다.
- 한가지 예시로 S3에 저장해놓은 Python Script를 Jobs 탭에서 바로 수정가능하고, Trigger도 등록해서 관리할 수 있다.

![image](https://user-images.githubusercontent.com/79494088/137592121-132e2e0b-71b6-472e-afb2-42e4a0bc9c3f.png)

- 해당 job은 step function이나 Glue를 통해 관리를 하거나, EC2에서 Crontab으로 스케쥴링의 변화를 통해서 관리를 하는 등 다양한 방법으로 관리를 하지만 아래와 같이 서비스들의 지속적인 monitoring을 통해 cost를 효율적으로 사용할 선택과 집중을 해야 할 것이다. 어떤 부분까지 monitoring을 할 것인지에 대해 선택하여 집중한다.

![image](https://user-images.githubusercontent.com/79494088/137593056-d6cafa3a-da72-44cb-ba9d-91f4d49e8bef.png)

# Crontab

![](https://user-images.githubusercontent.com/79494088/137593157-084d76d5-b08e-429d-b4c5-6cc11c0604cd.png)

# 마이크로 서비스

## 수집 프로세스
- Unknown Artist가 챗봇 메세지로 들어왔을 경우 AWS Lambda 서비스 통해 Spotify API Access
- 해당 데이터가 Top Tracks, Artist Table에 가야되는지 S3에 가야되는지를 관리
- Ad Hoc Data Job을 통해 하루에 한번이라던지, 직접 로컬에서 command line을 통해 데이터를 가져올 수도 있게 된다.
- Lambda가 필요한 이유는 우리가 Unknown Artist가 챗봇 메세지로 들어왔을때 내용을 업데이트
- 사람들이 기대하는 챗봇은 업데이트를 바로 해줘서 원하는 정보를 얻게끔 해줘야 하기 때문에 Lambda라는 서비스를 통해 해결
- Lambda는 마이크로 서비스의 개념

![](https://user-images.githubusercontent.com/79494088/137593705-c65d91cd-4d30-4499-ba5e-c000fe2a6a7b.png)

- 챗봇을 Lambda로 구현하는 이유: Severless는 하나의 Func이기 때문에 Stateless라고도 하는데 지금 상태가 어떤지 모르겠다는 의미이다.
- 어떤 메세지를 보내면 Lambda Func에는 이전에 어떤 메세지를 갖고 있었는지 담을 수 없다.
- 그러므로 State를 관리할 DB가 필요한데 DynamoDB는 메시지에 특화되어 있다.
- Lambda의 경우 해당 서비스의 User가 기하급수적으로 늘어났을 때 병렬로 늘어나기 때문에 제한점이 서버로 구현하는 것보다 덜하다.
- 지속적으로 띄워져 있는 것이 아니라 필요할 때 띄워서 사용한 만큼만 비용을 지불한다.

![image](https://user-images.githubusercontent.com/79494088/137593775-4a4f9e75-2abc-4feb-bd27-9c2f9c4e2cd4.png)

## Lambda 스크립팅

### 함수 생성
- Lambda Function은 이전에 DynamoDB에 top track정보를 DynamoDB에 저장했었는데, Artist가 추가된다면 DynamoDB에도 저장되어야하므로 이 작업을 작성

![image](https://user-images.githubusercontent.com/79494088/137594121-73085b27-f2b5-40e6-af4e-a9fb4cd5bcec.png)

### S3 생성

![image](https://user-images.githubusercontent.com/79494088/137595988-1f1eeae7-ff24-4d88-8b4c-08f8ef7c9da9.png)

### top_tracks 구조


```
top_tracks
├── deploy.sh
├── lambda_function.py
├── requirements.txt
└── setup.cfg
```

#### deploy.sh

```
#!/bin/bash

rm -rf ./libs
pip3 install -r requirements.txt -t ./libs

rm *.zip
zip top_tracks.zip -r *

aws s3 rm s3://6mini-top-tracks/top_tracks.zip
aws s3 cp ./top_tracks.zip s3://6mini-top-tracks/top_tracks.zip
aws lambda update-function-code --function-name top-tracks --s3-bucket 6mini-top-tracks --s3-key top_tracks.zip
```

#### lambda_function.py

```py
import sys
sys.path.append('./libs')
import os
import boto3
import requests
import base64
import json
import logging


client_id = ""
client_secret = ""

try:
    dynamodb = boto3.resource('dynamodb', region_name='ap-northeast-2', endpoint_url='http://dynamodb.ap-northeast-2.amazonaws.com')
except:
    logging.error('could not connect to dynamodb')
    sys.exit(1)


def lambda_handler(event, context):

    headers = get_headers(client_id, client_secret)

    table = dynamodb.Table('top_tracks')

    artist_id = event['artist_id']

    URL = "https://api.spotify.com/v1/artists/{}/top-tracks".format(artist_id)
    params = {
        'country': 'US'
    }
    r = requests.get(URL, params=params, headers=headers)

    raw = json.loads(r.text)

    for track in raw['tracks']:

        data = {
            'artist_id': artist_id
        }

        data.update(track)

        table.put_item(
            Item=data
        )

    return "SUCCESS"



def get_headers(client_id, client_secret):

    endpoint = "https://accounts.spotify.com/api/token"
    encoded = base64.b64encode("{}:{}".format(client_id, client_secret).encode('utf-8')).decode('ascii')

    headers = {
        "Authorization": "Basic {}".format(encoded)
    }

    payload = {
        "grant_type": "client_credentials"
    }

    r = requests.post(endpoint, data=payload, headers=headers)

    access_token = json.loads(r.text)['access_token']

    headers = {
        "Authorization": "Bearer {}".format(access_token)
    }

    return headers


if __name__=='__main__':
    main()

```

#### requirements.txt

```
requests
```

#### setup.cfg

```
[install]
prefix=
```

### 실행

```
$ brew install awscli

$ chmod +x deploy.sh

$ ./deploy.sh
```

### IAM 역할 설정

![image](https://user-images.githubusercontent.com/79494088/137596084-7031f5ae-8e62-471f-9158-5d45f118199c.png)

![image](https://user-images.githubusercontent.com/79494088/137596104-10d9584c-0ba0-415f-857c-630b4ebc790c.png)

### Test

![image](https://user-images.githubusercontent.com/79494088/137596123-146fcf45-fb71-486e-a6ad-fb5ca62f38cf.png)
