---
title: '[Data Pipeline Project(1)] Spotify recommend(6) 자동화'
description: 스포티파이 API 이용 데이터 파이프라인 구축 토이 프로젝트 EC2 Crontab과 Lambda 이용 자동화 시스템 구축
categories:
 - Project
tags: [Project, Data Engineering, Data Pipeline, EC2, Crontab, Lambda]
---

# Data Pipeline

## Data Workflow
- 아래와 같은 서비스를 S3에 모아 Athena 같은 서비스로 분석해준 뒤 그 결과를 저장해놓는 일련의 데이터 작업의 흐름

![image](https://user-images.githubusercontent.com/79494088/137546020-94a29a6d-181e-4be6-a8ee-2fd02ffe31ef.png)

## DAGs
- 하나의 job이 시작되거나 어떠한 event에 trigger가 됐을 때, 또 다른 job으로 연결이 되는 이런 정보들을 DAGs(Directed Acyclic Graphs)라고 부른다.

![image](https://user-images.githubusercontent.com/79494088/137545829-37d543ae-6c55-488a-9ace-2c5b8f7059dd.png)

# ETL
- 보통은 Extract -> Transform -> Load순으로 작업을 해 왔지만, 최근에는 Extract -> Load -> Transform 순으로 작업을 하기도 한다.
- 데이터 파이프 라인의 연장선
- 하나의 예시를 들자면, 하루의 정해진 시간에 의한 스케쥴링인 Amazon CloudWatch Event와 Automation Script를 통해서 machine이 시작하면, AWS안에 AWS Step Functions는 각 과정에서 그 다음과정으로의 연결에 대한 여러가지 경우의 수에 대한 룰을 정해놓는 서비스로 쉽게 말하면, 임의의 단계에서 fail이 일어나면 어떤 event를 발생시켜야 하고, success를 하면 어떤 event를 발생시켜야 하는지를 관리할 수 있도록 도와주는 서비스이다.
- 이런 Step Function안의 ETL Flow state machine이 시작하고, 이후에는 다양한 job들이 작동하게 된다.
- 이러한 ETL job들의 log를 CloudWatch에 저장을 하고, 아래와 같은 Flow를 갖게된다.

![image](https://user-images.githubusercontent.com/79494088/137546310-20b6421f-b07e-4703-976f-7089536a2458.png)

![image](https://user-images.githubusercontent.com/79494088/137546361-e89e0b75-9db8-4e92-9568-0f1bed4baaf9.png)

## AWS Glue

- AWS의 Step function에 관해 조금 더 말하자면, 아래 그림과 같이 사용할 수 있다.
- start가 되면 job이 submit이 되고, job이 finish될때 까지 기다려 줄 수 있게끔 Wait Seconds를 사용할 수도 있다.
- Athena는 어느 정도 빅데이터를 처리하는 시스템이기 때문에 MySQL이나 PostgreSQL보다는 느린 부분이 있다.
- 이런 경우 위와 같이 time sleep을 통해 python script를 잠깐 멈춰두고 그 다음에 해당 시간이 지났을때 그 query에 대한 결과들을 가져올 수 있다.
- 이후에는 다시 job status를 받고 job이 끝났는지 아닌지에 따라 작업을 진행하는 flow를 볼 수 있다. 
- 이런 service들이 없었을 때는 하나하나 monitoring을 통해서 수동으로 관리를 해야 했다.

![image](https://user-images.githubusercontent.com/79494088/137546527-79abe867-eda1-44c2-92e8-385dbf7996fc.png)

- 가장 좋은 부분은 SQL 같은 경우에 만들어 놓은 Schema에 맞춰서 data를 insert하였는데, 이제는 data가 방대해지고 형식도 다 다른데, 이런 것을 Glue한다는 의미의 서비스라는 점
- 가장 많이 쓰여지는 부분 중에 하나가 Crawler인데 Crawler를 사용하면 자동으로 해당 data를 Crwaling해서 data가 어떤 형식인지에 대해서 지속적으로 Schema 관리가 들어가는 부분
- 그러므로 data와 column도 많은데 column이 변하는 경우에 사용하면 좋다.
- AWS Glue 페이지를 보면 아래 그림과 같이 table과 ETL, Trigger등 다양한 작업을 할 수 있다.
- 한 가지 예시로 S3에 저장해놓은 python Script를 Jobs 탭에서 바로 수정가능하며, Trigger들도 등록해서 관리 할 수 있다.

![image](https://user-images.githubusercontent.com/79494088/137592121-132e2e0b-71b6-472e-afb2-42e4a0bc9c3f.png)

- 해당 job은 step function이나 Glue를 통해 관리를 하거나, EC2에서 Crontab으로 스케쥴링의 변화를 통해서 관리를 하는 등 다양한 방법으로 관리를 하지만 아래와 같이 서비스들의 지속적인 monitoring을 통해 cost를 효율적으로 사용할 선택과 집중을 해야 할 것이다. 어떤 부분까지 monitoring을 할 것인지에 대해 선택하여 집중한다.

![image](https://user-images.githubusercontent.com/79494088/137593056-d6cafa3a-da72-44cb-ba9d-91f4d49e8bef.png)

# Crontab

![image](https://user-images.githubusercontent.com/79494088/137593157-084d76d5-b08e-429d-b4c5-6cc11c0604cd.png)

- top_tracks와 audio feature 데이터를 S3에 parquet화하여 저장 자동화
- Cronjob 실행에 관련된 사항은 [이곳](https://6mini.github.io/project/2021/10/10/Cother5/) 참고

# 마이크로서비스

## 전체적인 수집 프로세스
- Unknown Artist가 챗봇 메세지로 들어왔을 경우 AWS Serverless Lamda 서비스를 통해 Spotify API에 Access
- 해당 데이터가 Top Tracks, Artist Table에 가야되는지 S3에 가야되는지를 관리
- Ad Hoc Data Job을 통해 하루에 한번이라던지, 직접 로컬에서 command line을 통해 데이터를 가져올 수도 있게된다.
- Lambda가 필요한 이유는 우리가 Unknown Artist가 챗봇 메세지로 들어왔을때 내용을 업데이트
- 보통 사람들이 기대하는 챗봇은 업데이트를 바로 해주어서 원하는 정보를 얻을 수 있게끔 해주어야 하기에 이렇게 바로 업데이트를 할 수 있게끔 Lambda라는 서비스를 통해서 해결 할 수 있다.
- 이런 Lambda는 마이크로서비스의 개념인데, monolithic 이라는 개념의 반대
- monolithic은 하나의 서비스를 만들때 크게 프로젝트 단위로 만들어 놓고 관리를 해주는 개념으로써 관리에 있어서 전체 프로세스가 보이기 때문에 컨트롤하기 쉬운 부분이 있다.
- 이에 반해 마이크로서비스는 세세한 작업하나씩을 단위로 관리를 하는 것이다.

![image](https://user-images.githubusercontent.com/79494088/137593705-c65d91cd-4d30-4499-ba5e-c000fe2a6a7b.png)

- 챗봇을 Lambda로 구현하는 이유: Serverless는 하나의 Function이기 때문에 Stateless라고도 하는데 지금 상태가 어떤지 모르겠다는 의미
- 어떤 메시지를 보냈다고 가정하면, Lambda Function에는 이전의 어떠한 메시지를 갖고 있었는지를 담고있을 수 없다.
- 상태가 없는 Function이라고 생각하면 된다.
- 그러므로 이런 State를 관리할만한 데이터베이스가 필요
- 주로 메시지에 특화된 DynamoDB를 사용
- Lambda의 경우에는 해당 서비스의 User가 기하급수적으로 늘어났을 때 병렬로 늘어나기 때문에 제한점이 서버로 구현하는것보단 덜하다
- 서버의 경우에는 메모리나 CPU의 제한된 성능으로 구축된 동일한 서버를 통해 1명에게 서비스하는 것과 백만명에게 서비스하는 것은 완전 다를것이다
- 또 한가지 좋은 점은 지속적으로 띄워져 있는 것이 아니라 필요할 때 띄워서 사용한 만큼만 비용을 지불한다는 점이다.

![image](https://user-images.githubusercontent.com/79494088/137593775-4a4f9e75-2abc-4feb-bd27-9c2f9c4e2cd4.png)

## Lambda 스크립팅

### 함수 생성
- Lambda Function은 이전에 DynamoDB에 top track정보를 DynamoDB에 저장했었는데, Artist가 추가된다면 DynamoDB에도 저장되어야하므로 이 작업을 작성

![image](https://user-images.githubusercontent.com/79494088/137594121-73085b27-f2b5-40e6-af4e-a9fb4cd5bcec.png)

### S3 생성

![image](https://user-images.githubusercontent.com/79494088/137595988-1f1eeae7-ff24-4d88-8b4c-08f8ef7c9da9.png)

### top_tracks 구조

```
top_tracks
├── deploy.sh
├── lambda_function.py
├── requirements.txt
└── setup.cfg
```

#### deploy.sh

```
#!/bin/bash

rm -rf ./libs
pip3 install -r requirements.txt -t ./libs

rm *.zip
zip top_tracks.zip -r *

aws s3 rm s3://6mini-top-tracks/top_tracks.zip
aws s3 cp ./top_tracks.zip s3://6mini-top-tracks/top_tracks.zip
aws lambda update-function-code --function-name top-tracks --s3-bucket 6mini-top-tracks --s3-key top_tracks.zip
```

#### lambda_function.py

```py
import sys
sys.path.append('./libs')
import os
import boto3
import requests
import base64
import json
import logging


client_id = ""
client_secret = ""

try:
    dynamodb = boto3.resource('dynamodb', region_name='ap-northeast-2', endpoint_url='http://dynamodb.ap-northeast-2.amazonaws.com')
except:
    logging.error('could not connect to dynamodb')
    sys.exit(1)


def lambda_handler(event, context):

    headers = get_headers(client_id, client_secret)

    table = dynamodb.Table('top_tracks')

    artist_id = event['artist_id']

    URL = "https://api.spotify.com/v1/artists/{}/top-tracks".format(artist_id)
    params = {
        'country': 'US'
    }
    r = requests.get(URL, params=params, headers=headers)

    raw = json.loads(r.text)

    for track in raw['tracks']:

        data = {
            'artist_id': artist_id
        }

        data.update(track)

        table.put_item(
            Item=data
        )

    return "SUCCESS"



def get_headers(client_id, client_secret):

    endpoint = "https://accounts.spotify.com/api/token"
    encoded = base64.b64encode("{}:{}".format(client_id, client_secret).encode('utf-8')).decode('ascii')

    headers = {
        "Authorization": "Basic {}".format(encoded)
    }

    payload = {
        "grant_type": "client_credentials"
    }

    r = requests.post(endpoint, data=payload, headers=headers)

    access_token = json.loads(r.text)['access_token']

    headers = {
        "Authorization": "Bearer {}".format(access_token)
    }

    return headers


if __name__=='__main__':
    main()

```

#### requirements.txt

```
requests
```

#### setup.cfg

```
[install]
prefix=
```

### 실행

```
$ brew install awscli

$ chmod +x deploy.sh

$ ./deploy.sh
```

### IAM 역할 설정

![image](https://user-images.githubusercontent.com/79494088/137596084-7031f5ae-8e62-471f-9158-5d45f118199c.png)

![image](https://user-images.githubusercontent.com/79494088/137596104-10d9584c-0ba0-415f-857c-630b4ebc790c.png)

### Test

![image](https://user-images.githubusercontent.com/79494088/137596123-146fcf45-fb71-486e-a6ad-fb5ca62f38cf.png)
